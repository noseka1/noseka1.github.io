<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Ales Nosek - The Software Practitioner]]></title>
  <link href="http://alesnosek.com/atom.xml" rel="self"/>
  <link href="http://alesnosek.com/"/>
  <updated>2019-10-27T20:51:02-07:00</updated>
  <id>http://alesnosek.com/</id>
  <author>
    <name><![CDATA[Ales Nosek]]></name>

  </author>
  <generator uri="http://octopress.org/">Octopress</generator>


  <entry>
    <title type="html"><![CDATA[Open Policy Agent, Part II &mdash; Developing Policies]]></title>
    <link href="http://alesnosek.com/blog/2019/10/27/open-policy-agent-part-ii-developing-policies/"/>
    <updated>2019-10-27T20:37:08-07:00</updated>
    <id>http://alesnosek.com/blog/2019/10/27/open-policy-agent-part-ii-developing-policies</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2019/10/08/open-policy-agent-part-i-the-introduction/">previous part</a> of the series, we explored Open Policy Agent and implemented an ACL-based access control for our application. In this entry, I am going to share with you some of the discoveries that I made while evaluating Open Policy Agent in regards to policy design and development.</p>

<!-- more -->


<h2>Notes on Policy Design</h2>

<p>After evaluating policy rules, OPA returns a result of the policy decision to your application. This result is a JSON structure. Based on your requirements, this JSON structure can contain a single member holding a <em>true</em> or <em>false</em> (authorized/not authorized) value. However, you can create policies whose evaluation results in an arbitrarily complex JSON document. For example, OPA can return a list of nodes on which Kubernetes should schedule a workload.</p>

<p>In microservice applications, OAuth 2.0 is a rather popular authorization framework used to secure service’s APIs. It typically leverages JSON Web Tokens (JWT) to convey claims. OPA comes with built-in functions that can decode the token and validate its signature and expiration time. Furthermore, your policy rules can make decisions based on the claims included in the token. Just forward the token as an input to OPA and offload the entire token processing from your application!</p>

<p>OPA makes policy decisions based on the data stored in memory. In the case of large data sets, replicating all the data in memory can be impractical. While evaluating policy rules, is OPA able to reach out to an external data store to get additional data for decision making? For example, send a query to LDAP to grab additional attributes or look up data in an SQL database? Based on my research, I think there are two possible approaches for leveraging external data sources in OPA. First, there is a built-in <a href="https://www.openpolicyagent.org/docs/latest/language-reference/#http">HTTP</a> function that can fetch data from external HTTP services during policy evaluation. Second, you can leverage Partial Evaluation as described in this <a href="https://blog.openpolicyagent.org/write-policy-in-opa-enforce-policy-in-sql-d9d24db93bf4">blog post</a>. While partially evaluating policies, OPA doesn’t return a complete policy decision but instead it returns a set of conditions. It is left to you to translate this set of conditions into a query appropriate for your data store and execute the query in order to obtain the final policy decision. Note that regardless of which approach you choose, reaching out to external data stores will have negative impact on latency and reliability of your solution. Caching data in OPA’s memory is always a better option assuming that it suits your use case.</p>

<p>If you have raw data that would be difficult to write a policy against, you can pre-process that data into a form that better suits the policy writing before importing it into OPA. Moreover, if you have multiple sources of data, e.g. data from LDAP and Active Directory, you can merge them outside of OPA and load the merged form into OPA.</p>

<p>RBAC (Role-Based Access Control) and ABAC (Attribute-Based Access Control) are two frequently used policy models. Are you wondering if you can implement them using OPA? Of course you can! Follow these two links to find sample implementations of <a href="https://www.openpolicyagent.org/docs/latest/comparison-to-other-systems/#role-based-access-control-rbac">RBAC</a> and <a href="https://www.openpolicyagent.org/docs/latest/comparison-to-other-systems/#attribute-based-access-control-abac">ABAC</a>.</p>

<p>Hierarchical group permissions are commonly found in practice, e.g. parent group permissions are a superset of child group permissions. These models can be elegantly described using recursive rules. However, at the time of this writing, OPA doesn’t support <a href="https://github.com/open-policy-agent/opa/issues/947">recursion in policies</a>.</p>

<h2>Developing policies</h2>

<p>While learning the OPA’s Rego language, I appreciated the built-in interactive shell (REPL) that I could use to write and test my policies instantly. Just type <code>opa run</code> and you are good to go. Alternatively, you can go on-line and utilize the <a href="https://play.openpolicyagent.org/">Rego Playground</a>, too.</p>

<p>If you are dealing with complex policies, how do you ensure that you implemented your policies correctly? OPA <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-test-policies/">allows</a> you to write test cases which you can run against your policies. You can use data mocking and calculate test coverage. See also the command <code>opa test</code>.</p>

<p>Is the evaluation of your policies too slow? OPA comes with a <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-test-policies/#profiling">profiler</a> to report on time spent on evaluating policy expressions. See also the <code>opa eval</code> command.</p>

<p>OPA comes with a formatting tool <code>opa fmt</code> to format Rego policy files. You don’t need to fight battles with other developers about how the Rego files should be formatted!</p>

<p>OPA is a relatively new project, however, additional tooling and integrations with OPA are showing up quickly. If you like to use Visual Studio Code, there is a feature-rich <a href="https://marketplace.visualstudio.com/items?itemName=tsandall.opa">VS Code plugin</a> available for you. Rego syntax highlighting is available for several other editors like VIM, <a href="https://github.com/open-policy-agent/opa/tree/master/misc/syntax/atom">Atom</a>, and <a href="https://github.com/open-policy-agent/opa/tree/master/misc/syntax/textmate">TextMate</a>.</p>

<h2>Conclusion</h2>

<p>In this blog post, I shared with you several tips and approaches for how to design policies in Open Policy Agent. In the final article in the series we will focus on how you can integrate Open Policy Agent with your application.</p>

<p>If you have any comments or questions, please use the comment section below. I look forward to hearing from you.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Open Policy Agent, Part I &mdash; The Introduction]]></title>
    <link href="http://alesnosek.com/blog/2019/10/08/open-policy-agent-part-i-the-introduction/"/>
    <updated>2019-10-08T07:13:38-07:00</updated>
    <id>http://alesnosek.com/blog/2019/10/08/open-policy-agent-part-i-the-introduction</id>
    <content type="html"><![CDATA[<p>Recently I was looking for a way to implement access control for microservices. I needed a solution that would allow defining complex authorization rules that could be enforced across many services. After searching the web, I discovered a very promising <a href="https://www.openpolicyagent.org/">Open Policy Agent</a> project that seems to be the right tool for the job. In this series of three blog posts, I am going to introduce Open Policy Agent to you and highlight how it can help you.</p>

<!-- more -->


<h2>What is Open Policy Agent?</h2>

<p>Open Policy Agent (OPA) is a policy engine that can be used to implement fine-grained access control for your application. For example, you can use OPA to implement <a href="https://www.openpolicyagent.org/docs/latest/http-api-authorization/">authorization</a> across microservices. However, there is much more that can be accomplished with OPA. For your inspiration, there are several open-source projects that integrate with OPA to implement fine-grained access control like <a href="https://github.com/open-policy-agent/opa-docker-authz">Docker</a>, <a href="https://github.com/open-policy-agent/opa-istio-plugin">Istio</a> and <a href="https://github.com/open-policy-agent/contrib">others</a>. Furthermore, OPA as a general-purpose policy engine, can be leveraged in use cases beyond access control, for instance to make advanced pod placement decisions in <a href="https://github.com/open-policy-agent/opa-kube-scheduler">Kubernetes</a>.</p>

<p>OPA can be deployed as a standalone service along with your microservices. In order to protect your application, each request coming to a microservice must be authorized before it can be processed. To check the authorization, the microservice makes an API call to OPA to decide whether the request is authorized or not. Note that while you can offload authorization decisions from your application to OPA, your application still has to implement the enforcement of those decisions. For example, your application can ask OPA the question <em>&ldquo;Is user Alice allowed to invoke GET /protected/resource?&rdquo;</em> and if OPA answers <em>&ldquo;No&rdquo;</em>, your application has to send HTTP 403 Forbidden back to Alice.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_basic_flow.png"></p>

<p>OPA is written in the Go language and its source code is available on <a href="https://github.com/open-policy-agent/opa">GitHub</a> under the Apache License 2.0. The Open Policy Agent project is hosted by <a href="https://www.cncf.io/">CNCF</a> as an incubating project.</p>

<h2>Making policy decisions</h2>

<p>In this section, I am going to explain how OPA works. Don&rsquo;t worry if everything is not clear to you right away. In the following section, we are going to work through a practical example which will help clarify the details.</p>

<p>What does it take for OPA to make a policy decision? In OPA, there are three inputs into the decision-making process:</p>

<ol>
<li><strong>Data</strong> is a set of facts about the outside world that OPA refers to while making a decision. For example, when controlling access based on the access control list, the data would be a list of users along with the permissions they were granted. Another example: when deciding where to place the next pod on the Kubernetes cluster, the data would be a list of Kubernetes nodes and their currently available capacity. Note that data may change over time and OPA caches its latest state in memory. The data must be provided to OPA in the JSON format.</li>
<li><strong>Query Input</strong> triggers the decision computation. It specifies the question that OPA should decide upon. The query input must be formatted as JSON. For instance, for the question <em>&ldquo;Is user Alice allowed to invoke GET /protected/resource?&rdquo;</em> the query input would contain parameters: <em>Alice</em>, <em>GET</em>, and <em>/protected/resource</em>.</li>
<li><strong>Policy</strong> specifies the computational logic that for the given <em>data</em> and <em>query input</em> yields a policy decision aka query result. The computational logic is described as a set of policy rules in the OPA&rsquo;s custom policy language called <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-write-policies/">Rego</a>. Note that OPA doesn&rsquo;t come with any pre-defined policies. OPA is a policy engine that is able to interpret a policy, however, in order to make use of it you have to create a policy yourself and provide it to OPA.</li>
</ol>


<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_policy_decision.png"></p>

<p>In order to make a policy decision, all three inputs (data, query input, and the policy) are fed into the Policy Engine. The Policy Engine interprets the rules included in the policy and based on the data and the query input makes a policy decision. The policy decision generated by the Policy Engine is a JSON document.</p>

<p>That is how OPA works from a high-level perspective. In the next section, we will dive into a practical example.</p>

<h2>Hands-on tutorial</h2>

<p>This section is a hands-on tutorial where I will walk you through an example of working with OPA. Although, all sorts of access control models can be implemented using OPA, the goal of this exercise is to implement access control using an Access Control List (ACL). So, let&rsquo;s get started!</p>

<h3>Creating data</h3>

<p>Access control list specifies which users have access to the application as well as what operations they are allowed to invoke. For the purposes of this tutorial, I came up with a simple ACL definition:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "alice": [
</span><span class='line'>    "read",
</span><span class='line'>    "write"
</span><span class='line'>  ],
</span><span class='line'>  "bob": [
</span><span class='line'>    "read"
</span><span class='line'>  ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>According to this ACL, a user named <code>alice</code> was granted <code>read</code> and <code>write</code> access to the application. In addition, a user named <code>bob</code> was given <code>read</code> access. No other users were given any access to the application. For now, you can save this ACL definition as a file called <code>myapi-acl.json</code>.</p>

<p>Note that later on we are going to inject this access control list as <em>data</em> into OPA to allow it to make policy decisions based on this list. How did we know what the structure of the ACL document looks like? As a matter of fact, OPA doesn&rsquo;t prescribe how you should structure your data. It only requires the data to be in a JSON format. The recommendation is to structure your data in a way that makes it easy to write policy rules against it. I followed this recommendation and the above access control list is what I came up with.</p>

<h3>Defining query input</h3>

<p>Next, we are going to define a structure of the <em>query input</em>. On each access to our application, we are going to ask OPA whether the given access is authorized or not. To answer that question, OPA needs to know the name of the user that is trying to access the application and the operation that the user is trying to invoke. Here is a sample query input that conveys the two query arguments to OPA :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "input": {
</span><span class='line'>    "user": "alice",
</span><span class='line'>    "operation": "write"
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>You can interpret this query input as the question: &ldquo;Is user <em>alice</em> allowed <em>write</em> access to the application?&rdquo;. Note that it&rsquo;s up to you how you structure your query input. OPA&rsquo;s only requirement is for the input to be in the JSON format.</p>

<h3>Writing Rego policy</h3>

<p>After we decided how our data and the query input look like, we can create a <em>policy</em> that implements the ACL semantics. Using the Rego language, let&rsquo;s create a policy with two rules <code>allow</code> and <code>whocan</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package myapi.policy
</span><span class='line'>
</span><span class='line'>import data.myapi.acl
</span><span class='line'>import input
</span><span class='line'>
</span><span class='line'>default allow = false
</span><span class='line'>
</span><span class='line'>allow {
</span><span class='line'>        access = acl[input.user]
</span><span class='line'>        access[_] == input.access
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>whocan[user] {
</span><span class='line'>        access = acl[user]
</span><span class='line'>        access[_] == input.access
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>The <code>allow</code>  rule checks whether the user is allowed access according to the ACL. It instructs the policy engine to first look up the user&rsquo;s record in ACL and then to check whether the operation the user is trying to invoke is included on user&rsquo;s permission list. Only if there is an ACL record for the given user and the user was granted given access permission, the allow rule results to <code>true</code>. Otherwise it results to <code>false</code>.</p>

<p>The second rule in our policy is the <code>whocan</code> rule. This rule takes the operation as the input argument. For the given operation, <code>whocan</code> rule returns a list of all users that are allowed to invoke the given operation.</p>

<p>You can save the above policy as a file called <code>myapi-policy.rego</code>. We are going to upload it into OPA in just a moment. At this point, both the ACL file <code>myapi-acl.json</code> we created earlier and the policy file  <code>myapi-policy.rego</code> are sitting in our working directory. It&rsquo;s now time to put OPA to work!</p>

<h3>Starting up Open Policy Agent service</h3>

<p>You can grab the OPA binary for your  platform (Linux, MacOS, or Windows) from <a href="https://github.com/open-policy-agent/opa/releases">GitHub</a>. After downloading the binary, start the OPA service by issuing the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ opa run --server</span></code></pre></td></tr></table></div></figure>


<p>OPA service is now up and listening on port <code>8181</code>. Next, we are going to upload the ACL file and the policy file into OPA. Note that OPA stores both the data and policies in memory and so if you restart the OPA service, you will have to reload both of the files.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_upload_policy_and_data.png"></p>

<p>First, upload the ACL file <code>myapi-acl.json</code> into OPA using the following <code>curl</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X PUT http://localhost:8181/v1/data/myapi/acl --data-binary @myapi-acl.json</span></code></pre></td></tr></table></div></figure>


<p>Next, upload the policy file <code>myapi-policy.rego</code> into OPA by issuing:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X PUT http://localhost:8181/v1/policies/myapi --data-binary @myapi-policy.rego</span></code></pre></td></tr></table></div></figure>


<h3>Invoking policy queries</h3>

<p>Finally, if everything went well, we are now ready to issue our first  query.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_query_policy.png"></p>

<p>Let&rsquo;s ask OPA whether the user <code>alice</code> can invoke a <code>write</code> operation on our application:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X POST http://localhost:8181/v1/data/myapi/policy/allow \
</span><span class='line'>--data-binary '{ "input": { "user": "alice", "access": "write" } }' \
</span><span class='line'>| jq
</span><span class='line'>{
</span><span class='line'>  "result": true
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>The query result returned by OPA says that the user <code>alice</code> is authorized for writing. Our application would now proceed with executing the write operation. And what about <code>bob</code>? Is user <code>bob</code> allowed to write?</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X POST http://localhost:8181/v1/data/myapi/policy/allow \
</span><span class='line'>--data-binary '{ "input": { "user": "bob", "access": "write" } }' \
</span><span class='line'>| jq
</span><span class='line'>{
</span><span class='line'>  "result": false
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>The query result says it clearly. User <code>bob</code> is denied <code>write</code> access. Our application would return HTTP 403 Forbidden to <code>bob</code> at this point.</p>

<p>From what we have seen so far, a query result can be a simple <code>true</code> or <code>false</code> value. However, this is not a limitation that OPA would impose. OPA allows you to write policy rules that can yield an arbitrarily complex JSON structure. For example, the <code>whocan</code> rule that we defined in our policy, returns a JSON list.</p>

<p>Let&rsquo;s give it a try and ask OPA to return a list of users that were granted the <code>read</code> permission:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X POST http://localhost:8181/v1/data/myapi/policy/whocan \
</span><span class='line'>--data-binary '{ "input": { "access": "read" } }' \
</span><span class='line'>| jq
</span><span class='line'>{
</span><span class='line'>  "result": [
</span><span class='line'>    "alice",
</span><span class='line'>    "bob"
</span><span class='line'>  ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>In this article, we took an initial look at Open Policy Agent. After discussing how OPA works, we went through an example of implementing an Access Control List policy. In the <a href="http://alesnosek.com/blog/2019/10/27/open-policy-agent-part-ii-developing-policies/">next entry</a> to this series, we are going to dive deeper into developing policies with OPA.</p>

<p>I hope that you found this article useful. If you have any questions or comments, please add them to the comment section below. I look forward to hearing from you.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Future-Proof Monolithic Applications with Modular Design]]></title>
    <link href="http://alesnosek.com/blog/2019/09/23/future-proof-monolithic-applications-with-modular-design/"/>
    <updated>2019-09-23T14:34:26-07:00</updated>
    <id>http://alesnosek.com/blog/2019/09/23/future-proof-monolithic-applications-with-modular-design</id>
    <content type="html"><![CDATA[<p>The <a href="https://www.redhat.com/en/events/webinar/develop-deploy-deliver-continuously">Cloud Native Virtual Event</a>, presented by Red Hat, is coming up on October 10th, 2019. As part of the Development track, I will be co-presenting on the topic: <em>Future-proof monolithic applications with modular design</em>. If you are interested in hearing Eric Murphy and myself discussing the development of highly-modular applications, you can register for the event <a href="https://www.redhat.com/en/events/webinar/develop-deploy-deliver-continuously#registration">here</a>. As part of our presentation, we will be demonstrating a sample Quarkus + Vert.x application that can be deployed both as a monolith or as a set of microservices while using the same code and modular design.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Configuring Envoy to Auto-Discover Pods on Kubernetes]]></title>
    <link href="http://alesnosek.com/blog/2019/08/19/configuring-envoy-to-audo-discover-pods-on-kubernetes/"/>
    <updated>2019-08-19T11:04:51-07:00</updated>
    <id>http://alesnosek.com/blog/2019/08/19/configuring-envoy-to-audo-discover-pods-on-kubernetes</id>
    <content type="html"><![CDATA[<p>Pods on Kubernetes are ephemeral and can be created and destroyed at any time. In order for Envoy to load balance the traffic across pods, Envoy needs to be able to track the IP addresses of the pods over time. In this blog post, I am going to show you how to leverage Envoy&rsquo;s Strict DNS discovery in combination with a headless service in Kubernetes to accomplish this.</p>

<!-- more -->


<h2>Overview</h2>

<p>Envoy provides several <a href="https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/service_discovery">options</a> on how to discover back-end servers. When using the <a href="https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/service_discovery#strict-dns">Strict DNS</a> option,  Envoy will periodically query a specified DNS name. If there are multiple IP addresses included in the response to Envoy&rsquo;s query, each returned IP address will be considered a back-end server. Envoy will load balance the inbound traffic across all of them.</p>

<p>How to configure a DNS server to return multiple IP addresses to Envoy? Kubernetes comes with a <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a> object which, roughly speaking, provides two functions. It can create a single DNS name for a group of pods for discovery and it can load balance the traffic across those pods. We are not interested in the load balancing feature as we aim to use Envoy for that. However, we can make a good use of the discovery mechanism. The Service configuration we are looking for is called a <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">headless service</a> with selectors.</p>

<p>The diagram below depicts how to configure Envoy to auto-discover pods on Kubernetes. We are combining Envoy&rsquo;s Strict DNS service discovery with a headless service in Kubernetes:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/envoy_auto_discovery.png"></p>

<h2>Practical implementation</h2>

<p>To put this configuration into practice, I used <a href="https://www.okd.io/minishift/">Minishift</a> 3.11 which is a variant of Minikube developed by Red Hat. First, I deployed two replicas of the httpd server on Kubernetes to play the role of back-end services. Next, I created a headless service using the following definition:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">apiVersion</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">v1</span>
</span><span class='line'><span class="l-Scalar-Plain">kind</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Service</span>
</span><span class='line'><span class="l-Scalar-Plain">metadata</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd-discovery</span>
</span><span class='line'><span class="l-Scalar-Plain">spec</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusterIP</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">None</span>
</span><span class='line'>  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">http</span>
</span><span class='line'>      <span class="l-Scalar-Plain">port</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">8080</span>
</span><span class='line'>  <span class="l-Scalar-Plain">selector</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">app</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>  <span class="l-Scalar-Plain">type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ClusterIP</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that we are explicitly specifying &ldquo;None&rdquo; for the cluster IP in the service definition. As a result, Kubernetes creates the respective Endpoints object containing the IP addresses of the discovered httpd pods:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc get endpoints
</span><span class='line'>NAME              ENDPOINTS                                                        AGE
</span><span class='line'>httpd-discovery   172.17.0.21:8080,172.17.0.22:8080                                30s
</span></code></pre></td></tr></table></div></figure>


<p> If you ssh to one of the cluster nodes or rsh to any of the pods running on the cluster, you can verify that the DNS discovery is working:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>host httpd-discovery
</span><span class='line'>httpd-discovery.mynamespace.svc.cluster.local has address 172.17.0.21
</span><span class='line'>httpd-discovery.mynamespace.svc.cluster.local has address 172.17.0.22
</span></code></pre></td></tr></table></div></figure>


<p>Next, I used the container image <code>docker.io/envoyproxy/envoy:v1.7.0</code> to create an Envoy proxy. I deployed the proxy into the same Kubernetes namespace called <code>mynamespace</code> where I created the headless service before. A minimum Envoy configuration that can accomplish our goal looks as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">static_resources</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">listeners</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">listener_0</span>
</span><span class='line'>    <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>        <span class="l-Scalar-Plain">protocol</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">TCP</span>
</span><span class='line'>        <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0.0.0.0</span>
</span><span class='line'>        <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">10000</span>
</span><span class='line'>    <span class="l-Scalar-Plain">filter_chains</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">filters</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">envoy.http_connection_manager</span>
</span><span class='line'>        <span class="l-Scalar-Plain">config</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="l-Scalar-Plain">stat_prefix</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ingress_http</span>
</span><span class='line'>          <span class="l-Scalar-Plain">route_config</span><span class="p-Indicator">:</span>
</span><span class='line'>            <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">local_route</span>
</span><span class='line'>            <span class="l-Scalar-Plain">virtual_hosts</span><span class="p-Indicator">:</span>
</span><span class='line'>            <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">local_service</span>
</span><span class='line'>              <span class="l-Scalar-Plain">domains</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span><span class="s">&quot;*&quot;</span><span class="p-Indicator">]</span>
</span><span class='line'>              <span class="l-Scalar-Plain">routes</span><span class="p-Indicator">:</span>
</span><span class='line'>              <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">match</span><span class="p-Indicator">:</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">prefix</span><span class="p-Indicator">:</span> <span class="s">&quot;/&quot;</span>
</span><span class='line'>                <span class="l-Scalar-Plain">route</span><span class="p-Indicator">:</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">host_rewrite</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">cluster</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>          <span class="l-Scalar-Plain">http_filters</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">envoy.router</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusters</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>    <span class="l-Scalar-Plain">connect_timeout</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0.25s</span>
</span><span class='line'>    <span class="l-Scalar-Plain">type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">STRICT_DNS</span>
</span><span class='line'>    <span class="l-Scalar-Plain">dns_lookup_family</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">V4_ONLY</span>
</span><span class='line'>    <span class="l-Scalar-Plain">lb_policy</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ROUND_ROBIN</span>
</span><span class='line'>    <span class="l-Scalar-Plain">hosts</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd-discovery</span>
</span><span class='line'>          <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">8080</span>
</span><span class='line'><span class="l-Scalar-Plain">admin</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">access_log_path</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">/tmp/admin_access.log</span>
</span><span class='line'>  <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="l-Scalar-Plain">protocol</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">TCP</span>
</span><span class='line'>      <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">127.0.0.1</span>
</span><span class='line'>      <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">9901</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that in the above configuration,  I instructed Envoy to use the Strict DNS discovery and pointed it to the DNS name <code>httpd-discovery</code> that is managed by Kubernetes.</p>

<p>That&rsquo;s all that was needed to be done! Envoy is load balancing the inbound traffic across the two httpd pods now. And if you create a third pod replica, Envoy is going to route the traffic to this replica as well.</p>

<h2>Conclusion</h2>

<p>In this article, I shared with you the idea of using Envoy&rsquo;s Strict DNS service discovery in combination with the headless service in Kubernetes to allow Envoy to auto-discover the back-end pods. While writing this article, I discovered this <a href="https://blog.markvincze.com/how-to-use-envoy-as-a-load-balancer-in-kubernetes/">blog post</a> by Mark Vincze that describes the same idea and you should take a look at it as well.</p>

<p>This idea opens the door for you to utilize the advanced features of Envoy proxy in your microservices architecture. However, if you find yourself looking for a more complex solution down the road, I would suggest that you evaluate the <a href="https://istio.io/">Istio</a> project. Istio provides a control plane that can manage Envoy proxies for you achieving the so called service mesh.</p>

<p>Hope you found this article useful. If you are using Envoy proxy on top of Kubernetes I would be happy to hear about your experiences. You can leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Troubleshooting the Performance of Vert.x Applications, Part III &mdash; Troubleshooting Event Loop Delays]]></title>
    <link href="http://alesnosek.com/blog/2019/08/05/troubleshooting-the-performance-of-vert-dot-x-applications-troubleshooting-event-loop-delays/"/>
    <updated>2019-08-05T13:26:34-07:00</updated>
    <id>http://alesnosek.com/blog/2019/08/05/troubleshooting-the-performance-of-vert-dot-x-applications-troubleshooting-event-loop-delays</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays/">previous entry</a> to this series, we reviewed several techniques that help you to prevent event loop delays. However, even the best programmer makes mistakes. What should you do when your Vert.x application doesn&rsquo;t perform as expected? How to find out what part of your code is blocking the event loop threads? In the final part of the series, we are going to focus on troubleshooting event loop delays.</p>

<!-- more -->


<p>The event loop thread model is vastly different from the thread-per-request model employed by standard JEE or Spring frameworks. From my experience I can report that it takes developers some time to wrap their heads around it and that at the beginning they tend to make the mistake of introducing blocking calls into the event loop&rsquo;s code path. In the following sections, we will discuss several techniques of how to troubleshoot such situations.</p>

<h2>Blocked thread checker</h2>

<p>Vert.x comes with a built-in mechanism to detect delays on event loop and worker threads by checking the execution time of handlers that you registered with the Vert.x APIs. This mechanism operates in two steps. In the first step, Vert.x saves the timestamp of the moment when a handler starts executing. This <em>start timestamp</em> is saved to a storage attached to the thread that is executing the handler. Whenever the execution of the handler has completed the timestamp is reset. In the second step, Vert.x periodically checks the timestamps using a dedicated thread called <a href="https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/impl/BlockedThreadChecker.java"><code>vertx-blocked-thread-checker</code></a>. This thread is spawned by Vert.x during the creation of the Vert.x instance for example when you call <code>Vertx.vertx()</code>. The vertx-blocked-thread-checker thread can be seen in <a href="https://visualvm.github.io/">VisualVM</a>:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/vertx_blocked_thread_checker.png"></p>

<p>The blocked thread checker serves as a watchdog that periodically checks the Vert.x threads. It iterates over all Vert.x threads and for each thread it subtracts the threads start timestamp from the current time to compute how long the thread has already been executing the handler code. If the execution time exceeds the specified threshold a warning message is dropped into the logs:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-5,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">39</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-6,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">26</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-1,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">31</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-3,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">42</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-2,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">20</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-4,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">21</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-7,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">19</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span></code></pre></td></tr></table></div></figure>


<p>You can use grep to routinely search through your application logs for this message. Vert.x can also log the entire stack trace to help you pinpoint the location in your code where your handler is blocking the thread:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>Mar 24, <span class="m">2019</span> 9:34:23 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-6,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">24915</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>io.vertx.core.VertxException: Thread blocked
</span><span class='line'>        at java.lang.Thread.sleep<span class="o">(</span>Native Method<span class="o">)</span>
</span><span class='line'>        at MyComputingVerticle.start<span class="o">(</span>HelloServer.java:72<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.DeploymentManager.lambda<span class="nv">$doDeploy$8</span><span class="o">(</span>DeploymentManager.java:494<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.DeploymentManager<span class="nv">$$</span>Lambda<span class="nv">$8</span>/644460953.handle<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.ContextImpl.executeTask<span class="o">(</span>ContextImpl.java:320<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.EventLoopContext.lambda<span class="nv">$executeAsync$0</span><span class="o">(</span>EventLoopContext.java:38<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.EventLoopContext<span class="nv">$$</span>Lambda<span class="nv">$9</span>/1778535015.run<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute<span class="o">(</span>AbstractEventExecutor.java:163<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks<span class="o">(</span>SingleThreadEventExecutor.java:404<span class="o">)</span>
</span><span class='line'>        at io.netty.channel.nio.NioEventLoop.run<span class="o">(</span>NioEventLoop.java:462<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.SingleThreadEventExecutor<span class="nv">$5</span>.run<span class="o">(</span>SingleThreadEventExecutor.java:897<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.FastThreadLocalRunnable.run<span class="o">(</span>FastThreadLocalRunnable.java:30<span class="o">)</span>
</span><span class='line'>        at java.lang.Thread.run<span class="o">(</span>Thread.java:748<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that the stack trace is generated at the moment when Vert.x detects that the threshold has been exceeded which is not necessarily the moment when the thread was actually blocking. In other words, it is probable but it is not guaranteed that the stack trace is showing the actual location where your event loop thread is blocking. You may need to examine multiple stack traces to pinpoint the right location.</p>

<p>You can tweak the watchdog check period and the warning thresholds. Here is an example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">VertxOptions</span> <span class="n">options</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">VertxOptions</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// check for blocked threads every 5s</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setBlockedThreadCheckInterval</span><span class="o">(</span><span class="mi">5</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setBlockedThreadCheckIntervalUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// warn if an event loop thread handler took more than 100ms to execute</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxEventLoopExecuteTime</span><span class="o">(</span><span class="mi">100</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxEventLoopExecuteTimeUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">MILLISECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// warn if an worker thread handler took more than 10s to execute</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxWorkerExecuteTime</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxWorkerExecuteTimeUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'> <span class="c1">// log the stack trace if an event loop or worker handler took more than 20s to execute</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setWarningExceptionTime</span><span class="o">(</span><span class="mi">20</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setWarningExceptionTimeUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="n">Vertx</span> <span class="n">vertx</span> <span class="o">=</span> <span class="n">Vertx</span><span class="o">.</span><span class="na">vertx</span><span class="o">(</span><span class="n">options</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that the first check is not executed right at the application start but is delayed by one check period. In our example the first check is executed 5 seconds after the application start followed by checks executed every 5 seconds. The concrete thresholds shown in the example worked well for one of my projects, however, your mileage may vary.  Also, the very first execution of the handlers can be rather slow due to JVM class loading. Performance further improves when the JVM moves from interpreting the byte code to compiling it into the native code and running it directly on the CPU. Hence, you are more likely to hit the warning thresholds shortly after the application start than later on during the application run. It would be great if the threshold values could be dynamically adjusted to avoid the warnings before the JVM warms up. Unfortunately, there&rsquo;s no way how to adjust the thresholds in runtime.</p>

<p>It goes without saying that Vert.x only checks the threads that were created as a result of calling Vert.x APIs. If you instantiate your own thread pool outside of Vert.x those threads won&rsquo;t be checked. If you want Vert.x to check the threads in your custom thread pool, you can ask Vert.x to instantiate a checked thread pool for you like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// create a thread pool with 20 threads, set blocked thread warning threshold to 10 seconds</span>
</span><span class='line'><span class="n">WorkerExecutor</span> <span class="n">executor</span> <span class="o">=</span> <span class="n">vertx</span><span class="o">.</span><span class="na">createSharedWorkerExecutor</span><span class="o">(</span><span class="s">&quot;mypool&quot;</span><span class="o">,</span> <span class="mi">20</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>The good thing about the blocked thread checker is that it is able to detect thread delays regardless of whether they were caused by a call to a blocking API or by executing a compute intensive task. As such it can serve as a good indicator that there is something seriously wrong with your application.</p>

<h2>Inspecting stack traces</h2>

<p>Some event loop delays can be so subtle that they can go unnoticed by the blocked thread checker. Imagine a situation where you have a handler that causes a very short delay.  The blocked thread checker won&rsquo;t catch this short delay because it is not long enough to reach the threshold. However, if this handler is called very frequently, the aggregate delay caused by this handler can have a great impact on the performance of your application. How to uncover this kind of issue?</p>

<p>A good option is to analyze Java thread dumps by hand. You can refer to <a href="https://dzone.com/articles/how-analyze-java-thread-dumps">this article</a> if you want to learn how to do it. Alternatively, you can use a Java profiler like <a href="[https://visualvm.github.io/](https://visualvm.github.io/">VisualVM</a> to find out in what parts of your code the most processing time is spent. Instead of writing a long prose about how to use VisualVM to troubleshoot a Vert.x application, I created a short video for you. You can watch this demo using <a href="[https://jmeter.apache.org/](https://jmeter.apache.org/">JMeter</a> and VisualVM to figure out the cause of delays of the Vert.x event loop:</p>

<div style="text-align:center;">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/xxLVQMssLCk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>


<h2>Conclusion</h2>

<p>In this article, we talked about the blocked thread checker as a first indicator of the event loop delays. Next, I showed you in the video how to troubleshoot event loop delays in practice using VisualVM.</p>

<p>I hope that I didn&rsquo;t scare you throughout this series by analyzing all the things that can go wrong when working with the thread model Vert.x is based on. In reality it&rsquo;s not so bad. One just has to pay attention to the event loop model while coding. The awesome performance that Vert.x applications can achieve is definitely a sufficient reward for the extra effort.</p>

<p>If you got some battle scars while working with the event loop thread model in Vert.x, I would be interested in hearing your stories. Also, let me know if you found the video demonstration helpful or if you have suggestions for future videos. If you have any further questions or comments, feel free to add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Troubleshooting the Performance of Vert.x Applications, Part II &mdash; Preventing Event Loop Delays]]></title>
    <link href="http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays/"/>
    <updated>2019-07-22T11:15:42-07:00</updated>
    <id>http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2019/06/30/troubleshooting-the-performance-of-vert-dot-x-applications-part-i-the-event-loop-model/">previous part</a> of the series, we took a closer look at the event loop model. In this article, we are going to discuss several techniques that help you to prevent event loop delays.</p>

<!-- more -->


<p>The causes of event loop delays can be divided into two categories. The first category contains event loop delays caused by a handler calling a blocking API. The second category covers delays caused by a handler code taking a great amount of CPU time to complete. Let&rsquo;s start with the first category and talk about blocking API calls.</p>

<h2>Working with blocking APIs</h2>

<p>Calling a blocking API on the event loop thread is especially hurtful for the performance of your application and you should avoid it at all cost. When you call a blocking API from the event loop thread, the event loop thread will be put to sleep, i.e. it will relinquish the CPU. The duration of the sleep can be rather long in comparison to how much work the event loop thread could have accomplished if it would remain executing on the CPU. This is going to result in a serious decrease of the throughput of your application. In addition to impacting the throughput, the latency of your application is going to raise, too. Because as the event loop thread is sleeping no processing is taking place and so all the outstanding work is going to be pushed back by the duration of the sleep.</p>

<p>Common examples of blocking APIs that you should not call from the event loop thread are:</p>

<ul>
<li>&ldquo;Old&rdquo; Java  I/O APIs found in the <code>java.io</code> package</li>
<li>JDBC APIs</li>
<li>Locking APIs in the <code>java.util.concurrent.locks</code> package</li>
<li>Using <code>synchronized</code> keyword in your code</li>
<li>Other blocking APIs</li>
</ul>


<p>You should also check the various third-party libraries you may be using to ensure that their APIs are non-blocking. Sometimes the differences can be really subtle. For example, if you are using <a href="https://logging.apache.org/log4j/2.x/">Apache Log4j 2</a> library for logging, you may want to configure it to use <a href="https://logging.apache.org/log4j/log4j-2.0/manual/async.html">asynchronous loggers</a> when logging from the event loop.</p>

<p>There are situations where you cannot avoid using blocking APIs. A typical example is when a third-party library you want to use provides only blocking APIs. As there is no way how to execute a blocking API on the event loop thread without putting this thread to sleep, your only option in Vert.x is to offload the blocking calls to a worker thread. I am going to show you two techniques how you can accomplish this.</p>

<p>The first technique is straight forward. It leverages the <code>executeBlocking</code> method provided by Vert.x. In the following example, the event loop thread schedules a <code>blockingCodeHandler</code> to run on a worker thread by calling the <code>vertx.executeBlocking()</code> method. After the execution of the <code>blockingCodeHandler</code> is complete, the <code>resultHandler</code> will be executed  on the event loop thread that made the original <code>vertx.executeBlocking()</code> call:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">class</span> <span class="nc">ExecuteBlockingExample</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// on the event loop thread</span>
</span><span class='line'>      <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Calling from &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">Future</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">blockingCodeHandler</span> <span class="o">=</span> <span class="n">future</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// executed on a worker thread</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Work executed on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>          <span class="n">future</span><span class="o">.</span><span class="na">complete</span><span class="o">(</span><span class="s">&quot;OK&quot;</span><span class="o">);</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">AsyncResult</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">resultHandler</span> <span class="o">=</span> <span class="n">result</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// back on the calling event loop thread</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Result &#39;&quot;</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="na">result</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; received on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">executeBlocking</span><span class="o">(</span><span class="n">blockingCodeHandler</span><span class="o">,</span> <span class="n">resultHandler</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>After running the example code, you will see the following output:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">Calling</span> <span class="n">from</span> <span class="n">vert</span><span class="o">.</span><span class="na">x</span><span class="o">-</span><span class="n">eventloop</span><span class="o">-</span><span class="n">thread</span><span class="o">-</span><span class="mi">0</span>
</span><span class='line'><span class="n">Work</span> <span class="n">executed</span> <span class="n">on</span> <span class="n">vert</span><span class="o">.</span><span class="na">x</span><span class="o">-</span><span class="n">worker</span><span class="o">-</span><span class="n">thread</span><span class="o">-</span><span class="mi">0</span>
</span><span class='line'><span class="n">Result</span> <span class="err">&#39;</span><span class="n">OK</span><span class="err">&#39;</span> <span class="n">received</span> <span class="n">on</span> <span class="n">vert</span><span class="o">.</span><span class="na">x</span><span class="o">-</span><span class="n">eventloop</span><span class="o">-</span><span class="n">thread</span><span class="o">-</span><span class="mi">0</span>
</span></code></pre></td></tr></table></div></figure>


<p>The second technique for offloading the blocking API calls to a worker thread is a bit more involved. We are going to deploy a worker verticle and send it the work as a message using the event bus. After the worker thread completes the work it will reply sending the result back to us.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">AbstractVerticle</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">(</span><span class="n">Future</span><span class="o">&lt;</span><span class="n">Void</span><span class="o">&gt;</span> <span class="n">startFuture</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// work handler</span>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">Message</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">handler</span> <span class="o">=</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Received message on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'>          <span class="c1">// do work</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Working ...&quot;</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>          <span class="n">message</span><span class="o">.</span><span class="na">reply</span><span class="o">(</span><span class="s">&quot;OK&quot;</span><span class="o">);</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// wait for work</span>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">eventBus</span><span class="o">().</span><span class="na">consumer</span><span class="o">(</span><span class="s">&quot;worker&quot;</span><span class="o">,</span> <span class="n">handler</span><span class="o">).</span><span class="na">completionHandler</span><span class="o">(</span><span class="n">r</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">startFuture</span><span class="o">.</span><span class="na">complete</span><span class="o">();</span>
</span><span class='line'>      <span class="o">});</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">},</span> <span class="k">new</span> <span class="nf">DeploymentOptions</span><span class="o">().</span><span class="na">setWorker</span><span class="o">(</span><span class="kc">true</span><span class="o">));</span>
</span><span class='line'>
</span><span class='line'><span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">AbstractVerticle</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// reply handler</span>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">AsyncResult</span><span class="o">&lt;</span><span class="n">Message</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;&gt;</span> <span class="n">replyHandler</span> <span class="o">=</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span>
</span><span class='line'>              <span class="s">&quot;Received reply &#39;&quot;</span> <span class="o">+</span> <span class="n">message</span><span class="o">.</span><span class="na">result</span><span class="o">().</span><span class="na">body</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// dispatch work</span>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">eventBus</span><span class="o">().</span><span class="na">send</span><span class="o">(</span><span class="s">&quot;worker&quot;</span><span class="o">,</span> <span class="s">&quot;request&quot;</span><span class="o">,</span> <span class="n">replyHandler</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>After running the above code  you will receive the following output:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>Received message on vert.x-worker-thread-1
</span><span class='line'>Working ...
</span><span class='line'>Received reply <span class="s1">&#39;OK&#39;</span> on vert.x-eventloop-thread-0
</span></code></pre></td></tr></table></div></figure>


<h2>Executing compute intensive tasks</h2>

<p>What is a compute intensive task? It is a task that makes heavy use of CPU and memory. Common examples of compute intensive tasks are parsing, encryption, compression and others. Executing compute intensive task within the event loop handler doesn&rsquo;t affect the throughput of your application because the event loop thread is busy doing useful work which would need to be done anyway. However, as the event loop thread is kept busy, other handlers on the event loop will be processed with a delay. How can we improve the situation and allow other handlers to be processed in a timely fashion?</p>

<p>Let&rsquo;s assume that you are able to chunk up the compute intensive task into several chunks. Then instead of running the entire compute intensive task at once:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">workChunk1</span><span class="o">();</span>
</span><span class='line'><span class="n">workChunk2</span><span class="o">();</span>
</span><span class='line'><span class="n">workChunk3</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can distribute the execution of individual chunks in time allowing the event loop to process other handlers in between. In the following example, we are creating pauses of 100 milliseconds between the work chunks to allow the event loop to interleave other handlers:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kt">long</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">100</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="n">workChunk1</span><span class="o">();</span>
</span><span class='line'><span class="n">vertx</span><span class="o">.</span><span class="na">setTimer</span><span class="o">(</span><span class="n">delay</span><span class="o">,</span> <span class="n">timerId</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">workChunk2</span><span class="o">();</span>
</span><span class='line'>  <span class="n">vertx</span><span class="o">.</span><span class="na">setTimer</span><span class="o">(</span><span class="n">delay</span><span class="o">,</span> <span class="n">timerId2</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">workChunk3</span><span class="o">();</span>
</span><span class='line'>  <span class="o">});</span>
</span><span class='line'><span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>You may encounter scenarios where you won&rsquo;t be able to chunk up the compute intensive task. For example, the compute intensive task&rsquo;s code is contained within a third-party library and executes all at once. In this case, you will have to defer to running this task on a worker thread and incur the cost of context switching. The operating system scheduler will periodically preempt the compute intensive task to prevent it from hogging the CPU and giving your event loop threads a chance to run.</p>

<h2>Conclusion</h2>

<p>In this article, we discussed how to work with blocking APIs in Vert.x. A blocking API call has to be made on a worker thread and not on an event loop thread. Futhermore, we described a technique that allows you to execute compute intensive tasks on the event loop without considerably delaying the processing of other tasks on the same event loop.</p>

<p>If you have any comments or questions please feel free to use the comment section below. In the final article in the series we will cover some techniques for troubleshooting event loop delays.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Installing OpenShift 4.1 Using Libvirt and KVM]]></title>
    <link href="http://alesnosek.com/blog/2019/07/08/installing-openshift-4-dot-1-using-libvirt-and-kvm/"/>
    <updated>2019-07-08T11:53:54-07:00</updated>
    <id>http://alesnosek.com/blog/2019/07/08/installing-openshift-4-dot-1-using-libvirt-and-kvm</id>
    <content type="html"><![CDATA[<p>In this blog post, I am going to talk about how I installed OpenShift 4.1 on a Fedora laptop with 16 GB of RAM. If you are interested in deploying your own OpenShift instance whether for evaluation or testing please follow along with me.</p>

<!-- more -->


<p>OpenShift 4.1 is the first GA release in the OpenShift 4 series. It is a significant leap forward in the evolution of OpenShift mainly due to the incorporation of features developed by the folks at CoreOS. In order to take a closer look at the latest and greatest version of OpenShift, I installed OpenShift 4.1 on my laptop using Libvirt and KVM. How did I accomplish this?</p>

<p>I essentially followed the <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html">guide</a> for installing the OpenShift cluster on bare metal and I recommend that you read this guide first. After you make yourself familiar with the bare metal installation process, read on to learn the details on how I made this process work on Libvirt and KVM.</p>

<h2>Deployment overview</h2>

<p>First, let&rsquo;s take a look at the diagram showing the deployment of the OpenShift cluster on Libvirt/KVM. In addition to the OpenShift cluster nodes, the diagram also depicts supplementary pieces of the user-provisioned infrastructure that you will need to deploy:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/openshift_4_on_libvirt.png"></p>

<p>In the diagram, you can see that there is an HTTP server and an oc client installed directly on the host machine. The remaining boxes in the diagram are virtual machines. I outlined the purpose of the virtual machines for you in the following table:</p>

<table>
<thead>
<tr>
<th> VM Name </th>
<th> Operating System </th>
<th> Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td> <em>dns</em> </td>
<td> RHEL7 </td>
<td> Custom Dnsmasq DNS server used by the load balancer, bootstrap node and OpenShift nodes. </td>
</tr>
<tr>
<td> <em>loadbalancer</em> </td>
<td> RHEL 7 </td>
<td> HAProxy load balancer. Facilitates bootstrapping, balances the load between the master nodes and also between the ingress router pods. </td>
</tr>
<tr>
<td> <em>bootstrap</em> </td>
<td> RHCOS </td>
<td> The bootstrap machine. Used one-time to initialize the OpenShift cluster. </td>
</tr>
<tr>
<td> <em>master</em> </td>
<td> RHCOS </td>
<td> OpenShift master node. </td>
</tr>
<tr>
<td> <em>worker-1</em> </td>
<td> RHCOS </td>
<td> OpenShift worker node. </td>
</tr>
</tbody>
</table>


<p>Note that the virtual machines are deployed across two Libvirt networks: <code>openshift-dns</code> and <code>openshift-cluster</code>. Using two Libvirt networks allowed me to meet the OpenShift DNS requirements and I will elaborate on this design later on in this post.</p>

<p>After reviewing the big picture, let&rsquo;s roll up our sleeves and get to work. We are going to deal with the HTTP server first.</p>

<h2>Setting up HTTP server</h2>

<p>The OpenShift installation process assumes installation on empty virtual machines with no operating system pre-installed. There are two provisioning methods available to choose from. You can either provision OpenShift nodes by booting from an ISO image or you can leverage the PXE boot. I find the PXE boot option to take a bit more effort to configure and hence went with the ISO image method.</p>

<p>Using the ISO image method, you are supposed to boot the virtual machines using the <code>rhcos-4.1.0-x86_64-installer.iso</code> CD-ROM image. During the boot from this image, the Red Hat CoreOS installer starts up and provisions an empty virtual machine in two steps:</p>

<ol>
<li>It downloads a disk image <code>rhcos-4.1.0-x86_64-metal-bios.raw.gz</code> from a URL you specify and writes it to the virtual machine&rsquo;s disk.</li>
<li>It downloads one of the ignition files (e.g. <code>bootstrap.ign</code>, <code>master.ign</code>, or <code>worker.ign</code>) and installs it on the virtual machine&rsquo;s file system.  This ignition file contains configuration required for the bootstrap of the OpenShift cluster that is triggered on the next reboot.</li>
</ol>


<p>You are expected to host the aforementioned files on an HTTP server that is reachable from the OpenShift nodes during the provisioning process. To meet this requirement, I installed an Apache HTTP server on my Fedora host machine and copied the disk image and ignition files to the <code>/var/www/html</code> directory which is the default <code>DocumentRoot</code> directory on a Fedora host.</p>

<h2>Addressing OpenShift DNS requirements</h2>

<p>OpenShift <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html#installation-dns-user-infra_installing-bare-metal">requires</a> a set of records to be configured in your DNS. In addition to simple A records, you must also configure a wildcard DNS record that points to the load balancer and an SRV DNS record for each of the etcd nodes.</p>

<p>Libvirt allows you to insert custom A and SRV records into DNS. You can specify them using the <a href="https://libvirt.org/formatnetwork.html">network descriptor</a>. However, Libvirt doesn&rsquo;t support creating wildcard DNS records. The respective feature request can be found <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1532856">here</a>. It would be great if it would be possible to meet the OpenShift DNS requirements by just configuring the DNS records in the Libvirt&rsquo;s network descriptor. However, as the wildcard DNS records were not supported at the time of this writing, I had to look for an alternative solution. After giving it some thought, I decided to spin up my own DNS server and instructed Libvirt to forward the DNS queries sent by the OpenShift nodes to this server. In order to achieve this, I had to define two networks in Libvirt: <code>openshift-dns</code> and <code>openshift-cluster</code>.</p>

<p>Let&rsquo;s tackle the <code>openshift-dns</code> network first. A single virtual machine is connected to this network. This virtual machine hosts the custom DNS server. Here is the respective network XML descriptor:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;network&gt;</span>
</span><span class='line'>  <span class="nt">&lt;name&gt;</span>openshift-dns<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>  <span class="nt">&lt;forward</span> <span class="na">mode=</span><span class="s">&#39;nat&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;nat&gt;</span>
</span><span class='line'>      <span class="nt">&lt;port</span> <span class="na">start=</span><span class="s">&#39;1024&#39;</span> <span class="na">end=</span><span class="s">&#39;65535&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/nat&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/forward&gt;</span>
</span><span class='line'>  <span class="nt">&lt;bridge</span> <span class="na">name=</span><span class="s">&#39;virbr-oshd&#39;</span> <span class="na">stp=</span><span class="s">&#39;on&#39;</span> <span class="na">delay=</span><span class="s">&#39;0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;mac</span> <span class="na">address=</span><span class="s">&#39;52:54:00:2c:00:00&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;domain</span> <span class="na">name=</span><span class="s">&#39;mycluster.example.com&#39;</span> <span class="na">localOnly=</span><span class="s">&#39;no&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;ip</span> <span class="na">address=</span><span class="s">&#39;192.168.130.1&#39;</span> <span class="na">netmask=</span><span class="s">&#39;255.255.255.0&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;dhcp&gt;</span>
</span><span class='line'>      <span class="nt">&lt;range</span> <span class="na">start=</span><span class="s">&#39;192.168.130.10&#39;</span> <span class="na">end=</span><span class="s">&#39;192.168.130.254&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:00:10&#39;</span> <span class="na">name=</span><span class="s">&#39;dns.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.130.10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dhcp&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/ip&gt;</span>
</span><span class='line'><span class="nt">&lt;/network&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see in the descriptor, I prefer to manage virtual machine&rsquo;s MAC addresses and the associated IP addresses and host names by hand. The virtual machine <code>dns</code> that hosts my DNS server is connected to the <code>openshift-dns</code> network by including these settings in its domain configuration:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;domain</span> <span class="na">type=</span><span class="s">&#39;kvm&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;name&gt;</span>dns.mycluster.example.com<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>  ...
</span><span class='line'>    <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">&#39;network&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;mac</span> <span class="na">address=</span><span class="s">&#39;52:54:00:2c:00:10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;source</span> <span class="na">network=</span><span class="s">&#39;openshift-dns&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;model</span> <span class="na">type=</span><span class="s">&#39;virtio&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;address</span> <span class="na">type=</span><span class="s">&#39;pci&#39;</span> <span class="na">domain=</span><span class="s">&#39;0x0000&#39;</span> <span class="na">bus=</span><span class="s">&#39;0x00&#39;</span> <span class="na">slot=</span><span class="s">&#39;0x03&#39;</span> <span class="na">function=</span><span class="s">&#39;0x0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/interface&gt;</span>
</span><span class='line'>    ...
</span><span class='line'><span class="nt">&lt;/domain&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>I installed Dnsmasq on this <code>dns</code> virtual machine and replaced the content of <code>/etc/dnsmasq.conf</code> with my own configuration:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ini'><span class='line'><span class="na">local</span><span class="o">=</span><span class="s">/mycluster.example.com/</span>
</span><span class='line'><span class="na">address</span><span class="o">=</span><span class="s">/apps.mycluster.example.com/192.168.131.10</span>
</span><span class='line'><span class="na">srv-host</span><span class="o">=</span><span class="s">_etcd-server-ssl._tcp.mycluster.example.com,master.mycluster.example.com,2380,0,10</span>
</span><span class='line'><span class="err">no-hosts</span>
</span><span class='line'><span class="na">addn-hosts</span><span class="o">=</span><span class="s">/etc/dnsmasq.openshift.addnhosts</span>
</span><span class='line'><span class="na">conf-dir</span><span class="o">=</span><span class="s">/etc/dnsmasq.d,.rpmnew,.rpmsave,.rpmorig</span>
</span></code></pre></td></tr></table></div></figure>


<p>The listing of the <code>/etc/dnsmasq.openshift.addnhosts</code> file referred to in the above configuration looks as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>192.168.130.10 dns.mycluster.example.com
</span><span class='line'>192.168.131.10 loadbalancer.mycluster.example.com  api.mycluster.example.com  api-int.mycluster.example.com
</span><span class='line'>192.168.131.11 bootstrap.mycluster.example.com
</span><span class='line'>192.168.131.12 master.mycluster.example.com  etcd-0.mycluster.example.com
</span><span class='line'>192.168.131.13 worker-1.mycluster.example.com
</span></code></pre></td></tr></table></div></figure>


<p>This configuration addresses the user-provisioned DNS requirements as specified in the <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html">installation guide</a>.</p>

<p>In the next step, we want to make the load balancer machine and OpenShift nodes resolve their DNS queries using our custom DNS server. In order to achieve that, we define a second Libvirt network called <code>openshift-cluster</code> and place the load balancer and OpenShift nodes onto this network. The definition of the <code>openshift-cluster</code> network looks like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;network&gt;</span>
</span><span class='line'>  <span class="nt">&lt;name&gt;</span>openshift-cluster<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>  <span class="nt">&lt;forward</span> <span class="na">mode=</span><span class="s">&#39;nat&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;nat&gt;</span>
</span><span class='line'>      <span class="nt">&lt;port</span> <span class="na">start=</span><span class="s">&#39;1024&#39;</span> <span class="na">end=</span><span class="s">&#39;65535&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/nat&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/forward&gt;</span>
</span><span class='line'>  <span class="nt">&lt;bridge</span> <span class="na">name=</span><span class="s">&#39;virbr-osh&#39;</span> <span class="na">stp=</span><span class="s">&#39;on&#39;</span> <span class="na">delay=</span><span class="s">&#39;0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;mac</span> <span class="na">address=</span><span class="s">&#39;52:54:00:2c:01:00&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;domain</span> <span class="na">name=</span><span class="s">&#39;mycluster.example.com&#39;</span> <span class="na">localOnly=</span><span class="s">&#39;no&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;dns&gt;</span>
</span><span class='line'>    <span class="nt">&lt;forwarder</span> <span class="na">addr=</span><span class="s">&#39;192.168.130.10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/dns&gt;</span>
</span><span class='line'>  <span class="nt">&lt;ip</span> <span class="na">address=</span><span class="s">&#39;192.168.131.1&#39;</span> <span class="na">netmask=</span><span class="s">&#39;255.255.255.0&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;dhcp&gt;</span>
</span><span class='line'>      <span class="nt">&lt;range</span> <span class="na">start=</span><span class="s">&#39;192.168.131.10&#39;</span> <span class="na">end=</span><span class="s">&#39;192.168.131.254&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:10&#39;</span> <span class="na">name=</span><span class="s">&#39;loadbalancer.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:11&#39;</span> <span class="na">name=</span><span class="s">&#39;bootstrap.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.11&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:12&#39;</span> <span class="na">name=</span><span class="s">&#39;master.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.12&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:13&#39;</span> <span class="na">name=</span><span class="s">&#39;worker-1.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.13&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dhcp&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/ip&gt;</span>
</span><span class='line'><span class="nt">&lt;/network&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note the <code>&lt;forwarder addr='192.168.130.10'/&gt;</code> setting which allows all DNS requests from the load balancer and OpenShift nodes deployed on this network to be forwarded to our custom DNS server. Remember that the IP address <code>192.168.130.10</code> is the address of our custom DNS server that we configured previously.</p>

<p>With the DNS configuration out of the way, let&rsquo;s continue with deploying a load balancer in the next section.</p>

<h2>Setting up a load balancer</h2>

<p>Installing OpenShift on a user-provisioned infrastructure requires you to provision a load balancer. The details on how the load balancer should be configured can be found in the <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html#installation-network-user-infra_installing-bare-metal">networking requirements</a> section of the OpenShift installation guide.</p>

<p>The load balancer is used during the bootstrapping process to route the requests to the bootstrap and the master nodes. After the OpenShift installation is complete, the load balancer remains part of the deployment and balances load between the master nodes and also between the ingress router pods.</p>

<p>I created a dedicated virtual machine called <code>loadbalancer</code> and installed HAProxy on top of it. The HAProxy configuration is pretty straight forward. Here is the listing of the <code>/etc/haproxy/haproxy.cfg</code> file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>global
</span><span class='line'>    log         127.0.0.1 local2 info
</span><span class='line'>    chroot      /var/lib/haproxy
</span><span class='line'>    pidfile     /var/run/haproxy.pid
</span><span class='line'>    maxconn     4000
</span><span class='line'>    user        haproxy
</span><span class='line'>    group       haproxy
</span><span class='line'>    daemon
</span><span class='line'>
</span><span class='line'>defaults
</span><span class='line'>    timeout connect         5s
</span><span class='line'>    timeout client          30s
</span><span class='line'>    timeout server          30s
</span><span class='line'>    log                     global
</span><span class='line'>
</span><span class='line'>frontend kubernetes_api
</span><span class='line'>    bind 0.0.0.0:6443
</span><span class='line'>    default_backend kubernetes_api
</span><span class='line'>
</span><span class='line'>backend kubernetes_api
</span><span class='line'>    balance roundrobin
</span><span class='line'>    option ssl-hello-chk
</span><span class='line'>    server bootstrap bootstrap.mycluster.example.com:6443 check
</span><span class='line'>    server master master.mycluster.example.com:6443 check
</span><span class='line'>
</span><span class='line'>frontend machine_config
</span><span class='line'>    bind 0.0.0.0:22623
</span><span class='line'>    default_backend machine_config
</span><span class='line'>
</span><span class='line'>backend machine_config
</span><span class='line'>    balance roundrobin
</span><span class='line'>    option ssl-hello-chk
</span><span class='line'>    server bootstrap bootstrap.mycluster.example.com:22623 check
</span><span class='line'>    server master master.mycluster.example.com:22623 check
</span><span class='line'>
</span><span class='line'>frontend router_https
</span><span class='line'>    bind 0.0.0.0:443
</span><span class='line'>    default_backend router_https
</span><span class='line'>
</span><span class='line'>backend router_https
</span><span class='line'>    balance roundrobin
</span><span class='line'>    option ssl-hello-chk
</span><span class='line'>    server worker-1 worker-1.mycluster.example.com:443 check
</span><span class='line'>
</span><span class='line'>frontend router_http
</span><span class='line'>    mode http
</span><span class='line'>    option httplog
</span><span class='line'>    bind 0.0.0.0:80
</span><span class='line'>    default_backend router_http
</span><span class='line'>
</span><span class='line'>backend router_http
</span><span class='line'>    mode http
</span><span class='line'>    balance roundrobin
</span><span class='line'>    server worker-1 worker-1.mycluster.example.com:80 check</span></code></pre></td></tr></table></div></figure>


<p>With the load balancer in place, we will move on to creating OpenShift virtual machines in the next section.</p>

<h2>Creating OpenShift virtual machines</h2>

<p>The official installation guide <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html#machine-requirements_installing-bare-metal">defines</a> minimum machine requirements for installing an OpenShift cluster as follows:</p>

<ul>
<li>One bootstrap machine</li>
<li>Three control plane, or master, machines</li>
<li>At least two compute, or worker, machines</li>
</ul>


<p>If you can meet these requirements, you will achieve the smallest <em>highly available</em> OpenShift cluster. However, do we really need high availability for our test installation?</p>

<p>Internally, OpenShift uses <a href="https://etcd.io/">etcd</a> to store its state. Since etcd is a quorum-based cluster, it requires at least three nodes to achieve high availability. These etcd nodes are installed on OpenShift master machines which is the reason for the minimum requirement of three OpenShift master machines. In our limited environment, we are going to give up on high availability and instead save up two master machines. OpenShift can install with a single master machine just fine if you can accept the fact that the OpenShift control plane won&rsquo;t be highly available.</p>

<p>And what about the requirement of two worker machines? The minimum requirement of two worker machines ensures that there will be at least two OpenShift routers running on the cluster. OpenShift router is an ingress point for external traffic to reach application pods running on OpenShift. Production installations require that at least two routers are installed to avoid a single point of failure. Furthermore, a highly available load balancer is deployed in front of the two routers. In a data center, a hardware load balancer is typically used, in cloud environments like AWS an Elastic Load Balancer can be utilized. As we don&rsquo;t pursue a highly available deployment, we are going to install an OpenShift cluster with a single worker machine. There will be a single router running on top of this cluster which we hereby accept.</p>

<p>This discussion leads us to the minimum requirements for a <em>not highly available</em> OpenShift cluster:</p>

<ul>
<li>One bootstrap machine</li>
<li>One control plane, or master, machine</li>
<li>One compute, or worker, machine</li>
</ul>


<p>In regards to the minimum memory requirements for each of the machines, I was able to install OpenShift on virtual machines with the following memory configuration:</p>

<table>
<thead>
<tr>
<th> Machine        </th>
<th> RAM  </th>
</tr>
</thead>
<tbody>
<tr>
<td> Bootstrap      </td>
<td> 4 GB </td>
</tr>
<tr>
<td> Control plane  </td>
<td> 6 GB </td>
</tr>
<tr>
<td> Compute        </td>
<td> 6 GB </td>
</tr>
</tbody>
</table>


<p>Note that the above memory requirements allow you to properly deploy the OpenShift cluster including the monitoring and log collection components. Furthermore, there will be enough capacity left on the worker node for you to run several hello world applications.</p>

<p>This concludes the user-provisioned infrastructure setup. At this point, we have HTTP server, DNS server, load balancer and a set of empty virtual machines in place. Let&rsquo;s dive into the OpenShift installation in the next section.</p>

<h2>Installing OpenShift 4.1</h2>

<p>The installation of OpenShift 4 starts with crafting an installation configuration file. You can use the <code>install-config.yaml</code> configuration file that I created, just remember to replace the placeholders with your own pull secret and public SSH key:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">apiVersion</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">v1</span>
</span><span class='line'><span class="l-Scalar-Plain">baseDomain</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">example.com</span>
</span><span class='line'><span class="l-Scalar-Plain">compute</span><span class="p-Indicator">:</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">hyperthreading</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Enabled</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">worker</span>
</span><span class='line'>  <span class="l-Scalar-Plain">platform</span><span class="p-Indicator">:</span> <span class="p-Indicator">{}</span>
</span><span class='line'>  <span class="l-Scalar-Plain">replicas</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0</span>
</span><span class='line'><span class="l-Scalar-Plain">controlPlane</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">hyperthreading</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Enabled</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">master</span>
</span><span class='line'>  <span class="l-Scalar-Plain">platform</span><span class="p-Indicator">:</span> <span class="p-Indicator">{}</span>
</span><span class='line'>  <span class="l-Scalar-Plain">replicas</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">1</span>
</span><span class='line'><span class="l-Scalar-Plain">metadata</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">creationTimestamp</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">null</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">mycluster</span>
</span><span class='line'><span class="l-Scalar-Plain">networking</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusterNetwork</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">cidr</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">10.128.0.0/14</span>
</span><span class='line'>    <span class="l-Scalar-Plain">hostPrefix</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">23</span>
</span><span class='line'>  <span class="l-Scalar-Plain">networkType</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">OpenShiftSDN</span>
</span><span class='line'>  <span class="l-Scalar-Plain">serviceNetwork</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">172.30.0.0/16</span>
</span><span class='line'><span class="l-Scalar-Plain">platform</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">none</span><span class="p-Indicator">:</span> <span class="p-Indicator">{}</span>
</span><span class='line'><span class="l-Scalar-Plain">pullSecret</span><span class="p-Indicator">:</span> <span class="s">&#39;&lt;INSERT_YOUR_PULL_SECRET_HERE&gt;&#39;</span>
</span><span class='line'><span class="l-Scalar-Plain">sshKey</span><span class="p-Indicator">:</span> <span class="s">&#39;&lt;INSERT_YOUR_PUBLIC_SSH_KEY_HERE&gt;&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The OpenShift installation is actually driven by the ignition configuration files. You can issue this command to generate ignition configuration files out of your <code>install-config.yaml</code> file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>./openshift-install create ignition-configs
</span></code></pre></td></tr></table></div></figure>


<p>Beware that the above command will remove your handcrafted <code>install-config.yaml</code> from the disk. I found this behavior of the    <code>openshift-install</code> tool rather annoying. In order to not lose my configuration settings, I protect the <code>install-config.yaml</code> file from deletion by creating a hard link like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ln install-config.yaml install-config.yaml.hardlink
</span></code></pre></td></tr></table></div></figure>


<p>And after the <code>install-config.yaml</code> file is deleted, I can simply recreate it with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ln install-config.yaml.hardlink install-config.yaml
</span></code></pre></td></tr></table></div></figure>


<p>Finally, we can use our ignition files to kick off the OpenShift installation process which deploys OpenShift cluster on our fleet of virtual machines. The whole process takes about 30 minutes and consists of several steps:</p>

<ol>
<li>Provision and reboot the bootstrap machine</li>
<li>Provision and reboot the master machine</li>
<li>Bootstrap the master machine</li>
<li>Shut down the bootstrap machine</li>
<li>Provision and reboot the worker machine</li>
<li>Worker machine joins the OpenShift cluster</li>
</ol>


<p>Note that after you bootstrap the master machine, you should shut down the bootstrap machine. Only after that, you should boot up the worker machine. On startup, the worker node registers with the master node and forms an OpenShift cluster.</p>

<h2>Conclusion</h2>

<p>In this blog post, we discussed how to deploy OpenShift 4.1 into the Libvirt/KVM-based virtualized environment. We created and configured a bunch of user-provisioned infrastructure which was a prerequisite for the OpenShift installation. With the user-provisioned infrastructure in place, we followed the OpenShift bare metal deployment guide to create an OpenShift cluster.</p>

<p>I hope that you found this article useful and you have your OpenShift 4.1 cluster running by now. If you have any questions or comments please feel free to add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Troubleshooting the Performance of Vert.x Applications, Part I &mdash; The Event Loop Model]]></title>
    <link href="http://alesnosek.com/blog/2019/06/30/troubleshooting-the-performance-of-vert-dot-x-applications-part-i-the-event-loop-model/"/>
    <updated>2019-06-30T10:16:31-07:00</updated>
    <id>http://alesnosek.com/blog/2019/06/30/troubleshooting-the-performance-of-vert-dot-x-applications-part-i-the-event-loop-model</id>
    <content type="html"><![CDATA[<p>This article is the first in a series of three articles which share my experience with troubleshooting the performance of Vert.x applications. The first article provides an overview of the Vert.x event loop model, the second acticle covers techniques to prevent delays on the event loop, and the third article focuses on troubleshooting of event loop delays.</p>

<!-- more -->


<p>Programming with Vert.x requires a good understanding of its event loop model. From what I saw in practice, delayed or blocked event loop threads are the number one contributor to performance problems with Vert.x applications. But don&rsquo;t worry. In this article, we are going to review the event loop model.</p>

<h2>Event loop theads and worker threads</h2>

<p>Depending on how you register your handler with Vert.x APIs, Vert.x will either execute your handler using an event loop thread or a worker thread. There are only these two options in Vert.x. The determination whether the handler is going to be executed on an event loop thread or a worker thread is made at the time you register the handler and doesn&rsquo;t change throughout the lifetime of your application. Take a look at this example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">class</span> <span class="nc">MyVerticle</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">Future</span><span class="o">&lt;</span><span class="n">Void</span><span class="o">&gt;&gt;</span> <span class="n">blockingCodeHandler</span> <span class="o">=</span> <span class="n">future</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// this handler will be executed on a worker thread</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">AsyncResult</span><span class="o">&lt;</span><span class="n">Void</span><span class="o">&gt;&gt;</span> <span class="n">resultHandler</span> <span class="o">=</span> <span class="n">result</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// this handler will be executed on an event loop thread</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">executeBlocking</span><span class="o">(</span><span class="n">blockingCodeHandler</span><span class="o">,</span> <span class="n">resultHandler</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The API call <code>vertx.executeBlocking()</code> registered two handlers. Vert.x will call the <code>blockingCodeHandler()</code> using a worker thread and the <code>resultHandler()</code> using an event loop thread. Because there are restrictions on what code can be executed on event loop threads, you want to structure your code so that it&rsquo;s clear to a casual reader whether a specific piece of code executes on a worker thread or an event loop thread.</p>

<p>Event loop frameworks like Vert.x employ a small amount of event loop threads at their core to do all the computational work. Using a low amount of threads minimizes the need for context switching which leads to a better performance than what a thread-per-request model can achieve.</p>

<blockquote><p>In an ideal situation, your Vert.x application would exclusively use event loop threads.</p></blockquote>

<p>The increased utilization of computing resources resulting in increased performance is a great benefit that event loop frameworks bring to the table. However, there are situations where employing worker threads is inevitable. We are going to show you some examples of such situations in the second article of this series. Just keep in mind that an excessive use of worker threads results in frequent context switching which will impact the overall performance of your application. This context switching negates the benefit of employing event loop frameworks like Vert.x in the first place.</p>

<h2>Taking the event loop for a spin</h2>

<p>The whole purpose of the event loop is to react to events which are delivered to the event loop by the operating system. Event loop processes those events by executing handlers. To explain how the event loop operates, let&rsquo;s imagine a typical HTTP server application serving multiple client connections at the same time. There&rsquo;s data being sent back and forth between the server and the client on each of the connections. And here is how the event loop handles it. First, the event loop waits for any of the events like incoming data available on the connection, or connection is ready to send more data. If any of those events happens, the event loop executes handlers that were registered to handle that specific event. For example, if there is incoming data available, the event loop calls the respective handler that stores the incoming data into a buffer and passes that buffer through a chain of handlers to your handler to process it. Handlers registered with a given event loop are executed one by one because the event loop is a single thread after all. After the processing of the event is finished, event loop returns back to wait for the next event.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/vertx_event_loop.png"></p>

<p>I would like to highlight that the event loop is a single thread that executes the handlers sequentially. In order for this scheme to work smoothly:</p>

<blockquote><p>Handlers should not run code that would delay the event loop.</p></blockquote>

<p>In the case that the application is under full load, the events are queuing up while the event loop is busy executing handlers. In this case, the event loop doesn&rsquo;t really wait for events. Instead, it just picks up the next event and continues with executing handlers straight away.</p>

<p>On the other hand, if the application is idle and there are no events to process, the event loop will wait for events by blocking. It means the event loop thread will relinquish the CPU. Later on when the events arrive, the operating system scheduler will wake up the event loop thread again. Blocking while waiting for events is part of the event loop implementation and it is the only place where the event loop thread is supposed block. In contrast, handlers registered with the event loop  should never issue a blocking call.</p>

<p>On my Linux machine, if I dump a stack trace of an idle event loop thread I will get this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="s">&quot;vert.x-eventloop-thread-0&quot;</span> <span class="err">#</span><span class="mi">13</span> <span class="n">prio</span><span class="o">=</span><span class="mi">5</span> <span class="n">os_prio</span><span class="o">=</span><span class="mi">0</span> <span class="n">tid</span><span class="o">=</span><span class="mh">0x00007f89e0523800</span> <span class="n">nid</span><span class="o">=</span><span class="mh">0x1d67</span> <span class="n">runnable</span> <span class="o">[</span><span class="mh">0x00007f89cc4e0000</span><span class="o">]</span>
</span><span class='line'>   <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Thread</span><span class="o">.</span><span class="na">State</span><span class="o">:</span> <span class="n">RUNNABLE</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollArrayWrapper</span><span class="o">.</span><span class="na">epollWait</span><span class="o">(</span><span class="n">Native</span> <span class="n">Method</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollArrayWrapper</span><span class="o">.</span><span class="na">poll</span><span class="o">(</span><span class="n">EPollArrayWrapper</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">269</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollSelectorImpl</span><span class="o">.</span><span class="na">doSelect</span><span class="o">(</span><span class="n">EPollSelectorImpl</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">93</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">SelectorImpl</span><span class="o">.</span><span class="na">lockAndDoSelect</span><span class="o">(</span><span class="n">SelectorImpl</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">86</span><span class="o">)</span>
</span><span class='line'>        <span class="o">-</span> <span class="n">locked</span> <span class="o">&lt;</span><span class="mh">0x000000076ee73e18</span><span class="o">&gt;</span> <span class="o">(</span><span class="n">a</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">SelectedSelectionKeySet</span><span class="o">)</span>
</span><span class='line'>        <span class="o">-</span> <span class="n">locked</span> <span class="o">&lt;</span><span class="mh">0x000000076ee72be0</span><span class="o">&gt;</span> <span class="o">(</span><span class="n">a</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">Collections$UnmodifiableSet</span><span class="o">)</span>
</span><span class='line'>        <span class="o">-</span> <span class="n">locked</span> <span class="o">&lt;</span><span class="mh">0x000000076ee72ac8</span><span class="o">&gt;</span> <span class="o">(</span><span class="n">a</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollSelectorImpl</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">SelectorImpl</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">SelectorImpl</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">97</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">SelectedSelectionKeySetSelector</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">SelectedSelectionKeySetSelector</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">62</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">NioEventLoop</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">NioEventLoop</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">753</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">NioEventLoop</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">NioEventLoop</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">408</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">SingleThreadEventExecutor$5</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">SingleThreadEventExecutor</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">897</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">FastThreadLocalRunnable</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">FastThreadLocalRunnable</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">30</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Thread</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">Thread</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">748</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Vert.x tool-kit is built on top of <a href="https://netty.io/">Netty</a> framework and the event loop implementation is actually part of Netty. In the stack trace you can see that the Java thread is executing the Netty&rsquo;s event loop code which calls the Java NIO APIs which somewhere in the native code invokes the <code>epoll_wait</code> system call. This system call puts the event loop thread to sleep until the next event arrives.</p>

<p>Interestingly, while blocking in the <code>epoll_wait</code> system call, from the Java standpoint the thread is in a <code>RUNNABLE</code> state and not for example in the state <code>BLOCKED</code> which I would intuitively expect. JVM as an abstraction on top of the operating system has its own <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.State.html">definition of thread states</a>. According to this definition the thread is indeed in the <code>RUNNABLE</code> state even when from the stand point of the operating system it is in the state <em>interruptible sleep</em> and hence blocked.</p>

<h2>Conclusion</h2>

<p>In this article, we familiarized ourselves with the event loop model which is rather different from the thread-per-request model. The <a href="http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays/">next part</a> in the series will cover techniques to prevent delays on the event loop.</p>

<p>Comment below if you found this article helpful or if you have suggestions for future blog subjects.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Speaking at Red Hat Summit 2019]]></title>
    <link href="http://alesnosek.com/blog/2019/04/21/speaking-at-red-hat-summit-2019/"/>
    <updated>2019-04-21T12:41:43-07:00</updated>
    <id>http://alesnosek.com/blog/2019/04/21/speaking-at-red-hat-summit-2019</id>
    <content type="html"><![CDATA[<p>This year&rsquo;s <a href="https://www.redhat.com/en/summit/2019">Red Hat Summit</a> is going to be hosted in Boston on May 7-9, 2019. I will be co-presenting on the topic: <em>Using Domain-driven Design to Reimagine Monolithic Applications in a World of Microservices</em>. If you are interested in hearing about how to design monolithic applications in a practical, decomposable, and agile fashion, you can come and see Eric Murphy and myself at the Boston Convention &amp; Exhibition Center on Wednesday, May 8, 10:30 a.m.-11:15 a.m. Feel free to drop by to say hi!</p>

<!-- more -->


<p><strong> Update 05/10/2019 </strong></p>

<p>I enjoyed having the opportunity to be a co-presenter with Eric Murphy at this week’s Red Hat Summit. Discussing DDD, event storming, and why a monolithic architecture can still be the right choice despite the current push for microservices:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/using_ddd.jpeg"></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Remote Debugging of Java Applications on OpenShift]]></title>
    <link href="http://alesnosek.com/blog/2019/02/26/remote-debugging-of-java-applications-on-openshift/"/>
    <updated>2019-02-26T13:08:30-08:00</updated>
    <id>http://alesnosek.com/blog/2019/02/26/remote-debugging-of-java-applications-on-openshift</id>
    <content type="html"><![CDATA[<p>In this article I am going to show you how to attach a debugger and a VisualVM profiler to the Java application running on OpenShift. The approach described here doesn&rsquo;t make use of the <a href="https://jolokia.org/">Jolokia</a> bridge. Instead, we are going to leverage the port-forwarding feature of OpenShift.</p>

<!-- more -->


<p>The whole setup can be divided into three steps:</p>

<ol>
<li>Enable debug and JMX ports on the JVM</li>
<li>Set up port forwarding</li>
<li>Attach debugger and VisualVM to the forwarded ports</li>
</ol>


<p>I am going to use OpenShift v3.11 that I installed using Minishift and a test application built with Java OpenJDK 1.8. This is how the complete setup is going to look like:</p>

<p><img src="http://alesnosek.com/images/posts/remote_debugging_of_java_applications_on_openshift.svg"></p>

<h2>Hello world application</h2>

<p>For those of you who want to follow along, let&rsquo;s set up a test application which we will use for debugging. If you already have your Java application running on OpenShift, you can jump ahead to the next section.</p>

<p>Let&rsquo;s deploy a Hello world application that I found on <a href="https://github.com/vert-x3/vertx-openshift-s2i">GitHub</a>. This application was originally created to demonstrate how to build <a href="https://vertx.io/">Vert.x</a>-based microservices on OpenShift. You can get this application up and running in just two steps.</p>

<p>First, issue this command to build an S2I builder image for Vert.x applications:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc create -f https://raw.githubusercontent.com/vert-x3/vertx-openshift-s2i/master/vertx-s2i-all.json
</span><span class='line'>buildconfig.build.openshift.io/vertx-s2i created
</span><span class='line'>imagestream.image.openshift.io/vertx-centos created
</span><span class='line'>imagestream.image.openshift.io/vertx-s2i created
</span><span class='line'>template.template.openshift.io/vertx-helloworld-maven created
</span></code></pre></td></tr></table></div></figure>


<p>OpenShift started the build of the builder image and you can follow the progress with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc log -f bc/vertx-s2i
</span><span class='line'>
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>Removing intermediate container fc4bff8f426c
</span><span class='line'>Successfully built bd4a858867e9
</span><span class='line'>Pushing image 172.30.1.1:5000/myproject/vertx-s2i:latest ...
</span><span class='line'>Pushed 1/8 layers, 50% <span class="nb">complete</span>
</span><span class='line'>Pushed 2/8 layers, 25% <span class="nb">complete</span>
</span><span class='line'>Pushed 3/8 layers, 38% <span class="nb">complete</span>
</span><span class='line'>Pushed 4/8 layers, 50% <span class="nb">complete</span>
</span><span class='line'>Pushed 5/8 layers, 63% <span class="nb">complete</span>
</span><span class='line'>Pushed 6/8 layers, 97% <span class="nb">complete</span>
</span><span class='line'>Pushed 7/8 layers, 99% <span class="nb">complete</span>
</span><span class='line'>Pushed 8/8 layers, 100% <span class="nb">complete</span>
</span><span class='line'>Push successful
</span></code></pre></td></tr></table></div></figure>


<p>At the end of the build process OpenShift pushed the new image into the integrated Docker registry. Next, we are going to use the builder image to build and run a sample Vert.x application:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc new-app vertx-helloworld-maven
</span><span class='line'>--&gt; Deploying template <span class="s2">&quot;myproject/vertx-helloworld-maven&quot;</span> to project myproject
</span><span class='line'>
</span><span class='line'>     vertx-helloworld-maven
</span><span class='line'>     ---------
</span><span class='line'>     Sample Vert.x application build with Maven
</span><span class='line'>
</span><span class='line'>     * With parameters:
</span><span class='line'>        * <span class="nv">APPLICATION_NAME</span><span class="o">=</span>hello-world
</span><span class='line'>        * <span class="nv">APPLICATION_HOSTNAME</span><span class="o">=</span>
</span><span class='line'>        * <span class="nv">GIT_URI</span><span class="o">=</span>https://github.com/vert-x3/vertx-openshift-s2i.git
</span><span class='line'>        * <span class="nv">GIT_REF</span><span class="o">=</span>master
</span><span class='line'>        * <span class="nv">CONTEXT_DIR</span><span class="o">=</span><span class="nb">test</span>/test-app-maven
</span><span class='line'>        * <span class="nv">APP_OPTIONS</span><span class="o">=</span>
</span><span class='line'>        * <span class="nv">GITHUB_TRIGGER_SECRET</span><span class="o">=</span>EM325a5K <span class="c"># generated</span>
</span><span class='line'>        * <span class="nv">GENERIC_TRIGGER_SECRET</span><span class="o">=</span>CBCcCIWr <span class="c"># generated</span>
</span><span class='line'>
</span><span class='line'>--&gt; Creating resources ...
</span><span class='line'>    buildconfig.build.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    imagestream.image.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    deploymentconfig.apps.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    route.route.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    service <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>--&gt; Success
</span><span class='line'>    Build scheduled, use <span class="s1">&#39;oc logs -f bc/hello-world&#39;</span> to track its progress.
</span><span class='line'>    Access your application via route <span class="s1">&#39;hello-world-myproject.192.168.42.115.nip.io&#39;</span>
</span><span class='line'>    Run <span class="s1">&#39;oc status&#39;</span> to view your app.
</span></code></pre></td></tr></table></div></figure>


<p>You can follow the build logs by issuing the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc log -f bc/hello-world
</span><span class='line'>
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> --- maven-clean-plugin:2.5:clean <span class="o">(</span>default-clean<span class="o">)</span> @ vertx-hello-world ---
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Deleting /opt/app-root/src/source/target
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> BUILD SUCCESS
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Total <span class="nb">time</span>:  1.102 s
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Finished at: 2019-02-26T20:21:57Z
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'>Application jar file is located in /opt/openshift/vertx-app.jar
</span><span class='line'>Files located in the application directory:
</span><span class='line'>total 13216
</span><span class='line'>-rw-r--r--. <span class="m">1</span> default root      <span class="m">286</span> Feb <span class="m">26</span> 20:21 additional_files.md
</span><span class='line'>-rw-r--r--. <span class="m">1</span> default root <span class="m">13525420</span> Feb <span class="m">26</span> 20:21 vertx-app.jar
</span><span class='line'>Pushing image 172.30.1.1:5000/myproject2/hello-world:latest ...
</span><span class='line'>Pushed 0/9 layers, 2% <span class="nb">complete</span>
</span><span class='line'>Pushed 1/9 layers, 11% <span class="nb">complete</span>
</span><span class='line'>Push successful
</span></code></pre></td></tr></table></div></figure>


<p>If everything went fine, you should be able to see the Hello world application running:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc get pod <span class="p">|</span> grep hello-world
</span><span class='line'>hello-world-1-build   0/1       Completed    <span class="m">0</span>          6m
</span><span class='line'>hello-world-1-dw5lf   1/1       Running      <span class="m">0</span>          42s
</span></code></pre></td></tr></table></div></figure>


<h2>Enabling Debug and JMX ports on JVM</h2>

<p>In the following, I am going to use OpenJDK 1.8. Note that the available JVM options may vary depending on the version of Java  platform you are using.</p>

<p>To enable a remote debug port on JVM, one has to pass the following option to the JVM:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-agentlib:jdwp=transport=dt_socket,server=y,address=8000,suspend=n</span></code></pre></td></tr></table></div></figure>


<p>In order to enable JMX, the following JVM options are needed:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-Dcom.sun.management.jmxremote=true
</span><span class='line'>-Dcom.sun.management.jmxremote.port=3000
</span><span class='line'>-Dcom.sun.management.jmxremote.rmi.port=3001
</span><span class='line'>-Djava.rmi.server.hostname=127.0.0.1
</span><span class='line'>-Dcom.sun.management.jmxremote.authenticate=false
</span><span class='line'>-Dcom.sun.management.jmxremote.ssl=false</span></code></pre></td></tr></table></div></figure>


<p>This set of options deserves a bit more explanation. By default, JMX utilizes RMI as the underlying technology for the communication between the JMX client and the remote JVM. And as a matter of fact, there are two RMI ports needed for this communication:
* RMI registry port
* RMI server port</p>

<p>At the beginning, the client connects to the RMI registry on port 3000 and looks up the connection to the RMI server. After the successful lookup, the client initiates a second connection to the RMI server. Based on our configuration, the client is going to connect to 127.0.0.1:3001. However, there&rsquo;s no RMI server running on the local machine, so what&rsquo;s the deal? As you will see in the next section, we are going to forward the local port 3001 back to the remote server.</p>

<p>Next, we need to convey our configuration options to the JVM running inside the OpenShift pod. It turns out that there exists an environment variable <code>JAVA_TOOL_OPTIONS</code> that is interpreted directly by the JVM and where you can put your JVM configuration options. I recommend using this variable as there is a great chance that this variable will work no matter how deep in your wrapper scripts you are launching the JVM. Go ahead and modify the DeploymentConfig or Pod descriptor of your application in OpenShift to add the <code>JAVA_TOOL_OPTIONS</code> variable. For example, you can open the DeloymentConfig for editing like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc edit dc hello-world
</span></code></pre></td></tr></table></div></figure>


<p>&hellip; and add the <code>JAVA_TOOL_OPTIONS</code> environment variable to the container section of the specification:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>...
</span><span class='line'>
</span><span class='line'>    spec:
</span><span class='line'>      containers:
</span><span class='line'>      - env:
</span><span class='line'>        - name: JAVA_TOOL_OPTIONS
</span><span class='line'>          value: -agentlib:jdwp=transport=dt_socket,server=y,address=8000,suspend=n
</span><span class='line'>            -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=3000
</span><span class='line'>            -Dcom.sun.management.jmxremote.rmi.port=3001 -Djava.rmi.server.hostname=127.0.0.1
</span><span class='line'>            -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
</span><span class='line'>
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>After applying the above changes, OpenShift will redeploy the application pod. At startup, JVM will print out the following line to the stderr which will show up in the container logs:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc logs dc/hello-world <span class="p">|</span> grep JAVA_TOOL_OPTIONS
</span><span class='line'>Picked up JAVA_TOOL_OPTIONS: -agentlib:jdwp<span class="o">=</span><span class="nv">transport</span><span class="o">=</span>dt_socket,server<span class="o">=</span>y,address<span class="o">=</span>8000,suspend<span class="o">=</span>n -Dcom.sun.management.jmxremote<span class="o">=</span><span class="nb">true</span> -Dcom.sun.management.jmxremote.port<span class="o">=</span><span class="m">3000</span> -Dcom.sun.management.jmxremote.rmi.port<span class="o">=</span><span class="m">3001</span> -Djava.rmi.server.hostname<span class="o">=</span>127.0.0.1 -Dcom.sun.management.jmxremote.authenticate<span class="o">=</span><span class="nb">false</span> -Dcom.sun.management.jmxremote.ssl<span class="o">=</span><span class="nb">false</span>
</span></code></pre></td></tr></table></div></figure>


<p>This verifies that our JVM options are in effect and the debug port and JMX ports are open. How are we going to connect to these ports? Let&rsquo;s set up port forwarding on the local machine next.</p>

<h2>Setting up port forwarding</h2>

<p>OpenShift features <a href="https://docs.okd.io/latest/dev_guide/port_forwarding.html">port forwarding</a> that allows you to connect to an arbitrary port of a pod running on OpenShift. Port forwarding doesn&rsquo;t require you to define any additional objects like Service or Route to enable it. What you need though is to start a port forwarding proxy on your local machine. Issue the following command on your local machine to start the proxy and forward the three ports 8000, 3000, and 3001 to the remote pod running on OpenShift:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc port-forward &lt;POD&gt; <span class="m">8000</span> <span class="m">3000</span> 3001
</span></code></pre></td></tr></table></div></figure>


<p>In the above command, remember to replace <code>&lt;POD&gt;</code> with the name of your application pod. If everything worked well, you should see the following output :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc port-forward hello-world-2-55zlq <span class="m">8000</span> <span class="m">3000</span> 3001
</span><span class='line'>Forwarding from 127.0.0.1:8000 -&gt; 8000
</span><span class='line'>Forwarding from 127.0.0.1:3000 -&gt; 3000
</span><span class='line'>Forwarding from 127.0.0.1:3001 -&gt; 3001
</span></code></pre></td></tr></table></div></figure>


<p>Note that the proxy keeps running on the foreground.</p>

<h2>Attaching to the JVM running on OpenShift</h2>

<p>Having our port-forwarding proxy all set, let&rsquo;s fire up a debugger and attach it to our application. Note that we instruct the debugger to connect to the localhost on port 8000. This port is in turn forwarded to the port 8000 on the JVM:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>jdb -connect com.sun.jdi.SocketAttach:hostname<span class="o">=</span>localhost,port<span class="o">=</span>8000
</span></code></pre></td></tr></table></div></figure>


<p>After the debugger attaches, you can list existing JVM threads using the <code>threads</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>> threads
</span><span class='line'>Group system:
</span><span class='line'>  (java.lang.ref.Reference$ReferenceHandler)0x133a                                             Reference Handler                                   cond. waiting
</span><span class='line'>  (java.lang.ref.Finalizer$FinalizerThread)0x133b                                              Finalizer                                           cond. waiting
</span><span class='line'>  (java.lang.Thread)0x133c                                                                     Signal Dispatcher                                   running
</span><span class='line'>  (java.lang.Thread)0x133d                                                                     RMI TCP Accept-3001                                 running
</span><span class='line'>  (java.lang.Thread)0x133e                                                                     RMI TCP Accept-3000                                 running
</span><span class='line'>  (java.lang.Thread)0x133f                                                                     RMI TCP Accept-0                                    running
</span><span class='line'>Group main:
</span><span class='line'>  (java.util.TimerThread)0x1342                                                                vertx-blocked-thread-checker                        cond. waiting
</span><span class='line'>  (io.vertx.core.impl.VertxThread)0x1343                                                       vert.x-worker-thread-0                              cond. waiting
</span><span class='line'>
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>Next, let&rsquo;s check out if we can attach <a href="https://visualvm.github.io/">VisualVM</a> to our application as well:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>visualvm --openjmx localhost:3000
</span></code></pre></td></tr></table></div></figure>


<p>Works like a charm, doesn&rsquo;t it?</p>

<p><img src="http://alesnosek.com/images/posts/visualvm_attached.png"></p>

<h2>Conclusion</h2>

<p>In this blog post, we were able to attach a debugger and VisualVM to the Java application running on OpenShift. We didn&rsquo;t need to deploy Jolokia proxy or create additional Service or Route objects to make our setup work. Instead, we leveraged the port-forwarding feature already available in OpenShift. The demonstrated method has additional security benefits as we are not exposing any additional ports of the application container.</p>

<p>Hope you enjoyed this article and was able to reproduce this setup for yourself. If you have any thoughts or questions feel free to add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Comparing OpenAPI with gRPC]]></title>
    <link href="http://alesnosek.com/blog/2019/01/25/comparing-openapi-with-grpc/"/>
    <updated>2019-01-25T15:22:46-08:00</updated>
    <id>http://alesnosek.com/blog/2019/01/25/comparing-openapi-with-grpc</id>
    <content type="html"><![CDATA[<p>Are you still coding your API client libraries by hand? Is your manually maintained API documentation drifting away from what was actually implemented? You may be interested in reviewing the two popular technologies that solve this problem. In this article, we are going to look at OpenAPI and gRPC side-by-side.</p>

<!-- more -->


<p>Both OpenAPI and gRPC are communication technologies very much needed in the today&rsquo;s world of microservices applications. They allow you to describe your APIs using  a formal language. This description then serves as a source of truth from which you can generate the client and server code and API documentation. As there are two viable alternatives, the question is which one is going to work better for you? As I was trying to answer the same question I did some research on the Internet and came up with a comparison table. I didn&rsquo;t include every single detail, however, this table could perhaps be a good starting point for you:</p>

<table>
<thead>
<tr>
<th> Criteria </th>
<th> OpenAPI </th>
<th> gRPC </th>
</tr>
</thead>
<tbody>
<tr>
<td> Origins </td>
<td> <a href="https://www.openapis.org/">OpenAPI</a> evolved from the <a href="https://swagger.io/">Swagger</a> project. Swagger started out as a specification for documenting RESTful APIs. Later on, tools to generate client and server code and generating of test-cases were added. While the original Swagger Specification was donated to the <a href="https://linuxfoundation.org">Linux Foundation</a> and renamed the OpenAPI,  Swagger remains one of the most widely used open source tool sets for developing OpenAPIs. </td>
<td> <a href="https://grpc.io/">gRPC</a> was originally developed at Google. Later on, it was donated to <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a>. </td>
</tr>
<tr>
<td> Communication Protocol </td>
<td> OpenAPI uses HTTP/1.1 protocol for transport. For the data representation, JSON is generally assumed. </td>
<td> gRPC uses HTTP/2 protocol for transport and <a href="https://developers.google.com/protocol-buffers/">Protocol Buffers</a> as a serialization format. </td>
</tr>
<tr>
<td> API Description Format </td>
<td> Developers describe their APIs using JSON or YAML documents that follow the <a href="https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md">OpenAPI Specification</a> schema. You can find a large archive of sample OpenAPI descriptions at <a href="https://apis.guru/openapi-directory/">apis.guru/openapi-directory</a>. </td>
<td> APIs are described using <code>.proto</code> files written in a <a href="https://developers.google.com/protocol-buffers/docs/proto3">Protocol Buffer Language</a>. </td>
</tr>
<tr>
<td> Description Style </td>
<td> REST APIs are described using HTTP verbs and URIs. Each URI represents a resource in your system, and the HTTP verbs represent actions you take on your resources. <br/><br/> REST APIs use <a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP status codes</a> to signalize the results of the operation invocations. As the HTTP status codes were primarily meant to convey the results of the transport operations, the mapping of status codes to the results of your API functions may be a bit loose. </td>
<td> With gRPC, you can describe your API in terms of methods or procedures. However, if a lot of methods are added over time, the end result can be a complex and confusing API due to the fact that developers must understand what each method does individually. Instead, Google suggests to use a <a href="https://cloud.google.com/apis/design/resources">resource-oriented design</a> which applies the REST design principles to gRPC. This results in more comprehensible APIs. Also, if you intend to transcode HTTP/JSON API into gRPC, you will greatly benefit from a gRPC API designed using the resource-oriented approach. <br/><br/> gRPC offers a set of <a href="https://godoc.org/google.golang.org/grpc/codes">error codes</a> that are well suited to describe the outcome of API operations. </td>
</tr>
<tr>
<td> Client and Server Code Generation </td>
<td>  There are several tools for generating code based on the OpenAPI description. The most widely used code generation project is <a href="https://swagger.io/tools/swagger-codegen/">Swagger Codegen</a>. Other projects include <a href="https://github.com/Azure/autorest">AutoRest</a> and <a href="https://github.com/capitalone/oas-nodegen">oas-nodegen</a>. </td>
<td> gRPC comes with a modular code generator called <em>protoc</em>. Each supported language is implemented as a separate plugin. The code generator was part of the gRPC project from its inception. </td>
</tr>
<tr>
<td> Interactive Documentation </td>
<td> <a href="https://swagger.io/tools/swagger-ui/">Swagger UI</a> is a great tool to visualize your API and execute test requests against your API. </td>
<td> <a href="https://github.com/sourcegraph/prototools">prototools</a> and <a href="https://github.com/pseudomuto/protoc-gen-doc">protoc-gen-doc</a> can generate documentation based on your <code>.proto</code> files. </td>
</tr>
<tr>
<td> Tooling </td>
<td> <a href="https://swagger.io/">Swagger Tools</a>, <a href="https://curl.haxx.se/">curl</a>, <a href="https://www.getpostman.com/">Postman</a>, web browsers, <a href="https://www.tcpdump.org/">tcpdump</a>, <a href="https://www.wireshark.org/">Wireshark</a> </td>
<td> <a href="https://github.com/grpc-ecosystem/awesome-grpc">Awesome gRPC</a>, <a href="https://github.com/fullstorydev/grpcurl">gRPCurl</a>. At the time of this writing, Wireshark supports gRPC only partially. </td>
</tr>
<tr>
<td> Performance </td>
<td> HTTP/1.1 protocol is a request/response protocol. When sending multiple requests over a single TCP connection, the next request can only be sent after the response to the previous request was received. This would normally result in a poor performance especially on the connections with higher latency. To increase the performance, HTTP client opens multiple TCP connections to a single server and sends multiple HTTP requests in parallel. New connections are opened as they are needed. As establishing a new TCP connection is associated with a cost, clients implement <em>connection pooling</em> to reuse the existing TCP connections. Remember to tune the clients connection pool to achieve good performance. <br/><br/> Some HTTP clients/servers may support HTTP/1.1 <em>pipelining</em>. Each HTTP request over the TCP connection may be made immediately without waiting for the previous request&rsquo;s response to return. As request responses must be returned in the order requested, this is prone to head of line blocking. <br/><br/> HTTP/1.1 is a text-based protocol and JSON is a text-based serialization format which hurts the performance. </td>
<td> By default HTTP/2 client opens a single TCP connection to the server and multiplexes multiple requests on this connection. Requests and responses are split into chunks and can be returned in an intermingled fashion. This prevents the head of line blocking that HTTP/1.1 pipelining may suffer from. In addition to that, the client can open multiple HTTP/2 connections to a single server and implement connection pooling. However, it is common to use a single TCP connection only. <br/><br/> HTTP/2 is a binary protocol. Also, according to <a href="https://medium.com/apis-and-digital-transformation/openapi-and-grpc-side-by-side-b6afb08f75ed">this</a> article by Tim Burks of Google, the Protocol Buffers binary format can be orders of magnitude faster to read than corresponding JSON serializations. <br/><br/> Overall, gRPC offers a better performance than OpenAPI. </td>
</tr>
<tr>
<td> Overall Summary </td>
<td> OpenAPI offers a great interoperability due to leveraging widely used HTTP/1.1 protocol and the JSON format. There is a great amount of tools available that will work with OpenAPI-based interfaces. </td>
<td> If you are looking for maximum performance, gRPC is a great choice for you. Also, HTTP/2 protocol is gradually gaining market share. Why not start using it today? </td>
</tr>
</tbody>
</table>


<h2>Where to go from here?</h2>

<p>The comparison table in the previous section highlights only the basic characteristics of OpenAPI and gRPC. I constructed the table based on many great articles that I found on the web. If you are interested in further details on how OpenAPI and gRPC compares I recommend to you to visit the following references:</p>

<ul>
<li><a href="https://medium.com/apis-and-digital-transformation/openapi-and-grpc-side-by-side-b6afb08f75ed">OpenAPI and gRPC Side-by-Side</a></li>
<li><a href="https://sookocheff.com/post/api/swagger-thrift-or-grpc/">Comparing Swagger with Thrift or gRPC</a></li>
<li><a href="https://code.tutsplus.com/tutorials/rest-vs-grpc-battle-of-the-apis--cms-30711">REST vs. gRPC: Battle of the APIs</a></li>
<li><a href="http://www.andrewconnell.com/blog/grpc-and-protocol-buffers-an-alternative-to-rest-apis-and-json">gRPC and Protocol Buffers: an Alternative to REST APIs and JSON</a></li>
<li><a href="https://www.sajari.com/blog/grpc-and-displacement-of-rest-apis">gRPC and the displacement of REST-based APIs</a></li>
<li><a href="https://improbable.io/games/blog/grpc-web-moving-past-restjson-towards-type-safe-web-apis">gRPC-Web: Moving past REST+JSON towards type-safe Web APIs</a></li>
<li><a href="https://husobee.github.io/golang/rest/grpc/2016/05/28/golang-rest-v-grpc.html">REST v. gRPC</a></li>
<li><a href="https://blogs.dropbox.com/tech/2019/01/courier-dropbox-migration-to-grpc/">Courier: Dropbox migration to gRPC</a></li>
</ul>


<h2>Combining OpenAPI and gRPC</h2>

<p>Do you have to use either OpenAPI or gRPC? If you like the awesome performance offered by gRPC but still need to provide REST interfaces to the external third-party clients there is a solution for you. You can leverage one of the proxies (<a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/http_filters/grpc_json_transcoder_filter">Envoy</a>,  <a href="https://github.com/grpc-ecosystem/grpc-gateway">grpc-gateway</a>) that can transcode the REST interface into gRPC. If you design your gRPC interfaces in a <a href="https://cloud.google.com/apis/design/resources">resource-oriented</a> fashion the transcoding process is straight forward. The resulting system architecture may look like this:</p>

<p><img src="http://alesnosek.com/images/posts/comparing_openapi_with_grpc.svg"></p>

<p>The third-party REST client talks to the proxy using HTTP/JSON. Client requests are transcoded on-the-fly into gRPC requests. After the requests are processed, the resulting responses are transcoded from gRPC back to HTTP/JSON and delivered to the client.</p>

<h2>Conclusion</h2>

<p>In this blog post, we compared the basic characteristics of OpenAPI and gRPC. OpenAPI is a great choice due to its interoperability. On the other hand, gRPC offers a better performance. However, you don&rsquo;t have to choose one or the other. You can happily combine both technologies in a single system.</p>

<p>I hope you enjoyed this article. If you are looking into OpenAPI or gRPC I would be happy to hear about your thoughts. Please, feel free to leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Tips for Passing the Red Hat Certified Specialist in Gluster Storage Administration Exam]]></title>
    <link href="http://alesnosek.com/blog/2018/12/28/tips-for-passing-the-red-hat-certified-specialist-in-gluster-storage-administration-exam/"/>
    <updated>2018-12-28T11:24:40-08:00</updated>
    <id>http://alesnosek.com/blog/2018/12/28/tips-for-passing-the-red-hat-certified-specialist-in-gluster-storage-administration-exam</id>
    <content type="html"><![CDATA[<p>Recently I passed the <a href="https://www.redhat.com/en/services/training/ex236-red-hat-certified-specialist-in-gluster-storage-administration-exam">Red Hat Certified Specialist in Gluster Storage Administration</a> exam. In this blog post, I would like to share some of my experience and exam tips with you.</p>

<!-- more -->


<p>There are two major open-source storage technologies available today: <a href="https://ceph.com/">Ceph</a> and <a href="https://www.gluster.org/">Gluster</a>. For a couple of years, I used Ceph as a provider of a block and object storage for an OpenStack cluster with great success. I was curious to learn about what Gluster has to offer. To explore Gluster, I leveraged the training materials and labs included in my <a href="https://www.redhat.com/en/services/training/learning-subscription">Red Hat Learning Subscription</a>. Also, to give myself a particular goal to achieve, I signed up for the Red Hat Certified Specialist in Gluster Storage Administration exam. The main topics included on the exam are creating different types of Gluster volumes, volume snapshotting, exporting Gluster volumes via highly-available NFS and Samba, asynchronous replication (geo-replication), tiered volumes and transport security.</p>

<p>As I was working through the learning materials for the first time, I used the provided virtual machines to solve the lab exercises. I liked that after I completed the exercise I could run a grading script that would check my configuration and to see if anything was still missing. However, after I realized that setting up a Gluster cluster from scratch doesn&rsquo;t take much effort, I decided to spin up my own practice environment. I created three virtual machines (2 GB RAM, 4 vCPUs) on my laptop using libvirt/QEMU/KVM and installed CentOS 7 and Gluster 4.1. The software on the real exam is RHEL 7 and Gluster 3, however, it didn&rsquo;t make much difference to me. Switching to my custom practice environment removed the perceived latency while typing and allowed me to easily copy and paste between console windows. In addition to that, I could keep my virtual machines running all the time. Virtual machines in the lab environment provided by Red Hat shutdown automatically after two hours unless you bump up the timer.</p>

<p>If you are preparing for the Gluster certification exam, here are several things that are good to know:</p>

<ul>
<li>The complete <a href="https://access.redhat.com/documentation/en-us/red_hat_gluster_storage">Red Hat Gluster Storage documentation</a> is available to you during the exam in a searchable PDF format. The Red Hat Gluster Storage Administration Guide turned out to be particularly useful. I recommend reading through the guide as a part of the preparation for the exam. You will learn where the important configuration parts are located in the guide and will be able to quickly refer to them during the exam.</li>
<li>Preparing underlying LVM volumes for Gluster bricks takes quite a bit of time which you won&rsquo;t have plenty of in the exam. Here is my advice: at the beginning of the exam, walk through the exam tasks and create all the LVM volumes that you will need up front.</li>
<li>Command <code>gluster volume set help</code> lists all the Gluster volume parameters along with their short descriptions. If you cannot remember the exact parameter name just grep through the output of this command.</li>
<li>If you cannot remember the Gluster mount options, you can find them by typing <code>man mount.glusterfs</code></li>
<li>Provisioning of LVM thin volumes is thoroughly documented in <code>man lvmthin</code></li>
<li>To list all services that you can enable on the firewall, type <code>firewall-cmd --get-services</code></li>
<li>To find out whether SELinux denied access, issue the command  <code>grep denied /var/log/audit/audit.log</code>. SELinux can provide a hint on how to possibly solve the access issue, use the command <code>sealert -a /var/log/audit/audit.log</code></li>
<li>To list SELinux types related to Gluster, you can type <code>strings /sys/fs/selinux/policy | grep gluster</code></li>
<li>And last but not least, you can list volumes exported by the NFS server with <code>showmount -e &lt;HOST&gt;</code>. To show volumes available on a Samba server, issue the command <code>smbclient -L &lt;HOST&gt; -U %</code></li>
</ul>


<p>And how did I do on the exam? Well, I would not say that the exam was difficult, however, I also didn&rsquo;t practice much before the exam. Unfortunately, I ran out of time before I could complete the last exam task. Overall, I achieved 236 points out of 300. As the passing score was 210, I did pass!</p>

<p>Are you preparing for the Red Hat Gluster Storage exam? I would love to hear from you! Please, leave your comments or questions in the comment section below.</p>

<p><img src="http://alesnosek.com/images/posts/rhcs_gluster_storage_administration_badge.png"></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Speaking at the Red Hat Training Partner &amp; Instructor Conference]]></title>
    <link href="http://alesnosek.com/blog/2018/09/24/speaking-at-the-red-hat-training-partner-and-instructor-conference/"/>
    <updated>2018-09-24T08:47:00-07:00</updated>
    <id>http://alesnosek.com/blog/2018/09/24/speaking-at-the-red-hat-training-partner-and-instructor-conference</id>
    <content type="html"><![CDATA[<p>On September 21, 2018 I spoke at the <a href="https://www.redhat.com/en/events/training-partner-conference-emea">Red Hat Training Partner &amp; Instructor Conference</a> in Prague, Czech Republic. Why was I invited, and what did I learn? Read on if you want to find out.</p>

<!-- more -->


<h2>Why was I invited to speak at this conference?</h2>

<p>In this conference, Red Hat shares updates on their learning and certification programs, as well as the current status and trends. This conference is geared towards Red Hat’s training partners, instructors, and Red Hat Academy representatives.</p>

<p>To date, one of my most popular blog posts has been <a href="http://alesnosek.com/blog/2017/08/01/how-i-became-a-red-hat-certified-architect-in-one-year/">How I Became a Red Hat Certified Architect in One Year</a>. In this post I described my path through the Red Hat certification process, using the Red Hat Learning Subscription (<a href="https://www.redhat.com/en/services/training/learning-subscription">RHLS</a>), to achieve the Red Hat Certified Architect title. As a result of this, the conference organizers invited me to speak and give a customer testimonial about my experience.</p>

<h2>What did I talk about?</h2>

<p>I shared a little bit about my background, my personal certification path using the RHLS, offered a couple of suggestions for improvement of RHLS, and also listed reasons why I would recommend the RHLS to others:</p>

<ul>
<li>Quality learning materials (concise yet complete)</li>
<li>Access to the training lab (closely resembles the exam environment)</li>
<li>Was able to learn at my own pace - flexibility</li>
<li>Designed for remote access which was much more convenient for me than attending classes</li>
<li>Cost effectiveness</li>
<li>After becoming RHCA I used RHLS to evaluate other Red Hat products</li>
</ul>


<h2>What did I learn at the conference?</h2>

<p>I learned that Red Hat builds their learning platform themselves. Additionally, changes have been made such that the proctoring of the exams will be handled directly by Red Hat, instead of leveraging a third party.</p>

<p>Red Hat has updated the score report emails to include the breakdown by topic areas. This could be especially helpful for those who were unsuccessful in their exam attempt and need more information about what to focus on before retaking the exam.</p>

<p>The Red Hat Certified Architect certification has been divided in to two different certifications, Red Hat Certified Architect in Infrastructure and Red Hat Certified Architect in Enterprise Applications. This change is well documented <a href="https://servicesblog.redhat.com/2018/08/20/red-hat-certified-architect-program-changes/">here</a>. I would like to point out that those of you who achieved the RHCA already, can log into your Red Hat account and download your certificate with the updated title.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[How I Achieved the AWS Associate Certifications]]></title>
    <link href="http://alesnosek.com/blog/2018/08/30/how-i-achieved-the-aws-associate-certifications/"/>
    <updated>2018-08-30T23:20:27-07:00</updated>
    <id>http://alesnosek.com/blog/2018/08/30/how-i-achieved-the-aws-associate-certifications</id>
    <content type="html"><![CDATA[<p>Over the course of the last year I was working towards transitioning our company’s products to the AWS cloud. I gained a solid experience with many of the AWS services, wrote lots of lines of CloudFormation code, and embraced AWS reference architectures and best practices. To round up my AWS experience I thought that accomplishing some certifications would be a good idea. In this post, I am going to share with you how I achieved the AWS associate certifications.</p>

<!-- more -->


<p><a href="https://aws.amazon.com/certification/">AWS certifications</a> are divided into three levels of difficulty: foundational, associate, and professional. The foundational level is optional. If you worked with AWS cloud hands-on for several months, I would recommend skipping the foundational level and start your certification path at the associate level. The associate level comes with three certification options: Solutions Architect, Developer, and SysOps Administrator. In order to achieve a specific certification, you have to pass the respective multiple-choice test. As the requirements for the three tests highly overlap, I decided to study for all three certifications at the same time.</p>

<p>AWS certification is rather popular these days. It&rsquo;s no wonder that there is an abundance of preparation materials available. So, which one should you choose? I started off by reading the three official study guides:</p>

<ul>
<li><a href="https://www.amazon.com/Certified-Solutions-Architect-Official-Study/dp/1119138558">AWS Certified Solutions Architect Official Study Guide: Associate Exam</a></li>
<li><a href="https://www.amazon.com/Certified-SysOps-Administrator-Official-Study/dp/1119377420">AWS Certified SysOps Administrator Official Study Guide: Associate Exam</a></li>
<li><a href="https://www.amazon.com/Certified-Advanced-Networking-Official-Study-ebook/dp/B079VKD1CN">AWS Certified Advanced Networking Official Study Guide: Specialty Exam</a></li>
</ul>


<p>The three study guides are well organized and go beyond the associate exam requirements. I would recommend reading them even when you don&rsquo;t plan to get certified as they provide a good source of information about AWS in general.</p>

<p>In addition to reading the books, I made use of the AWS training courses offered by <a href="https://acloud.guru/courses?vendors=aws">A Cloud Guru</a>. I watched most of the videos from the Solutions Architect course and some of the videos from the SysOps Administrator course. I enjoyed the presentation style of Ryan Kroonenburg a lot and appreciated the practical demonstrations on AWS and the included exam tips. As I didn&rsquo;t really want to spend the time watching all the videos, I used ffmpeg to extract the audio tracks and listened to the courses while driving or being in the gym. Besides the training courses by A Cloud Guru, people also recommend the AWS courses offered by <a href="https://linuxacademy.com/amazon-web-services/courses">Linux Academy</a>.</p>

<p>Another useful prep material for the exam is the Jayendra&rsquo;s <a href="http://jayendrapatil.com/aws-certification-exam-cheat-sheet/">AWS Certification Exam Cheat Sheet</a>. It includes study notes as well as sample questions.</p>

<p>Before taking the real exam, I practiced using mock exams. You can find many of them freely available on the Internet. I also used several mock exam applications for Android:</p>

<ul>
<li><a href="https://play.google.com/store/apps/details?id=com.embleton.awstrainer">AWS Certification Stress-Free: RocketPrep</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.magycbytes.aws">AWS Certified Solutions Architect Associate</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.gent.dev.awsninja">AWS Ninja</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.vikashiiit.aws">FREE AWS Practice Quiz - Associates</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.ywdrtt.awssa">PREP AWS Solutions Architect</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.magycbytes.awssys">Test prep. AWS SysOps Administrator - Associate</a></li>
</ul>


<p>Note that the quality of the available prep materials varies and some of the materials may contain errors.</p>

<p>Finally, after I completed my studying, I took the three associate exams. Here are my results:</p>

<ul>
<li>AWS Certified Solutions Architect - Associate exam passed with 89%</li>
<li>AWS Certified Developer - Associate exam passed with 94%</li>
<li>AWS Certified SysOps Administrator - Associate exam passed with 95%</li>
</ul>


<p>If you are preparing to get your AWS certifications, I hope that sharing my experience might have been helpful for you.</p>

<p><a href="https://www.certmetrics.com/amazon/public/badge.aspx?i=1&amp;t=c&amp;d=2018-08-08&amp;ci=AWS00414888"><img src="http://alesnosek.com/images/posts/aws_certified_solutions_architect_associate.png"></a>
<a href="https://www.certmetrics.com/amazon/public/badge.aspx?i=2&amp;t=c&amp;d=2018-08-13&amp;ci=AWS00414888"><img src="http://alesnosek.com/images/posts/aws_certified_developer_associate.png"></a>
<a href="https://www.certmetrics.com/amazon/public/badge.aspx?i=3&amp;t=c&amp;d=2018-08-28&amp;ci=AWS00414888"><img src="http://alesnosek.com/images/posts/aws_certified_sysops_administrator_associate.png"></a></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Four Ansible Practices I Would Recommend]]></title>
    <link href="http://alesnosek.com/blog/2018/06/17/four-ansible-practices-i-would-recommend/"/>
    <updated>2018-06-17T11:25:59-07:00</updated>
    <id>http://alesnosek.com/blog/2018/06/17/four-ansible-practices-i-would-recommend</id>
    <content type="html"><![CDATA[<p><a href="https://www.ansible.com/">Ansible</a> is a popular IT automation tool. In this article, I would like to share with you some of the useful practices we have discovered while using Ansible over the past four years.</p>

<!-- more -->


<h2>Create a separate account for Ansible</h2>

<p><img class="right" src="http://alesnosek.com/images/posts/ansible_logo.png" width="150" height="150"></p>

<p>In order to apply configuration changes, Ansible connects to the target machine via SSH. We prefer to create a dedicated <code>ansible</code> account on each machine managed by Ansible. This account is set up with the required <code>sudo</code> privileges. Password authentication to the <code>ansible</code> account is disabled. Instead, access is managed by adding or removing person&rsquo;s SSH public key to the <code>ansible</code> user&rsquo;s <code>authorized_keys</code> file.</p>

<p>SSH daemon logs the SSH key fingerprint that was used for authentication. That allows us to keep track of who made use of the <code>ansible</code> account. On Red Hat based distros, you can find the access logs in <code>/var/log/secure</code>. Here is a sample log message after I triggered the execution of an Ansible playbook:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2018-06-16T19:33:02.298905-07:00 machine1 sshd[29892]: Accepted publickey for ansible from 10.0.0.253 port 54600 ssh2: RSA f4:83:34:8f:f8:7d:29:0e:40:65:b9:bc:a0:bb:eb:d0</span></code></pre></td></tr></table></div></figure>


<p>Furthermore, any time Ansible uses <code>sudo</code> to execute a task, an additional log message is appended to the <code>/var/log/secure</code> log file on the target machine. We found that for the auditing purposes the generated logs are sufficient.</p>

<p>In the cloud, we either use custom images that already contain the <code>ansible</code> account or we create the <code>ansible</code> account on the first boot using a cloud-init script. Using a dedicated <code>ansible</code> account instead of the <code>ec2-user</code>, <code>cloud-user</code>, <code>centos</code> and other image accounts streamlines our management efforts.</p>

<h2>Report changes made on the target machine accurately</h2>

<p>When Ansible executes a playbook, it highlights all configuration changes made to the target machine while bringing it to the desired state described in the playbook. Administrator can review the reported changes to verify that they meet his expectations.  If no changes had to be made to the target machine, Ansible should report <code>changed=0</code> after the playbook execution completes.</p>

<p>When executing Ansible <code>command</code> module or <code>shell</code> module, there&rsquo;s no good way for Ansible to know whether the executed command or shell script made any changes to the target machine. Here we can help ourselves with a neat trick that I will explain on the following example.  Imagine that we want to create a new InfluxDB database:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>- name: Create a database in InfluxDB
</span><span class='line'>  shell: |
</span><span class='line'>    set -e
</span><span class='line'>    if ! influx -execute 'show databases' | grep {{ database_name }}; then
</span><span class='line'>      influx -execute 'create database {{ database_name }}'
</span><span class='line'>    fi</span></code></pre></td></tr></table></div></figure>


<p>The above task creates a new InfluxDB database in the case that it doesn&rsquo;t already exist. The problem with the above code is that Ansible will always mark this task as changed. In order to report the change status accurately, let&rsquo;s leverage Ansible&rsquo;s <code>changed_when</code> directive:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>- name: Create a database in InfluxDB
</span><span class='line'>  shell: |
</span><span class='line'>    set -e
</span><span class='line'>    if ! influx -execute 'show databases' | grep {{ database_name }}; then
</span><span class='line'>      influx -execute 'create database {{ database_name }}'
</span><span class='line'>      echo CHANGED
</span><span class='line'>    fi
</span><span class='line'>  register: create_database
</span><span class='line'>  changed_when: create_database.stdout | search("CHANGED")</span></code></pre></td></tr></table></div></figure>


<p>We modified the shell script to print <code>CHANGED</code> to the standard output if and only if a new InfluxDB database has been created. Next, we captured the entire standard output of the shell script in the <code>create_database</code> variable using the Ansible&rsquo;s <code>register</code> directive. Lastly, we search the content of the <code>create_database</code> variable for the <code>CHANGED</code> keyword. If the <code>CHANGED</code> keyword is found, Ansible will mark the task as changed.</p>

<p>It would be great if Ansible would come up with a mechanism to determine whether a shell script made changes to the target machine or not. In the meanwhile, the above pattern works very well for us.</p>

<h2>Skip completed tasks</h2>

<p>Ansible playbook may be executed multiple times against the same target machine. During each run Ansible must be able to determine which tasks should be executed and which tasks should be skipped because they were already completed in the previous run. Think about the scenario where we are configuring a Docker storage. In the following code, we are invoking the <code>docker-storage-setup</code> command on the target machine:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>- name: Run the Docker storage configurator
</span><span class='line'>  command: docker-storage-setup
</span><span class='line'>  become: yes</span></code></pre></td></tr></table></div></figure>


<p>If you would run the above command the second time, it would fail because the Docker storage has already been configured. How to ensure that the above task will run only once? Ansible&rsquo;s <code>command</code> module provides <code>creates</code> and <code>removes</code> parameters that instruct Ansible to only run the <code>command</code> task if a specific file does or doesn&rsquo;t exist on the file system. The idea is that the executed command creates or deletes these files. Could these parameters help us here? While these parameters can save you in many cases, we would like to avoid using them in this situation. Firstly, we would have to go and figure out whether the <code>docker-storage-setup</code> script creates or removes any file. Secondly, the location of the created or removed file may depend on the chosen storage driver which would demand extending our script with additional logic. And lastly, there is no guarantee that the future versions of the <code>docker-storage-setup</code> script would manipulate the same file which could cause our Ansible script to break. As an alternative, here is a pattern that a software practitioner can use in such a situation:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>- name: Check the docker_storage_initialized stamp
</span><span class='line'>  stat: path=docker_storage_initialized
</span><span class='line'>  register: storage_initialized
</span><span class='line'>
</span><span class='line'>- block:
</span><span class='line'>    - name: Run the Docker storage configurator
</span><span class='line'>      command: docker-storage-setup
</span><span class='line'>      become: yes
</span><span class='line'>
</span><span class='line'>    - name: Create the docker_storage_initialized timestamp
</span><span class='line'>      file: path=docker_storage_initialized state=touch
</span><span class='line'>
</span><span class='line'>  when: not storage_initialized.stat.exists</span></code></pre></td></tr></table></div></figure>


<p>The gist of the above code is simple. After we have successfully configured the Docker storage we create a stamp file. Because the stamp file exists, Ansible will skip the Docker storage configuration in all the following playbook runs. The stamp file is created in a well defined location. Should we want to re-run the Docker storage configuration in the future, we can just remove the stamp file before executing the playbook.</p>

<h2>Backporting Ansible modules</h2>

<p>For the task at hand, it is always preferable to leverage a dedicated Ansible module before falling back on generic <code>command</code> or <code>shell</code> modules. In our Ansible practice, we came into situations where the Ansible module we would like to use was available only in the newer versions of Ansible or that the module in our version of Ansible was buggy. As the interface between Ansible core and the Ansible modules is pretty stable, here is my advice: just copy the desired module from the newer version of Ansible and drop it into the <code>library</code> directory next to your playbook. This <code>library</code> directory is a location where you can put your custom modules. Moreover, any custom module having the same name will override a module distributed with Ansible. This is how our <code>library</code> directory currently looks like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ls -1 library
</span><span class='line'>nsupdate.py
</span><span class='line'>win_get_url.ps1
</span><span class='line'>win_get_url.py
</span><span class='line'>win_reg_stat.ps1
</span><span class='line'>win_reg_stat.py
</span></code></pre></td></tr></table></div></figure>


<p>We are using Ansible version 2.2.1.0 which doesn&rsquo;t contain <code>nsupdate</code> and <code>win_reg_stat</code> modules. Also, we found the <code>win_get_url</code> module in version 2.2.1.0 to be buggy. Adding a handful of modules to the <code>library</code> directory avoids the need to upgrade to the next version of Ansible. From past experience we know that porting our Ansible code base to the next version of Ansible requires a considerable effort.</p>

<h2>Conclusion</h2>

<p>In this article, we shared some of the Ansible practices we found useful. We recommended to create a dedicated <code>ansible</code> account on each machine that is managed by Ansible. We described how to inform Ansible whether a script did or did not make any changes to the target machine. We showed you how to prevent a repeated execution of Ansible tasks by creating a custom stamp file. Lastly, we demonstrated that backporting Ansible modules is not that complicated as it may sound.</p>

<p>Hope you enjoyed this article. Let me know if you have any comments or suggestions to the presented practices. Feel free to add your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Red Hat Summit 2018]]></title>
    <link href="http://alesnosek.com/blog/2018/05/14/red-hat-summit-2018/"/>
    <updated>2018-05-14T20:07:17-07:00</updated>
    <id>http://alesnosek.com/blog/2018/05/14/red-hat-summit-2018</id>
    <content type="html"><![CDATA[<p>Last week, I had the pleasure of attending Red Hat Summit 2018. It was hosted at the Moscone Center in San Francisco, May 8-10, 2018. I greatly enjoyed this conference and would like to share with you some of the interesting things I learned there.</p>

<!-- more -->


<p>You can view video recordings of the general sessions as well as a selection of the breakout sessions on <a href="https://www.youtube.com/user/redhatsummit">YouTube</a>.</p>

<h2>Major announcements</h2>

<p><a href="https://www.redhat.com/en/about/press-releases/red-hat-and-microsoft-co-develop-first-red-hat-openshift-jointly-managed-service-public-cloud">Red Hat OpenShift on Azure</a>. Red Hat and Microsoft are introducing OpenShift as a fully managed service on Azure. This brings customers the possibility to freely move workloads between their on-premise OpenShift clusters and Azure. Many of the Azure services will be accessible from within OpenShift via the Service Catalog. In the future, Windows containers will be supported alongside Linux containers. Support for Red Hat OpenShift on Azure will be provided by both Red Hat and Microsoft.</p>

<p><a href="https://www.redhat.com/en/about/press-releases/ibm-and-red-hat-join-forces-accelerate-hybrid-cloud-adoption">Red Hat and IBM working toward a hybrid cloud</a>. Red Hat and IBM are expanding their collaboration to bring together enterprise application platforms, Red Hat OpenShift and IBM Cloud Private. IBM&rsquo;s recent move to re-engineer its entire software portfolio with containers, including WebSphere, MQ Series and Db2 will allow it to make this sofware available on the hybrid cloud with IBM Cloud Private and Red Hat OpenShift serving as the common foundation.</p>

<p>Both major announcements go along with the Red Hat&rsquo;s vision of the future being the hybrid cloud. There&rsquo;s no doubt that Red Hat stands behind the hybrid cloud. In one of the general sessions, I heard Red Hat&rsquo;s Paul Cormier saying:</p>

<blockquote><p>Hybrid cloud is the only practical way forward.</p></blockquote>

<h2>Sessions attended</h2>

<ul>
<li><strong>CoreOS and Red Hat</strong>

<ul>
<li>After Red Hat <a href="https://www.redhat.com/en/about/press-releases/red-hat-acquire-coreos-expanding-its-kubernetes-and-containers-leadership">acquired</a> CoreOS in January this year, developers from both companies are busy with merging features of CoreOS Tectonic into Red Hat OpenShift. While CoreOS Tectonic was focused on operators, Red Hat OpenShift was more oriented toward developers. After the merge is completed, Red Hat OpenShift should become a product with a strong appeal to both operators and developers.</li>
<li>OpenShift console will be extended by an Admin console which is based on the Tectonic Console.</li>
<li>OpenShift is embracing the <a href="https://github.com/operator-framework">Operator Framework</a> originally developed by CoreOS. Initially, more than 60 ISVs are planning to provide certified OpenShift operators to end users.</li>
<li>Quay Enterprise is going to be rebranded to Red Hat Quay. It remains a standalone product. Customers with higher demands may prefer leveraging Red Hat Quay in place of the integrated OpenShift image registry.</li>
<li>CoreOS Container Linux and RHEL Atomic Host are going to be merged into a new container operating system called Red Hat CoreOS. Initially, Red Hat CoreOS is going to be based on RHEL 7.5, however, later on Red Hat CoreOS will be updated faster than RHEL.</li>
</ul>
</li>
<li><strong>Next-generation tools for container technology</strong>

<ul>
<li>Dan Walsh discussed several Linux container related tools developed by his team: <a href="https://github.com/kubernetes-incubator/cri-o">CRI-O</a> container runtime, <a href="https://github.com/projectatomic/buildah">Buildah</a>, <a href="https://github.com/projectatomic/skopeo/">Skopeo</a>, and <a href="https://github.com/projectatomic/libpod">Podman</a>. With a certain dose of sarcasm, Dan explained the flaws in the design of the Docker tool -  mainly the unfortunate decision to create a &ldquo;big fat&rdquo; Docker daemon. Podman is a command-line tool that reimplements the Docker functionality without the need for a Docker daemon. In the future, Podman could replace the Docker tool.</li>
</ul>
</li>
<li><strong>Kubernetes and the platform of the future</strong>

<ul>
<li>This was a chat with Clayton Coleman (Chief Engineer for OpenShift) and Brandon Philips (previously CTO of CoreOS, acquired by Red Hat) about the future of Kubernetes and OpenShift projects.</li>
<li>Kubernetes is considered to be a new distributed operating system. &ldquo;We have a deployment target for the open-source community for multiple machines, as we had Linux as a target for a single machine&rdquo;.</li>
</ul>
</li>
<li><strong>Low-risk mono to microservices: Istio, Teiid, and Spring Boot</strong>

<ul>
<li>In this session, I learned about several open-source projects that may come in handy when moving toward a microservice architecture: <a href="http://arquillian.org/">Arquillian</a> is an integration testing framework, <a href="https://istio.io/">Istio</a> is a service mesh, <a href="https://github.com/kiali/kiali">Kiali</a> is an Istio observability project, <a href="https://www.apicur.io/">apicurio</a> is a tool for designing RESTful APIs according to the <a href="https://github.com/OAI/OpenAPI-Specification">OpenAPI</a> specification, <a href="http://teiid.jboss.org/">Teiid</a> is a data virtualization system.</li>
<li>If you want to release your software frequently, monolithic architecture may become a bottleneck. You can begin to break up your monolithic project into microservices to speed up the release process. If you&rsquo;ve gotten to the point where you can go faster, stop breaking things up! You don&rsquo;t want to cross the point of diminishing returns. If there is some monolith left in your project, that&rsquo;s okay.</li>
</ul>
</li>
<li><strong>OpenShift roadmap: You won&rsquo;t believe what&rsquo;s next</strong>

<ul>
<li>Prometheus monitoring system is going to be integrated into OpenShift more deeply. In addition to monitoring, metrics collected by Prometheus are going to be used for container auto healing.</li>
<li>Work is underway for Open Virtual Network (OVN) to become the default OpenShift SDN in the future.</li>
<li>Red Hat is investing in the <a href="https://github.com/kubevirt">KubeVirt</a> project whose goal is to run virtual machines on Kubernetes/OpenShift.</li>
<li>Red Hat is also investing in <a href="https://openwhisk.apache.org/">Apache OpenWhisk</a>. OpenWhisk is a serverless platform allowing to run functions on Kubernetes.</li>
</ul>
</li>
<li><strong>Intelligent applications on OpenShift from prototype to production</strong>

<ul>
<li>OpenShift is entering the big data arena. This was an introductory talk about running Spark on OpenShift for machine learning. If you are interested to run data analysis on OpenShift, check out the <a href="https://radanalytics.io/">rad analytics</a> project.</li>
</ul>
</li>
</ul>


<h2>Some photos from the event</h2>

<p><img class="center" src="http://alesnosek.com/images/posts/redhatsummit2018/keynote.jpeg"></p>

<p>Opening keynote session.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/redhatsummit2018/cruise.jpeg"></p>

<p>Harbor cruise for Red Hat Certified Professionals, including myself ;-)</p>

<p><img class="center" src="http://alesnosek.com/images/posts/redhatsummit2018/sf1.jpeg"></p>

<p><img class="center" src="http://alesnosek.com/images/posts/redhatsummit2018/sf2.jpeg"></p>

<p>San Francisco skyline as viewed from the cruise.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Designing a Common Build System]]></title>
    <link href="http://alesnosek.com/blog/2018/05/03/designing-a-common-build-system/"/>
    <updated>2018-05-03T21:57:40-07:00</updated>
    <id>http://alesnosek.com/blog/2018/05/03/designing-a-common-build-system</id>
    <content type="html"><![CDATA[<p>Code reuse belongs to the basic tenets of software development. Moreover, one should have the same principle in mind when maintaining build scripts. If you are copy-pasting Makefiles and pom.xml files from project to project, stop now and read this article! We are going to discuss how to design a common build system.</p>

<!-- more -->


<p>A good software practitioner avoids having huge chunks of Makefiles, pom.xml files, build.xml files or shell scripts copy-pasted all over the code base. Based on experience, copy-pasted build scripts lead to inconsistencies, build issues and are overall driving the maintenance cost high.</p>

<p>In 2010, we invested heavily in the improvements of our build infrastructure. We introduced a continuous integration server Hudson (remember the project that was later renamed to Jenkins?), added source code analysis tool Sonar (nowadays called SonarQube), embraced RPM packaging and created a set of highly reusable build scripts which we called a common build system. In the next section, I&rsquo;m going to discuss a high-level design and ideas behind the common build system.</p>

<h2>High-level overview</h2>

<p>Our build system supports Java, C++ and C development. The core of the build system comprises of:</p>

<ul>
<li><a href="https://ant.apache.org/">Apache Ant</a> An old-timer between build tools. In current times, writing build scripts in XML is not sexy anymore, however, we like Ant for its simplicity and power. If you cannot express the required functionality using Ant tasks, you can always defer to using an embedded JavaScript. In our Ant scripts, you could find the <code>&lt;script language="javascript"&gt; ... &lt;/script&gt;</code> element that embeds JavaScript in several places.</li>
<li><a href="http://ant.apache.org/ivy/">Apache Ivy</a> Is a very flexible dependency manager that integrates with Apache Ant. While Ivy is predominantly used to manage Java jar files, we use it to manage C/C++ dependencies, too. For that, we zip up the C++ header files and push it along with the C++ shared libraries into the artifact repository.</li>
<li><a href="https://github.com/tumbarumba/AntScriptLibrary">Ant Script Library</a> Writing Ant build scripts from scratch is time consuming. To avoid spending this effort, we embraced Ant Script Library (ASL) which is a collection of re-usable Ant scripts providing a number of pre-defined targets.</li>
<li><a href="https://github.com/dmoulding/boilermake">Boilermake</a> Boilermake is a reusable GNU Make compatible Makefile. It uses a non-recursive strategy which avoids the many well-known pitfalls of recursive make, see also <a href="http://aegis.sourceforge.net/auug97.pdf">Recursive Make Considered Harmful</a>. We leverage Boilermake to compile C/C++ source code. An Ant <code>build.xml</code> wrapper script calls Boilermake when building a C/C++ module.</li>
</ul>


<p>The following diagram illustrates the organization of our code base:</p>

<p><img src="http://alesnosek.com/images/posts/common_build_system.svg" width="600" height="600"></p>

<p>Our code base is divided up into modules. A module contains either Java or C/C++ source code required to build a library or executable. The <code>build-common</code> module is special in that it doesn&rsquo;t contain any source code to compile. Instead, it acts as a container in which we store all our reusable build scripts. The build scripts of other modules import the definitions from the <code>build-common</code> module. Due to high code reuse, the build scripts of individual modules are rather concise. The Ant statement to import the common definitions from the <code>build-common</code> module looks as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;import <span class="nv">file</span><span class="o">=</span><span class="s2">&quot;../../Build/build-common/module.xml&quot;</span> /&gt;
</span></code></pre></td></tr></table></div></figure>


<p>Modules are organized into Git repositories according to the functionality they implement. For instance, modules of a specific product reside in its own Git repository. Furthermore, the <code>Platform</code> repository groups together modules that implement common libraries shared across several products.</p>

<p>All artifacts exported by the individual modules (jars, shared libraries, header files) are shared between the modules via the artifact repository. If additional information needs to be shared between modules, modules can publish Java properties files into the artifact repository which other modules can fetch and import. It was important to us to avoid any direct references between modules on the file system with the exception of the reference to the <code>build-common</code> module. These direct references between modules would be less obvious than passing artifacts and extra information via the artifact repository. We like to keep a good track of the dependencies between our software modules.</p>

<h2>Module directory structure</h2>

<p>Apache Ant does not propose any particular directory structure. However, it is easier to work with modules which have a common structure. Ant Script Library embraces the <a href="https://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html">Standard Directory Layout</a> from Maven project and so we derive our directory structure from this standard. Here is our module directory structure in greater detail:</p>

<table>
<thead>
<tr>
<th style="text-align:left;"> Directory          </th>
<th style="text-align:left;"> Purpose                          </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> src/main/java      </td>
<td style="text-align:left;"> Java application/library sources </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/c++       </td>
<td style="text-align:left;"> C++ application/library sources  </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/c         </td>
<td style="text-align:left;"> C application/library sources    </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/resources </td>
<td style="text-align:left;"> Application/library resources    </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/scripts   </td>
<td style="text-align:left;"> Application/library scripts      </td>
</tr>
<tr>
<td style="text-align:left;"> src/test/java      </td>
<td style="text-align:left;"> Java test sources                </td>
</tr>
<tr>
<td style="text-align:left;"> src/test/c++       </td>
<td style="text-align:left;"> C++ test sources                 </td>
</tr>
<tr>
<td style="text-align:left;"> src/test/c         </td>
<td style="text-align:left;"> C test sources                   </td>
</tr>
<tr>
<td style="text-align:left;"> build.xml          </td>
<td style="text-align:left;"> Ant build file                   </td>
</tr>
<tr>
<td style="text-align:left;"> ivy.xml            </td>
<td style="text-align:left;"> Ivy module descriptor            </td>
</tr>
<tr>
<td style="text-align:left;"> README.md          </td>
<td style="text-align:left;"> Module&rsquo;s README file             </td>
</tr>
<tr>
<td style="text-align:left;"> target             </td>
<td style="text-align:left;"> Build output directory           </td>
</tr>
</tbody>
</table>


<h2>Common build targets</h2>

<p>We maintain a set of common Ant build targets which every module must implement:</p>

<table>
<thead>
<tr>
<th style="text-align:left;"> Target name               </th>
<th style="text-align:left;"> Description                                                                </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> default                   </td>
<td style="text-align:left;"> Build artifacts, publish artifacts                                         </td>
</tr>
<tr>
<td style="text-align:left;"> distribute                </td>
<td style="text-align:left;"> Build artifacts, publish artifacts and create a distribution package       </td>
</tr>
<tr>
<td style="text-align:left;"> all                       </td>
<td style="text-align:left;"> Build and test artifacts, publish artifacts, create a distribution package </td>
</tr>
<tr>
<td style="text-align:left;"> clean                     </td>
<td style="text-align:left;"> Delete files generated during the build                                    </td>
</tr>
<tr>
<td style="text-align:left;"> clean-dist                </td>
<td style="text-align:left;"> Delete files generated during the RPM package build                        </td>
</tr>
<tr>
<td style="text-align:left;"> clean-all                 </td>
<td style="text-align:left;"> Delete all generated files                                                 </td>
</tr>
<tr>
<td style="text-align:left;"> ci-default                </td>
<td style="text-align:left;"> Called by CI server during the build job execution                         </td>
</tr>
<tr>
<td style="text-align:left;"> report-sonar              </td>
<td style="text-align:left;"> Do statical analysis and send reports to Sonar server                      </td>
</tr>
</tbody>
</table>


<p>These build targets constitute a well-known interface which allows developers to clean and build any module using the same Ant command. Furthermore, each module defines the <code>ci-default</code> target which is called by the Jenkins CI server when building the module. This allows us to have Jenkins build any of our modules by issuing these two commands:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ant clean-all
</span><span class='line'>ant ci-default
</span></code></pre></td></tr></table></div></figure>


<p>This two-command interface establishes a contract between modules and Jenkins and allows us to keep the Jenkins job definition fairly static. On the other hand, developers have full power to define what should happen during the build by implementing the module&rsquo;s  <code>ci-default</code> target.</p>

<p>Target <code>report-sonar</code> runs the SonarQube source code analysis tool, and sends the collected data to the SonarQube server. As the source code analysis takes some time to complete, we don&rsquo;t run it on every push to the Git repository. Instead, we scheduled a nightly Jenkins job that analyzes all the modules and uploads the collected data at once.</p>

<h2>Final remarks</h2>

<p>It has been several years since we created the common build system and we have been improving it ever since. We added many features to support our development process. We have already discussed some of them. Here is a summary of the most important capabilities we implemented so far:</p>

<ul>
<li>Support for building Java and C/C++ code</li>
<li>Support for multiple target platforms (RHEL5, RHEL6, RHEL7, Solaris 10)</li>
<li>Packaging software as RPM, Solaris pkg, IzPack and Docker image</li>
<li>Import of test data into Oracle database before running the unit tests</li>
<li>Management of build jobs in Jenkins</li>
<li>Source code analysis using SonarQube</li>
</ul>


<p>In our company, the relentless improvement process never stops. The Ant + Ivy tools we leverage at the core of our build system are past their prime. So, what&rsquo;s next? I&rsquo;m very excited about our current progress in gradually replacing Ant + Ivy with the more modern Gradle build tool.</p>

<p>I hope you enjoyed the tour through the design of the common build system. I would be interested to know how you promote code reuse of the build scripts in your company. It would be great to hear about your approach. Please, feel free to leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Booting Amazon Linux 2 on OpenStack]]></title>
    <link href="http://alesnosek.com/blog/2018/04/21/booting-amazon-linux-2-on-openstack/"/>
    <updated>2018-04-21T22:21:04-07:00</updated>
    <id>http://alesnosek.com/blog/2018/04/21/booting-amazon-linux-2-on-openstack</id>
    <content type="html"><![CDATA[<p>Amazon Linux 2 runs on OpenStack perfectly fine. There is only one glitch that you should be aware of. Amazon Linux 2 won&rsquo;t accept metadata and user data provided by OpenStack on boot. That means that you won&rsquo;t be able to SSH into the instance after it comes up. In this brief tutorial, we are going to modify the Amazon Linux 2 image to fix this problem.</p>

<!-- more -->


<p>You can download Amazon Linux 2 images from <a href="https://cdn.amazonlinux.com/os-images/latest/.">https://cdn.amazonlinux.com/os-images/latest/.</a> An image suitable for OpenStack is located in the <code>kvm</code> subdirectory. I downloaded the <code>amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2</code> version of the image. By the time you are reading this tutorial, a newer version of the image may be available.</p>

<p>In the rest of this article, I&rsquo;m going to use my machine that is running RHEL7 to modify the Amazon Linux 2 image. First, let&#8217; download the image:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>wget https://cdn.amazonlinux.com/os-images/2017.12.0.20180330/kvm/amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2
</span></code></pre></td></tr></table></div></figure>


<p>Next, let&rsquo;s install the <code>qemu-img</code> utility useful for manipulating qcow2 images:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo yum install qemu-img
</span></code></pre></td></tr></table></div></figure>


<p>Now we can convert the Amazon Linux 2 image from the qcow2 format to the raw format:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>qemu-img convert -f qcow2 -O raw amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2 amzn2-kvm.raw
</span></code></pre></td></tr></table></div></figure>


<p>The previous command creates a file <code>amzn2-kvm.raw</code> in the current working directory. This file is a binary image of the virtual machine disk. We can explore it using the <code>fdisk</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>fdisk -l amzn2-kvm.raw
</span><span class='line'>Disk amzn2-kvm.raw: 26.8 GB, <span class="m">26843545600</span> bytes, <span class="m">52428800</span> sectors
</span><span class='line'><span class="nv">Units</span> <span class="o">=</span> sectors of <span class="m">1</span> * <span class="nv">512</span> <span class="o">=</span> <span class="m">512</span> bytes
</span><span class='line'>Sector size <span class="o">(</span>logical/physical<span class="o">)</span>: <span class="m">512</span> bytes / <span class="m">512</span> bytes
</span><span class='line'>I/O size <span class="o">(</span>minimum/optimal<span class="o">)</span>: <span class="m">512</span> bytes / <span class="m">512</span> bytes
</span><span class='line'>Disk label <span class="nb">type</span>: gpt
</span><span class='line'>Disk identifier: 88B4CB3B-A2F1-4C9C-82DC-F18B0F440F56
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c">#         Start          End    Size  Type            Name</span>
</span><span class='line'> <span class="m">1</span>         <span class="m">4096</span>     <span class="m">52428766</span>     25G  Linux filesyste Linux
</span><span class='line'><span class="m">128</span>         <span class="m">2048</span>         <span class="m">4095</span>      1M  BIOS boot       BIOS Boot Partition
</span></code></pre></td></tr></table></div></figure>


<p>The output of the <code>fdisk</code> command shows that the disk contains two partitions. The size of the first partition is 25 GB and it holds a Linux filesystem. On the disk, the Linux filesystem starts at the sector number 4096. Given that the size of the sector is 512 bytes, we can tell that the Linux filesystem starts at offset 2097152 (4096 * 512) bytes from the start of the disk image. Knowing the offset of the Linux filesystem, let&rsquo;s loop mount the Linux filesystem under <code>/mnt</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo mount -o loop,offset<span class="o">=</span><span class="m">2097152</span> amzn2-kvm.raw /mnt
</span></code></pre></td></tr></table></div></figure>


<p>If everything went well, we can now take a look at the cloud-init configuration of the Amazon Linux 2 image:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo vi /mnt/etc/cloud/cloud.cfg
</span></code></pre></td></tr></table></div></figure>


<p>In the cloud-init configuration file, you can find the data source list set as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>datasource_list: <span class="o">[</span> NoCloud, AltCloud, ConfigDrive, OVF, None <span class="o">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Sadly, none of the listed data sources is available on OpenStack. OpenStack supports its own data source called <code>OpenStack</code>. Alternatively, OpenStack is compatible with the AWS data source called <code>Ec2</code>. This compatibility ensures that virtual machine images designed for EC2 will work properly on OpenStack. I would expect that the <code>Ec2</code> data source would be included in the data source list of the Amazon Linux 2 image but it is not. Let&rsquo;s add the <code>OpenStack</code> data source to the list:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>datasource_list: <span class="o">[</span> OpenStack, NoCloud, AltCloud, ConfigDrive, OVF, None <span class="o">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>I put the <code>OpenStack</code> data source at the beginning of the list. You can choose to add it anywhere else. Just make sure that the <code>None</code> data source remains as the last one on the list. <code>None</code> is a fallback datasource used when no other datasources can be selected and it provides empty metadata and empty user data.</p>

<p>After you saved your changes, you can unmount the Linux filesystem:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo umount /mnt
</span></code></pre></td></tr></table></div></figure>


<p>And convert the modified image back to the qcow2 format:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>qemu-img convert -f raw -O qcow2 amzn2-kvm.raw amzn2-kvm.qcow2
</span></code></pre></td></tr></table></div></figure>


<p>Now you can upload the modified image into the OpenStack image repository:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openstack image create --min-disk <span class="m">25</span> --min-ram <span class="m">512</span> --container-format bare --disk-format qcow2 --file amzn2-kvm.qcow2 amzn2-kvm
</span></code></pre></td></tr></table></div></figure>


<p>After the image upload into OpenStack has completed, you can create a test virtual machine off of this image:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openstack server create --image amzn2-kvm --flavor m1.medium --key-name &lt;key-name&gt; --nic net-id<span class="o">=</span>&lt;net-id&gt; amzn-test
</span></code></pre></td></tr></table></div></figure>


<p>Note that in the above command, you&rsquo;ll have to replace the <code>&lt;key-name&gt;</code> and <code>&lt;net-id&gt;</code> placeholders with the name of your key pair and the name of the network you want your instance to be attached to. After the virtual machine has booted up, you should be able to connect to it using SSH. Note that the default user enabled on the Amazon Linux 2 image is <code>ec2-user</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ssh ec2-user@amzn-test
</span><span class='line'>Last login: Sun Apr <span class="m">22</span> 05:08:45 <span class="m">2018</span> from ales.dev.ussd.verimatrix.com
</span><span class='line'>
</span><span class='line'>       __<span class="p">|</span>  __<span class="p">|</span>_  <span class="o">)</span>
</span><span class='line'>       _<span class="p">|</span>  <span class="o">(</span>     /   Amazon Linux <span class="m">2</span> AMI
</span><span class='line'>      ___<span class="p">|</span><span class="se">\_</span>__<span class="p">|</span>___<span class="p">|</span>
</span><span class='line'>
</span><span class='line'>https://aws.amazon.com/amazon-linux-2/
</span><span class='line'>No packages needed <span class="k">for</span> security<span class="p">;</span> <span class="m">8</span> packages available
</span><span class='line'>Run <span class="s2">&quot;sudo yum update&quot;</span> to apply all updates.
</span></code></pre></td></tr></table></div></figure>


<p>This is the end of the tutorial. You have a working Amazon Linux 2 image on OpenStack, congratulations! If you have any comments or questions, let me know in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[18 Months with OpenStack, Our Experience, Part II]]></title>
    <link href="http://alesnosek.com/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii/"/>
    <updated>2018-03-08T20:51:11-08:00</updated>
    <id>http://alesnosek.com/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2018/02/19/18-months-with-openstack-our-experience-part-i/">previous post</a>, we discussed our experience with the deployment of OpenStack. In this article, we&rsquo;re going to share the lessons learned when operating it. It took effort to tame the OpenStack beast and make it work reliably. If you want to know how we accomplished that, read on.</p>

<!-- more -->


<h2>Monitoring OpenStack using Icinga</h2>

<p>As the old sysadmin saying goes:</p>

<blockquote><p>If you don&rsquo;t monitor it, it&rsquo;s not in production.</p></blockquote>

<p>When looking for a tool to monitor OpenStack, we came across the <a href="https://wiki.openstack.org/wiki/Monasca">Monasca</a> project. Monasca is a monitoring-as-a-service solution built exclusively for OpenStack. The idea of deploying a system which was from the ground up designed for OpenStack was very appealing. However, after taking a closer look at Monasca we steered away from it. Firstly, Monasca was built around Big Data technologies like <a href="https://kafka.apache.org">Apache Kafka</a> and <a href="http://storm.apache.org/">Apache Storm</a> which are a great fit for large-scale deployments. For our rather low-scale use case they seemed to be a bit too heavy. Secondly, around Kilo release it was difficult to predict how much adoption Monasca would find in the community. Instead of Monasca, we eventually decided to go with <a href="https://www.icinga.com/">Icinga</a> which is a derivate of Nagios, a de facto industry standard between monitoring solutions. I wrote about the monitoring of OpenStack using Icinga in one of my previous <a href="http://alesnosek.com/blog/2015/11/30/monitoring-openstack-cluster-with-icinga/">posts</a>. Setting up Icinga to monitor OpenStack meant to search for Nagios plugins to check various parts of the OpenStack cluster. In addition to the standard set of plugins that comes with the Nagios distribution, we ended up using many plugins that we found on the Internet:</p>

<ul>
<li><a href="https://github.com/justintime/nagios-plugins">check_mem</a> Monitor Linux system memory usage.</li>
<li><a href="https://github.com/mclarkson/check_diskstat">check_diskstat</a> Linux disk I/O checks, tps, read, write, avg. request size, avg. queue size and avg. wait time.</li>
<li><a href="https://github.com/nguttman/Nagios-Checks/tree/master/Unix/Check_Process">check_process</a> UNIX process monitoring.</li>
<li><a href="https://github.com/jonschipp/nagios-plugins/blob/master/check_service.sh">check_service</a> Monitors services managed by systemd.</li>
<li><a href="https://github.com/Crapworks/check_ceph_dash">check-ceph-dash</a> Monitors overall Ceph cluster status. Requires <a href="https://github.com/Crapworks/ceph-dash">ceph-dash</a> to be installed.</li>
<li><a href="https://github.com/noseka1/check_haproxy">check_haproxy</a> Monitors the health of HAProxy backends.</li>
<li><a href="https://github.com/polymorf/check_haproxy">haproxy_http_stats</a> Turns the HAProxy statistics into Nagios performance data.</li>
<li><a href="https://github.com/noseka1/nagios-plugin-check_galera_cluster">nagios-plugin-check_galera_cluster</a> Checks the status of a Galera cluster.</li>
<li><a href="https://github.com/alaskacommunications/nagios_check_keepalived">check_keepalived_vrrp</a> Monitors Keepalived VRRP subsystem.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_memcached.pl">check_memcached</a> Checks Memcached statistics.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_redis.pl">check_redis</a> Checks Redis status variables.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_uptime.pl">check_uptime</a> Tracks system uptime. Great to detect power outages.</li>
<li><a href="https://github.com/mzupan/nagios-plugin-mongodb">check_mongodb</a> Monitor MongoDB servers.</li>
<li><a href="https://github.com/noseka1/monitoring-for-openstack">monitoring-for-openstack</a> Monitor various OpenStack services (Nova, Cinder, Glance, Neutron &hellip;)</li>
<li><a href="https://github.com/noseka1/openstack-nagios-plugins">openstack-nagios-plugins</a> Yet another set of Nagios plugins to monitor OpenStack services.</li>
<li><a href="https://labs.consol.de/nagios/check_mysql_health/index.html">check_mysql_health</a> Monitor health and performance of a MySQL database.</li>
<li><a href="https://github.com/nagios-plugins-rabbitmq/nagios-plugins-rabbitmq">nagios-plugins-rabbitmq</a> Set of nagios checks useful for monitoring a RabbitMQ cluster.</li>
</ul>


<p>Besides monitoring the availability of OpenStack services, monitoring the performance of hypervisor hosts was another important point to ensure smooth operations and user happiness. You&rsquo;ve heard about the &ldquo;noisy neighbor&rdquo; problem before, haven&rsquo;t you? Time to time it happened to us that users unknowingly started a workload that would hog the CPU, disk or network I/O of the hypervisor to the extent that other virtual machines running on the same hypervisor were slowed down. In such a situation it was important that Icinga would alert the OpenStack operator that would resolve the problem before the affected users would notice.</p>

<h2>Ceilometer metrics and events</h2>

<p><a href="https://docs.openstack.org/ceilometer">Ceilometer</a> is an OpenStack data collection service that collects telemetry data across all OpenStack components. This telemetry data provides useful insights into the OpenStack operation and I would strongly recommend to you to deploy Ceilometer and configure it to store the telemetry data in the backend of your choice. The data provided by the Ceilometer service can be divided into two categories: measurements and events.</p>

<h3>Ceilometer measurements</h3>

<p><a href="https://docs.openstack.org/ceilometer/pike/admin/telemetry-measurements.html">Ceilometer measurements</a> are performance data. Ceilometer collects performance samples by polling the OpenStack infrastructure elements in regular intervals. For instance, Ceilometer measures CPU, memory, disk and network usage of individual virtual machines hosted on OpenStack, it can measure the performance of hypervisor hosts and much more. It&rsquo;s up to you to choose which data interests you. We ended up collecting merely the performance data of individual virtual machines. Monitoring of hypervisor hosts was better left to Icinga.</p>

<p>There are many options of how to process the performance data generated by Ceilometer. We configured Ceilometer to send the performance samples in the <a href="https://msgpack.org">MessagePack</a> format over UDP protocol to <a href="https://www.elastic.co/products/logstash">Logstash</a>. Logstash in turn forwards the data to the <a href="https://www.influxdata.com/">InfluxDB</a> storage. <a href="https://grafana.com/">Grafana</a> is used to view and graph the performance data stored in InfluxDB. We spent quite a bit of time configuring Logstash to enrich the data coming from Ceilometer to be able to create a beautiful Grafana dashboard that would display the performance graphs of individual virtual machines hosted on OpenStack. Our OpenStack users would be able to look up their virtual machine in the Grafana dashboard based on the OpenStack project and the display name of the instance. After investing all the effort to create the dashboard the practice showed that nobody really cared about the performance monitoring of most of the virtual machines. And if we deployed a virtual machine we wanted to monitor, we preferred to just install the Icinga monitoring agent on it.</p>

<h3>Ceilometer events</h3>

<p><a href="https://docs.openstack.org/ceilometer/pike/admin/telemetry-events.html">Ceilometer events</a> represent any action made in the OpenStack system, for example: successful user authentication, creating a virtual machine, terminating a virtual machine, creating a volume, attaching a volume to a virtual machine and many others. Ceilometer generates events based on the notifications that are published by the OpenStack services on the message bus. For instance, the list of notifications published by the Nova components can be found <a href="https://docs.openstack.org/nova/latest/reference/notifications.html">here</a>. In the past, I wrote an <a href="http://alesnosek.com/blog/2015/05/25/openstack-nova-notifications-subscriber/">article</a> describing how to subscribe to the Nova notifications on the RabbitMQ message bus.</p>

<p>In our OpenStack deployment, we configured Ceilometer to send events to <a href="https://www.elastic.co/">Elasticsearch</a>. <a href="https://www.elastic.co/products/kibana">Kibana</a> is used to view and search for the collected events. Having all the OpenStack events collected and archived at one place turned out to be really helpful. One day, a co-worker of mine brought up a complaint that somebody deleted his virtual machine. Deleting virtual machines of other people, who would dare that? Instead of asking around and disturbing people on the team, we were able to look up all the events pertaining to the lost virtual machine. We found out that the termination event ran on behalf of the Jenkins user. It didn&rsquo;t take much longer to identify the Jenkins job which deleted the virtual machine. Finally, it turned out that the co-worker that complained about the loss of &ldquo;his&rdquo; virtual machine was actually handed over the virtual machine only temporarily and that the machine was deleted and recreated every night by Jenkins. And I told to myself, what an <em>automated</em> world!</p>

<h2>Log collection using ELK</h2>

<p>In addition to storing Ceilometer events in Elasticsearch, we also configured <a href="https://www.elastic.co/products/beats/filebeat">Filebeat</a> to collect OpenStack logs and Linux system logs from all the OpenStack nodes and store them in Elasticsearch. They will come handy in the future when explaining other &ldquo;mysteries&rdquo; happening in our OpenStack cluster.</p>

<h2>Tempest and Rally</h2>

<p>When you deploy an OpenStack cluster, how do you verify that your cluster functions correctly? Icinga checks cover a very small subset of the OpenStack functionality. To accomplish a thorough verification of the OpenStack cluster, we started using the <a href="https://docs.openstack.org/tempest/latest/">Tempest</a> project. Tempest is a battery of integration tests that are used to verify OpenStack&rsquo;s functionality and it is a part of the continuous integration pipeline of the OpenStack project. Tempest tests send requests to the OpenStack APIs and verify the responses. As the goal of the Tempest project is to verify the integration of OpenStack components during development,  the included integration tests were a bit too low-level for our use case of merely verifying that the OpenStack cluster functioned properly. However, there were no better tools available at the time and it did the trick for us.</p>

<p>After a while of using Tempest, we discovered yet another project called <a href="https://docs.openstack.org/developer/rally/">Rally</a>. Rally is a benchmarking tool that is used to measure OpenStack&rsquo;s performance and to identify performance bottlenecks. Rally builds on top of Tempest and it comes with a set of predefined scenarios that are executed against the OpenStack cluster. Example scenarios are: boot and delete server, boot server from volume, create a subnet, create and attach volume, create and delete a Heat stack, and many more. The available scenarios were just right to verify our cloud! On top of that, Rally generates beautiful reports with the overview of executed tasks and their duration. We ended up creating a cron job that schedules the Rally tests to run every two hours. The test results are monitored using Icinga which in the case of test failure sends an alert to the operator.</p>

<p>Because our OpenStack cluster was constantly exercised by the Rally tests, we were able to quickly spot resources that OpenStack didn&rsquo;t clean up properly and that were piling up. We have seen diverse OpenStack database tables growing infinitely.  We have experienced Neutron leaving processes running on the controller nodes, leaving empty network namespaces behind or filling up the <code>/var/log/neutron</code> directory with files. Remember that we experienced these issues while using the Mitaka release of OpenStack. I&rsquo;m sure that things improved since then. To address the resource leaks, we wrote custom clean-up scripts. I&rsquo;m publishing them for you to use at your own risk. You can find them on <a href="https://github.com/noseka1/openstack-periodic-cleanup">GitHub</a>.</p>

<h2>Tracking cloud resource usage</h2>

<p>In OpenStack, we were missing some kind of reporting on resource usage. In our organization, each development team has its dedicated project in OpenStack. It is important to us to understand, how much of the cloud resources each team is consuming, i.e. how many CPU cores, memory, and volumes. In addition to per project usage, we also monitor the total resource usage across the entire cluster. In the case, that the total usage is reaching the total capacity available we can organize additional hardware ahead of time.</p>

<p>Around OpenStack Mitaka release, we didn&rsquo;t find any tool that would generate the usage reports. However, OpenStack&rsquo;s MariaDB database contains all the input data required to create such reports. It was rather straightforward to create a set of SQL scripts to generate the reports directly out of the OpenStack&rsquo;s database. We run these scripts periodically using Icinga, so that we can see the report output on our monitoring dashboard. If you are interested, you can find our OpenStack usage report scripts on <a href="https://github.com/noseka1/openstack-cloud-report">GitHub</a>.</p>

<h2>Further notes</h2>

<p>I&rsquo;d like to describe several further observations that we made while operating OpenStack. Once again, our experience pertains to the Mitaka release of OpenStack only. Many of the issues we stumbled upon might have been resolved in the newer releases of OpenStack.</p>

<ul>
<li>In order to get OpenStack working smoothly, you should expect to use some amount of duct tape and bubble gum. As OpenStack was implemented in Python, patching OpenStack is relatively easy. Many times I was able to find fixes for our issues on the project development branches and needed just to port them to our OpenStack version.</li>
<li>OpenStack is deployed on many nodes. It was useful for us to write Ansible scripts to automate the restart of the RabbitMQ cluster and to automate the restart of all OpenStack services on all nodes (aka restart the world). Due to the issues with the OpenStack TripleO installer in the Mitaka release, we are still forced to restart the world after adding a compute node.</li>
<li>Switching to Keystone Fernet tokens considerably reduced the load on the MariaDB database. We enabled Fernet tokens even in the Mitaka release of OpenStack.</li>
<li>RabbitMQ, Cinder Backup and several other services require higher amount of open file descriptors. For instance, RabbitMQ <a href="https://www.rabbitmq.com/production-checklist.html">recommends</a> to allow at least 50K of open file descriptors. Insufficient amount of file descriptors caused our RabbitMQ to crash. As RabbitMQ is the communication backbone of OpenStack, you can imagine how much fun it caused.</li>
<li>Our OpenStack networking is set up to use Neutron&rsquo;s OpenVSwitch driver and VLANs. In the default configuration, it happened to us that the multicast traffic sent by a single virtual machine flooded the entire network and caused OpenVSwitch to begin dropping packets. We didn&rsquo;t do any further research on the multicast on OpenStack topic so far, just avoided sending multicast altogether.</li>
<li>Kudos goes to the <a href="https://ceph.com/">Ceph</a> storage. We are running the old Ceph v0.94 Hammer which was able to survive emergency situations like lost storage node and running out of space condition without any problems.</li>
</ul>


<h2>Conclusion</h2>

<p>In this blog post, we shared some of our experiences with operating OpenStack. We described the monitoring using Icinga, collecting Ceilometer metrics and events, collecting system logs using the ELK stack, verifying the OpenStack functionality with Rally and generating cloud resource usage reports.</p>

<p>OpenStack is not the easiest software to run, however, if you do your homework you will succeed. At the present time, OpenStack just works for us and brings a lot of value to the teams in our company.</p>

<p>If you&rsquo;d like to share your experience with operating OpenStack, I would love to hear from you. Please, feel free to use the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[18 Months with OpenStack, Our Experience, Part I]]></title>
    <link href="http://alesnosek.com/blog/2018/02/19/18-months-with-openstack-our-experience-part-i/"/>
    <updated>2018-02-19T21:06:17-08:00</updated>
    <id>http://alesnosek.com/blog/2018/02/19/18-months-with-openstack-our-experience-part-i</id>
    <content type="html"><![CDATA[<p>It has been 18 months since we deployed OpenStack cloud in our company. In this article, I would like to review our time with OpenStack and describe some of the experience we gained. Are you thinking about building an OpenStack-based cloud? This article might provide you with additional insights and tips that will help you succeed.</p>

<!-- more -->


<h2>Introduction</h2>

<p>Right at the beginning, I&rsquo;d like to say that our company is not a cloud provider. We didn&rsquo;t build a cloud to provide a service to customers. Instead, we built a private cloud to support our engineering team in their software development efforts. Our OpenStack is running development machines, build machines and test machines. The requirements on the availability and reliability of our OpenStack cluster are therefore lower than the requirements that a public cloud would have to meet.</p>

<p>We started evaluating OpenStack around the Kilo release and ended up going with Mitaka into production. Around that time, Internet was flooded with articles criticizing the complexity of OpenStack including scary stories of companies failing their OpenStack projects. I can confirm that deploying OpenStack was a real challenge and that as we were working on it, the OpenStack version of the Kennedy&rsquo;s famous words passed through my mind several times:</p>

<blockquote><p>We choose to deploy OpenStack not because it is easy, but because it is hard.</p></blockquote>

<p>However, nothing can scare away a proficent software practitioner. Eventually, we got the job done and the invested effort did pay off.</p>

<h2>OpenStack essentials</h2>

<p><a href="https://www.openstack.org/">OpenStack</a> is an open-source infrastructure-as-a-service (IaaS) cloud platform. It&rsquo;s important to understand that OpenStack itself is only a controlling layer that relies on other software projects to provide the implementation of the underlying functionality. For instance, OpenStack can spin up virtual machines, however, you would not find any code in the OpenStack project that would actually implement a hypervisor. Instead, OpenStack integrates with an existing hypervisor software to do the job. A very popular choice of the hypervisor used along with OpenStack is <a href="https://www.linux-kvm.org">KVM</a> and so when the user creates a virtual machine on OpenStack, OpenStack merely calls the KVM hypervisor to spin up the virtual machine. The same holds true for other areas of OpenStack functionality like networking and storage where OpenStack drives the underlying networking and storage software to do the actual job.</p>

<p>When planning an OpenStack cluster, you will have to choose from a variety of underlying technologies. For instance, in addition to the KVM hypervisor, OpenStack also supports Xen, VMware vSphere and Hyper-V. Most of the time you will just pick the technology you already run at your place and for which you have the staff to manage it. The freedom of choice you have with OpenStack is amazing, however, I would recommend to always look at the most popular choices first because their integration with OpenStack tends to be more solid. In our case, we chose KVM as a hypervisor, <a href="http://www.openvswitch.org/">Open vSwitch</a> as a networking implementation and <a href="https://ceph.com/">Ceph</a> to provide object and block storage.</p>

<p>OpenStack is an umbrella project under which you can find a host of projects each dealing with a different portion of the cloud functionality. The core projects that one can find installed in the majority of OpenStack deployments are:</p>

<ul>
<li><a href="https://wiki.openstack.org/wiki/Nova">Nova</a>. Manages virtual machines.</li>
<li><a href="https://wiki.openstack.org/wiki/Neutron">Neutron</a>. Provides networking to virtual machines.</li>
<li><a href="https://wiki.openstack.org/wiki/Cinder">Cinder</a>. Provides block storage that can be attached to virtual machines.</li>
<li><a href="https://wiki.openstack.org/wiki/Glance">Glance</a>. Stores virtual machine images.</li>
<li><a href="https://wiki.openstack.org/wiki/Horizon">Horizon</a>. Web-based user interface to OpenStack services.</li>
<li><a href="https://wiki.openstack.org/wiki/Keystone">Keystone</a>. Identity service.</li>
</ul>


<p>Additionally, project <a href="https://wiki.openstack.org/wiki/Heat">Heat</a>, <a href="https://wiki.openstack.org/wiki/Swift">Swift</a>, and <a href="https://wiki.openstack.org/wiki/Telemetry">Ceilometer</a> are also rather popular. You can find plenty of other OpenStack projects listed on the <a href="https://www.openstack.org/software/project-navigator">Project navigator</a> page. When choosing OpenStack projects for your deployment, you should always consider the adoption and the maturity of the projects. Many projects on the list are still in the early stages of development and not ready for production use.</p>

<p>OpenStack was designed for massive scale deployments as you can tell if you look at the <a href="https://docs.openstack.org/arch-design/design.html">OpenStack architecture diagram</a>. Each OpenStack project consists of multiple services (daemons) that can be deployed on separate physical machines allowing OpenStack to scale out. OpenStack services communicate with each other over the network using RESTful APIs. In addition, some of the projects like Nova, Neutron and Cinder chose to leverage a message broker for internal communication. The high number of services that form an OpenStack deployment contributes to its operational complexity.</p>

<h2>Getting started with OpenStack</h2>

<p>If you are new to OpenStack, a great place to start learning OpenStack is the <a href="https://docs.openstack.org/devstack/latest/">DevStack project</a>. DevStack allows you to create an all-in-one deployment of OpenStack. With DevStack you can access debug logs of individual OpenStack services as well as easily restart OpenStack services after you changed their configuration. It took me a while to figure out which configuration option affects which OpenStack service and how OpenStack services communicate with each other. I learned a lot by re-deploying DevStack many times, trying to make the individual OpenStack features work properly.</p>

<p>OpenStack is a fast moving project with two major releases per year. Especially in the past, the project documentation could not keep up with the many changes packed in each release. The documentation was outdated on many places or was missing altogether. When working with OpenStack I quickly realized that reading the OpenStack&rsquo;s Python code was necessary in order to understand how some of the configuration options worked or when troubleshooting various issues.</p>

<blockquote><p> Ability to read the OpenStack source code was required to succeed.</p></blockquote>

<p>OpenStack is written using a beautiful idiomatic Python code which was most of the time a pleasure to read. At first, I started walking through the code of simpler projects like Glance and learned the patterns that were commonly used in other OpenStack projects, too. Only later I dived deeper into the internals of Nova, the OpenStack&rsquo;s brain that schedules and creates virtual machines. When between OpenStack releases configuration options were renamed or moved to different INI file sections, I just grepped through the source code and learned about the changes avoiding any further frustration.</p>

<p>If you are getting started with OpenStack, prepare for a steep learning curve. Apart from studying the OpenStack project documentation, you will have to refer to the documentation of the technologies that you integrate with OpenStack, too. For instance, I spend quite a bit of time studying the documentation of <a href="https://www.rabbitmq.com/documentation.html">RabbitMQ</a>, <a href="https://libvirt.org/docs.html">libvirt</a>, <a href="http://docs.openvswitch.org">Open vSwitch</a>, and <a href="http://docs.ceph.com">Ceph</a>.</p>

<h2>Choosing an OpenStack distribution</h2>

<p>There are several OpenStack distributions available out there. For us the choice was pretty straight forward. As we are a Red Hat shop, we went with <a href="https://www.rdoproject.org/">RDO</a> installed on top of RHEL7. I spent large amounts of time working with RDO and yeah, it was challenging, at least in its Mitaka release. For further details on our experience with OpenStack RDO, you can refer to articles: <a href="http://alesnosek.com/blog/2016/03/27/tripleo-installer-the-good/">1</a>, <a href="http://alesnosek.com/blog/2017/01/15/tripleo-installer-production-ready">2</a>. Due to the complexity of OpenStack, it is rather difficult to create a tool to manage its life-cycle and I&rsquo;m certain that further development effort will have to be spent before reaching perfection.</p>

<p>By the way, some OpenStack distributions come with a GUI-based installer. As there are dozens of configuration parameters to set during the installation, I don&rsquo;t see the point of using a graphical interface to do this. Instead, a well commented configuration file seems more desirable to me. Does the GUI-based installer enable product managers to make a check mark on their data sheet? I would say yes, but you can safely ignore it when choosing your OpenStack distribution.</p>

<h2>Choosing server hardware</h2>

<p>We started with a small OpenStack deployment comprised of 3 controller nodes, 2 compute nodes and 3 Ceph nodes. Over time, we added further nodes to meet the growing demand and ended up with the current size of the cluster being 3 controller nodes, 13 compute nodes and 7 Ceph nodes. Majority of the nodes are HP ProLiant DL360 Gen9 machines with the following hardware parameters:</p>

<ul>
<li><strong>Controller nodes.</strong> 96GB RAM, 2 x 300GB SAS 10K HDD in RAID1, 1Gbit Ethernet NICs</li>
<li><strong>Compute nodes.</strong> 288GB RAM, 8 x 300GB SAS 10K HDD in RAID10 (for the OS + instance ephemeral storage), 1Gbit and 10Gbit Ethernet NICs</li>
<li><strong>Ceph nodes.</strong> 32GB RAM, 2 x 300GB SAS 10K HDD in RAID1 (for the OS), 6 x 1.2TB SAS 10K HDD (Ceph OSD storage drives), 1Gbit and 10Gbit Ethernet NICs</li>
</ul>


<p>1Gbit Ethernet NICs are used to access OpenStack APIs on the controller nodes. Compute nodes and Ceph storage nodes are interconnected using 10Gbit Ethernet. All network interfaces are bonded and connected to two different switches to avoid a single-point-of-failure. There is a dedicated 1Gbit link attached to each of the OpenStack nodes used for node management via SSH.</p>

<p>From our experience, each of the compute nodes can run up to 40-50 virtual machines using the default OpenStack RDO settings: cpu_allocation_ratio=16.0, ram_allocation_ratio=1.0 and disk_allocation_ratio=1.0. Our current limit preventing us to achieve even higher density is the amount of provisioned RAM on the nodes. In the future, we are considering adding more RAM to the compute nodes or increasing the ram_allocation_ratio.</p>

<h2>Deployment overview</h2>

<p>Finally, we are going to take a look at the high-level overview of our OpenStack deployment. In the diagram below you can see the OpenStack projects that we chose for the deployment:</p>

<p><img src="http://alesnosek.com/images/posts/18_months_with_openstack_components.png" width="800" height="1000" title="OpenStack Components" ></p>

<p>Let me comment on some of the projects we deployed:</p>

<ul>
<li><strong><a href="https://docs.openstack.org/ironic">Ironic</a>.</strong> We deployed Ironic in order to manage baremetal machines that we use for performance testing. Performance tests are more accurate when carried out in an isolated baremetal environment than on the virtual machines that share the resources of the hypervisor. To this date we didn&rsquo;t realize this our plan but we will get back to it in the future.</li>
<li><strong><a href="https://docs.openstack.org/magnum">Magnum</a>.</strong> Magnum project simplifies the deployment of container orchestrators like Kubernetes, Swarm and Mesos on top of OpenStack. To accomplish this, Magnum leverages Heat templates behind the scenes and the actual provisioning is done by Heat. To be honest, we never really started using Magnum. When deploying Kubernetes, we preferred to use Heat templates provided by the Kubernetes project. This approach turned to be more straight forward than involving yet another service like Magnum. You can read about it <a href="http://alesnosek.com/blog/2016/06/26/deploying-kubernetes-on-openstack-using-heat">here</a>.</li>
<li><strong><a href="https://docs.openstack.org/sahara">Sahara</a>.</strong> Sahara project allows you to deploy big data frameworks like Apache Hadoop and Apache Spark on top of OpenStack. We made similar experience with Sahara as we made with Magnum. We just didn&rsquo;t start using it at all. It turned out that there were already pre-existing deployment scripts provided by Hortonworks and others that it made no sense for us to use Sahara. While Hortonworks <a href="https://github.com/hortonworks/ansible-hortonworks">scripts</a> can deploy Hadoop on any of the major clouds, Sahara would be an OpenStack-only solution.</li>
<li><strong><a href="https://docs.openstack.org/manila">Manila</a>.</strong> While not depicted in the diagram, we also deployed OpenStack Manila. Manila is a shared file system service and we use it to provision NFS shares. Manila project started as a code copy of the Cinder project and perhaps that&rsquo;s why it was pretty stable and usable soon after its inception. I wrote an <a href="http://alesnosek.com/blog/2016/05/22/test-driving-openstack-manila/">article</a> about Manila at the time we were evaluating it.</li>
<li><strong><a href="https://docs.openstack.org/designate">Designate</a>.</strong>  Designate is a DNS as a service for OpenStack. After evaluating this project, we realized that for our simple purpose Designate was too involved. We ended up writing a Python script that dynamically registers OpenStack virtual machines with our internal DNS server. This script works reliably ever since and you can read about it in this <a href="http://alesnosek.com/blog/2015/05/31/openstack-dynamic-dns-updates">blog post</a>.</li>
</ul>


<h2>Conclusion</h2>

<p>In this post, we described some of our experience with planning the OpenStack cloud and deploying it. In the <a href="http://alesnosek.com/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii/">second</a> blog post, we are going to share the lessons learned when operating OpenStack.</p>

<p>If you have battle scars from working with OpenStack, I would love to hear from you. Please, feel free to share your comments and stories in the comment section below.</p>
]]></content>
  </entry>

</feed>
