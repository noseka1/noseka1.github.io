<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Ales Nosek - The Software Practitioner]]></title>
  <link href="http://alesnosek.com/atom.xml" rel="self"/>
  <link href="http://alesnosek.com/"/>
  <updated>2020-09-28T07:34:01-07:00</updated>
  <id>http://alesnosek.com/</id>
  <author>
    <name><![CDATA[Ales Nosek]]></name>

  </author>
  <generator uri="http://octopress.org/">Octopress</generator>


  <entry>
    <title type="html"><![CDATA[Apache Airflow Architecture on OpenShift]]></title>
    <link href="http://alesnosek.com/blog/2020/09/13/apache-airflow-architecture-on-openshift/"/>
    <updated>2020-09-13T18:48:20-07:00</updated>
    <id>http://alesnosek.com/blog/2020/09/13/apache-airflow-architecture-on-openshift</id>
    <content type="html"><![CDATA[<p>This blog will walk you through the Apache Airflow architecture on OpenShift. We are going to discuss the function of the individual Airflow components and how they can be deployed to OpenShift. This article focuses on the latest Apache Airflow version 1.10.12.</p>

<!-- more -->


<h2>Architecture overview</h2>

<p>The three main components of Apache Airflow are the Webserver, Scheduler, and Workers. The Webserver provides the Web UI which is the Airflow&rsquo;s main user interface. It allows users to visualize their DAGs (Directed Acyclic Graph) and control the execution of their DAGs. In addition to the Web UI, the Webserver also provides an experimental REST API that allows controlling Airflow programatically as opposed to through the Web UI. The second component &mdash; the Airflow Scheduler &mdash; orchestrates the execution of DAGs by starting the DAG tasks at the right time and in the right order. Both Airflow Webserver and Scheduler are long-running services. On the other hand, Airflow Workers &mdash; the last of the three main components &mdash; run as ephemeral pods. They are created by the Kubernetes Executor and their sole purpose is to execute a single DAG task. After the task execution is complete, the Worker pod is deleted. The following diagram depicts the Aiflow architecture on OpenShift:</p>

<p><img src="http://alesnosek.com/images/posts/apache_airflow_architecture_on_openshift.png"></p>

<h2>Shared database</h2>

<p>As shown in the architecture diagram above, none of the Airflow components communicate directly with each other. Instead, they all read and modify the state that is stored in the <em>shared database</em>. For instance,  the Webserver reads the current state of the DAG execution from the database and displays it in the Web UI. If you trigger a DAG in the Web UI, the Webserver will update the DAG in the database accordingly. Next comes the Scheduler that checks the DAG state in the database periodically. It finds the triggered DAG and if the time is right, it will schedule the new tasks for execution. After the execution of the specific task is complete, the Worker marks that state of the task in the database as done. Finally, the Web UI will learn the new state of the task from the database and will show it to the user.</p>

<p>The shared database architecture provides Airflow components with a perfectly consistent view of the current state. On the other hand, as the number of tasks to execute grows, the database becomes a performance bottleneck as more and more Workers connect to the database. To alleviate the load on the database, a connection pool like <a href="https://www.pgbouncer.org/">PgBouncer</a> may be deployed in front of the database. The pool manages a relatively small amount of database connections which are re-used to serve requests of different Workers.</p>

<p>Regarding the choice of a particular DBMS, in production deployments the database of choice is typically PostgreSQL or MySQL. You can choose to run the database directly on OpenShift. In that case, you will need to put it on an RWO (ReadWriteOnce) persistent volume provided for example by <a href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage">OpenShift Container Storage</a>. Or, you can use an external database. For instance, if you are hosting OpenShift on top of AWS, you can leverage a fully managed database provided by <a href="https://aws.amazon.com/rds/">Amazon RDS</a>.</p>

<h2>Making DAGs accessible to Airflow components</h2>

<p>All three Airflow components Webserver, Scheduler, and Workers assume that the DAG definitions can be read from the local filesystem.  The question is, how to make the DAGs available on the local filesystem in the container? There are two approaches to achieve this. In the first approach, a shared volume is created to hold all the DAGs. This volume is then attached to the Airflow pods. The second approach assumes that your DAGs are hosted in a git repository. A sidecar container is deployed along with the Airflow Server and Scheduler. This sidecar container synchronizes the latest version of your DAGs with the local filesystem periodically. For the Worker pods, the pulling of the DAGs from the git repository is done only once by the init container before the Worker is brought up.</p>

<p>Note that since Airflow 1.10.10, you can use the <a href="https://airflow.apache.org/docs/1.10.10/dag-serialization.html">DAG Serialization</a> feature. With DAG Serialization, the Scheduler reads the DAGs from the local filesystem and saves them in the database. The Airflow Webserver then reads the DAGs from the database instead of the local filesystem. For the Webserver container, you can avoid the need to mount a shared volume or configure git-sync if you enable the DAG Serialization.</p>

<p>To synchronize the DAGs with the local filesystem, I personally prefer using git-sync over the shared volumes approach. First, you want to keep you DAGs in the source control anyway to facilitate the development of the DAGs. Second, git-sync seems to be easier to troubleshoot and recover in the case of failure.</p>

<h2>Airflow monitoring</h2>

<p>As the old saying goes, &ldquo;If you are not monitoring it, it&rsquo;s not in production&rdquo;. So, how can we monitor Apache Airflow running on OpenShift? <a href="https://prometheus.io/">Prometheus</a> is a monitoring system widely used for monitoring Kubernetes workloads and I recommend that you consider it for monitoring Airflow as well. Airflow itself reports metrics using the statsd protocol, so you will need to deploy the <a href="https://github.com/prometheus/statsd_exporter">statsd_exporter</a> piece between Airflow and the Prometheus server. This exporter will aggregate the statsd metrics, convert them into Prometheus format and expose them for the Prometheus server to scrape.</p>

<h2>Collecting Airflow logs</h2>

<p>By default, Apache Airflow writes the logs to the local filesystem. If you have an RWX (ReadWriteMany) persistent volume available, you can attach it to the Webserver, Scheduler, and Worker pods to capture the logs. As the Worker logs are written to the shared volume, they are instantly accessible by the Webserver. This allows for viewing the logs live in the Web UI.</p>

<p>An alternative approach to handling the Airflow logs is to enable remote logging.  With remote logging, the Worker logs can be pushed to the remote location like S3. The logs are then grabbed from S3 by the Webserver to display them in the Web UI. Note that when using an object store as your remote location, the Worker logs are uploaded to the object store only after the task run is complete. That means that you won&rsquo;t be able to view the logs live in the Web UI while the task is still running.</p>

<p>The remote logging feature in Airflow takes care of the Worker logs. How can you handle Webserver and Scheduler logs when not using a persistent volume? You can configure Airflow to dump the logs to stdout. The OpenShift logging will collect the logs and send them to the central location.</p>

<h2>Conclusion</h2>

<p>In this article, we reviewed the Apache Airflow architecture on OpenShift. We discussed the role of individual Airflow components and described how they interact with each other. We discussed the Airflow&rsquo;s shared database, explained how to make DAGs accessible to the Airflow components, and talked about Ariflow monitoring and log collection.</p>

<p>Apache Airflow can be deployed in several different ways. What is your favorite architecture for deploying Airflow? I would like to hear about your approach. If you have any further questions or comments, please add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Speaking at Red Hat Summit 2020, Part II]]></title>
    <link href="http://alesnosek.com/blog/2020/07/13/speaking-at-red-hat-summit-2020/"/>
    <updated>2020-07-13T19:06:44-07:00</updated>
    <id>http://alesnosek.com/blog/2020/07/13/speaking-at-red-hat-summit-2020</id>
    <content type="html"><![CDATA[<p>This year&rsquo;s <a href="https://www.redhat.com/en/summit">Red Hat Summit</a> is not over yet! There is a second batch of sessions that will be released on Wednesday, July 15. I will have a joint presentation with Andrew Baumann, titled: <em>Security and access control for microservices</em>. We will be discussing OAuth 2.0, the Keycloak project, and Open Policy Agent.</p>

<p>More information about the session can be found in the <a href="https://summit.redhat.com/conference/sessions?p1=eyJzcGVha2VyIjpbXSwidGltZXNsb3QiOltdLCJkYXkiOltdLCJyb29tIjpbXSwibG9jYXRpb24iOltdLCJzb3J0b3JkZXIiOiJkYXRlIiwic3RhcnQiOiIiLCJmaW5pc2giOiIiLCJwYWdlbnVtYmVyIjoxLCJzaGFyZWlkIjoiIiwiY2F0ZWdvcmllcyI6e30sImtleXdvcmQiOiJTZWN1cml0eSBhbmQgYWNjZXNzIGNvbnRyb2wifQ==">session catalog</a>.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/red_hat_summit_2020_part_ii.png"></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[CI/CD Pipeline Spanning Multiple OpenShift Clusters]]></title>
    <link href="http://alesnosek.com/blog/2020/06/30/ci-slash-cd-pipeline-spanning-multiple-openshift-clusters/"/>
    <updated>2020-06-30T17:53:09-07:00</updated>
    <id>http://alesnosek.com/blog/2020/06/30/ci-slash-cd-pipeline-spanning-multiple-openshift-clusters</id>
    <content type="html"><![CDATA[<p>This blog will cover how to create a CI/CD pipeline that spans multiple OpenShift clusters. It will show an example of a Jenkins-based pipeline, and design a pipeline that uses Tekton.</p>

<!-- more -->


<p>Traditionally, CI/CD pipelines were implemented on top of bare metal servers and virtual machines. Container platforms like Kubernetes and OpenShift appeared on the scene only later on. As more and more workloads are migrating to OpenShift, CI/CD pipelines are headed in the same direction. Pipeline jobs are executed in containers in the cluster.</p>

<p>In the real world, companies don&rsquo;t deploy a single OpenShift cluster but run multiple clusters. Why is that? They want to run their workloads in different public clouds as well as on-premise. Or, if they leverage a single platform provider, they want to run in multiple regions. Sometimes there is a need for multiple clusters in a single region, too. For example, when each cluster is deployed into a different security zone.</p>

<p>As there are plenty of reasons to use multiple OpenShift clusters, there is a need to create CI/CD pipelines that work across those clusters. The next sections are going to design such pipelines.</p>

<h2>CI/CD pipeline using Jenkins</h2>

<p>Jenkins is a legend among CI/CD tools. I remember meeting Jenkins back in the day when it was called Hudson but that&rsquo;s old history. How can we build a Jenkins pipeline that spans multiple OpenShift clusters? An important design goal for the pipeline is to achieve a single dashboard that can display output of all jobs involved in the pipeline. I gave it some thought and realized that achieving a single dashboard pretty much implies using a single Jenkins master. This Jenkins master is connected with each of the OpenShift clusters. During the pipeline execution, Jenkins master can run individual tasks on any of the clusters. The job output logs are collected and sent to the master as usual. If we consider having three OpenShift clusters Dev, Test, and Prod, the following diagram depicts the approach:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/ci_cd_pipeline_spanning_multiple_clusters_jenkins.png"></p>

<p>The Jenkins <a href="https://plugins.jenkins.io/kubernetes/">Kubernetes plugin</a> is a perfect plugin for connecting Jenkins to OpenShift. It allows the Jenkins master to create ephemeral workers on the cluster. Each cluster can be assigned a different node label. You can run each stage of your pipeline on a different cluster by specifying the label. A simple pipeline definition for our example would look like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>stage ('Build') {
</span><span class='line'>  node ("dev") {
</span><span class='line'>    // running on dev cluster
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>stage ('Test') {
</span><span class='line'>  node ("test") {
</span><span class='line'>    // running on test cluster
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>stage ('Prod') {
</span><span class='line'>  node ("prod") {
</span><span class='line'>    // running on prod cluster
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>OpenShift comes with a Jenkins template which can be found in the <code>openshift</code> project. This template allows you to create a Jenkins master that is pre-configured to spin up worker pods on the same cluster. Further effort will be needed to connect this master to additional OpenShift clusters. A tricky part of this set up is networking. Jenkins worker pod, after it starts up, connects back to the Jenkins master. This requires the master to be reachable from the worker running on any of the OpenShift clusters.</p>

<p>One last point I wanted to discuss is security. As long as the Jenkins master can spin up worker pods on OpenShift, it can execute arbitrary code on those workers. The OpenShift cluster has no means to control what code the Jenkins worker will run. The job definition is managed by Jenkins and it is solely up to the access controls in Jenkins to enforce which job is allowed to execute on which cluster.</p>

<h2>Kubernetes-native Tekton pipeline</h2>

<p>In this section, we are going to use Tekton to implement the CI/CD pipeline. In contrast to Jenkins, Tekton is a Kubernetes-native solution. It is implemented using Kubernetes building blocks and it is tightly integrated with Kubernetes. A single Kubernetes cluster is a natural boundary for Tekton. So, how can we build a Tekton pipeline that spans multiple OpenShift clusters?</p>

<p>I came up with an idea of composing the Tekton pipelines. To compose multiple pipelines into a single pipeline, I implemented the <a href="https://github.com/noseka1/execute-remote-pipeline">execute-remote-pipeline</a> task that can execute a Tekton pipeline located on a remote OpenShift cluster. The task will tail the output of the remote pipeline while the remote pipeline is executing. With the help of this task, I can now combine Tekton pipelines across OpenShift clusters and run them as a single pipeline. For example, the diagram below shows a composition of three pipelines. Each of the pipelines is located on a different OpenShift cluster Dev, Test, and Prod:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/ci_cd_pipeline_spanning_multiple_clusters_tekton.png"></p>

<p>The execution of this pipeline is started on the Dev cluster. The Dev pipeline will trigger the Test pipeline which will in turn trigger the Prod pipeline. The combined logs can be followed on the terminal:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tkn pipeline start dev --showlog
</span><span class='line'>Pipelinerun started: dev-run-bd5fs
</span><span class='line'>Waiting for logs to be available...
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] Logged into "https://api.cluster-affc.sandbox1480.opentlc.com:6443" as "system:serviceaccount:test-pipeline:pipeline-starter" using the token provided.
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step]
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] You have one project on this server: "test-pipeline"
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step]
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] Using project "test-pipeline".
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] Welcome! See 'oc help' to get started.
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step] Logged into "https://api.cluster-affc.sandbox1480.opentlc.com:6443" as "system:serviceaccount:prod-pipeline:pipeline-starter" using the token provided.
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step]
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step] You have one project on this server: "prod-pipeline"
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step]
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step] Using project "prod-pipeline".
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step] Welcome! See 'oc help' to get started.
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step] [prod : prod-step] Running on prod cluster
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step] [execute-remote-pipeline : execute-remote-pipeline-step]
</span><span class='line'>[execute-remote-pipeline : execute-remote-pipeline-step]</span></code></pre></td></tr></table></div></figure>


<p>Note that this example is showing a cascading execution of Tekton pipelines. Another way of composing pipelines would be executing multiple remote pipelines in sequence.</p>

<p>Before moving on to the final section of this blog, let&rsquo;s briefly discuss the pipeline composition in terms of security. As a Kubernetes-native solution, Tekton&rsquo;s access control is managed by RBAC. Before the task running on a local cluster can trigger a pipeline on a remote cluster, it has to be granted appropriate permissions. These permissions are defined by the remote cluster. This way a remote cluster running in a higher environment (Prod) can impose access restrictions on the tasks running in the lower environment (Test). For example, a Prod cluster will allow the Test cluster to only trigger pre-defined production pipelines. The Test cluster won&rsquo;t have permissions to create new pipelines in the Prod cluster.</p>

<h2>Conclusion</h2>

<p>This blog showed how to create CI/CD pipelines that span multiple OpenShift clusters using Jenkins and Tekton. It designed the pipelines and discussed some of the security aspects. The execute-remote-pipeline Tekton task was used to compose pipelines located on different OpenShift clusters into a single pipeline.</p>

<p>Needless to say, containerized pipelines work the same way on any OpenShift cluster regardless of whether the cluster itself is running on top of a public cloud or on-premise. The vision of the hybrid cloud is well showcased here.</p>

<p>Do you create pipelines that span multiple clusters? Would you like to share some of your design ideas?  I would be happy to hear about your thoughts. Please, feel free to leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Local Development with OpenShift and Tilt]]></title>
    <link href="http://alesnosek.com/blog/2020/06/08/local-development-with-openshift-and-tilt/"/>
    <updated>2020-06-08T20:36:36-07:00</updated>
    <id>http://alesnosek.com/blog/2020/06/08/local-development-with-openshift-and-tilt</id>
    <content type="html"><![CDATA[<p>In this blog post, I am going to show you how to use Tilt to facilitate local OpenShift development. Tilt’s capabilities will be demonstrated in a practical example that uses buildah and CodeReady Containers. If you develop containerized applications on OpenShift, this blog post is for you.</p>

<!-- more -->


<h2>How does Tilt facilitate local development?</h2>

<p>The diagram below depicts a development workflow orchestrated by Tilt. After you execute the <code>tilt up</code> command on your development machine, Tilt will keep running while performing the following actions:</p>

<ol>
<li>Tilt watches for changes in the source code made by the developer on the local machine.</li>
<li>After a change has been detected, Tilt executes buildah to update the container image. After the build completes, the updated container image is pushed to the internal registry in CodeReady Containers.</li>
<li>Tilt watches Kubernetes manifests on the local machine and keeps them in sync with CodeReady Containers. Any changes made to the manifests are instantly applied to CodeReady Containers.</li>
<li>Tilt forwards local ports to the application pod running in CodeReady Containers. This allows the developer to conveniently access the application on localhost.</li>
</ol>


<p><img class="center" src="http://alesnosek.com/images/posts/local_development_with_openshift_and_tilt_diagram.png"></p>

<p>Tilt helps the developer automate many of the manual steps made during the development of containerized applications. It speeds up the edit-compile-run loop considerably. Interested to trying it out? Follow me to the next section, where we will implement the workflow depicted in the above diagram.</p>

<h2>Using Tilt for developing a sample application</h2>

<p>In this section, we are going to use Tilt to orchestrate the development of a sample application. As I didn&rsquo;t want to reinvent the wheel by designing a custom application, I grabbed the Plain Old Static HTML example that comes with Tilt and can be found on <a href="https://github.com/tilt-dev/tilt-example-html/tree/faad605963b396b0863151802544fb01f6b414c6/0-base">GitHub</a>. This example is described in the Tilt&rsquo;s <a href="https://docs.tilt.dev/example_static_html.html">documentation</a> and you may already be familiar with it. It consists of a very simple shell script that serves a static HTML. In contrast to Tilt&rsquo;s example which leverages Docker and upstream Kubernetes, I will be using developer tools from the Red Hat&rsquo;s portfolio:</p>

<ul>
<li><a href="https://buildah.io/">buildah</a></li>
<li><a href="https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image">UBI container images</a></li>
<li><a href="https://developers.redhat.com/products/codeready-containers">CodeReady Containers</a></li>
</ul>


<p>In order to be able to use the Red Hat developer tools, I had to modify the original sample code. The sample code used in this tutorial can be found on <a href="https://github.com/noseka1/local-development-with-openshift-and-tilt">GitHub</a>. I recommend that you go ahead and briefly review it.</p>

<p>The overall setup consists of a Fedora 32 development machine where I installed buildah and CoreReady Containers (CRC) version 1.10. I installed Tilt version 0.13.4 which is the latest release of Tilt available at the time of this writing. If you plan to use Tilt along with CodeReady Containers, I recommend grabbing this or any future versions of Tilt, as this version includes a <a href="https://github.com/windmilleng/tilt/commit/7e9487816ea32ed086318ce7373c67d9febb6f36">patch</a> that makes Tilt work with CodeReady Containers without the need for further configuration. The Tilt binary can be downloaded from <a href="https://github.com/tilt-dev/tilt/releases">GitHub</a>.</p>

<p>Having the required tools in place, let&rsquo;s start by logging in into CRC and creating a new project:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ oc login
</span><span class='line'>$ oc new-project tilt-example</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s now focus  on configuring buildah to be able the pull and push images from the container registries. As you can see in the <a href="https://github.com/noseka1/local-development-with-openshift-and-tilt/blob/master/Dockerfile">Dockerfile</a>, our application uses the <code>registry.redhat.io/ubi8/ubi</code> container image as the base image. In order for buildah to be able to pull this image from the registry, we need to log in to this registry using the Red Hat Customer Portal credentials:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ buildah login registry.redhat.io</span></code></pre></td></tr></table></div></figure>


<p>Next, let&rsquo;s configure buildah to be able to push images into the CRC internal registry. The CRC registry endpoint uses a self-signed certificate. Buildah will refuse to communicate with the internal registry as the certificate is signed by an unknown authority. In order for buildah to be able to push images into the internal registry, you will need to add this registry to the list of insecure registries. On your development machine, edit <code>/etc/containers/registries.conf</code> and add the CRC internal registry to the list of insecure registries.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[registries.insecure]
</span><span class='line'>registries = [ 'default-route-openshift-image-registry.apps-crc.testing' ]</span></code></pre></td></tr></table></div></figure>


<p>In order for buildah to be able to push images into the CRC registry, we need to log in to this registry. For that, use the <code>oc</code> command to grab a token used for authentication against the registry:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ oc whoami --show-token
</span><span class='line'>7geTDzA6Mqa-NeXweTXtOFUJtEHocVShKl5yxtxqeB0</span></code></pre></td></tr></table></div></figure>


<p>Log in to the registry using the authentication token:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ buildah login \
</span><span class='line'>    --username unused \
</span><span class='line'>    --password 7geTDzA6Mqa-NeXweTXtOFUJtEHocVShKl5yxtxqeB0 \
</span><span class='line'>    default-route-openshift-image-registry.apps-crc.testing
</span><span class='line'>Login Succeeded!</span></code></pre></td></tr></table></div></figure>


<p>After successfully logging into the CRC internal registry, the buildah configuration is now complete. Finally, we can turn our attention to Tilt. First, let&rsquo;s review the <code>Tiltfile</code> which describes how Tilt will orchestrate our development workflow:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># push the container image to the CRC internal registry, project tilt-example
</span><span class='line'>default_registry(
</span><span class='line'>  'default-route-openshift-image-registry.apps-crc.testing/tilt-example',
</span><span class='line'>  host_from_cluster='image-registry.openshift-image-registry.svc:5000/tilt-example')
</span><span class='line'>
</span><span class='line'># use buildah to build and push the container image
</span><span class='line'>custom_build(
</span><span class='line'>  'example-html-image',
</span><span class='line'>  'buildah build-using-dockerfile --tag $EXPECTED_REF . && buildah push $EXPECTED_REF',
</span><span class='line'>  ['.'],
</span><span class='line'>  skips_local_docker=True)
</span><span class='line'>
</span><span class='line'># deploy Kubernetes resource
</span><span class='line'>k8s_yaml('kubernetes.yaml')
</span><span class='line'>
</span><span class='line'># make the application available on localhost:8000
</span><span class='line'>k8s_resource('example-html', port_forwards=8000)</span></code></pre></td></tr></table></div></figure>


<p>I annotated the <code>Tiltfile</code> with comments that explain the meaning of individual Tilt instructions. Ready to give it a shot? Just clone the git repository and run Tilt:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git clone https://github.com/noseka1/local-development-with-openshift-and-tilt
</span><span class='line'>$ cd local-development-with-openshift-and-tilt/
</span><span class='line'>$ tilt up</span></code></pre></td></tr></table></div></figure>


<p>After Tilt comes up, it will call buildah to pull the base image, build the application, and push the resulting image to the CRC internal registry. It will also deploy the application on Kubernetes by applying the <code>kubernetes.yaml</code> manifest referenced in the <code>Tiltfile</code>. If everything worked well, and the application pod starts up, you will see the &ldquo;Serving files on port 8000&rdquo; log message in the bottom pane:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/local_development_with_openshift_and_tilt.png"></p>

<p>At this point, you should be able to reach the running application on <code>localhost:8000</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl localhost:8000
</span><span class='line'>&lt;!doctype html&gt;
</span><span class='line'>&lt;html&gt;
</span><span class='line'>  &lt;body style="font-size: 30px; font-family: sans-serif; margin: 0;"&gt;
</span><span class='line'>    &lt;div style="display: flex; flex-direction: column; width: 100vw; height: 100vh; align-items: center; justify-content: center;"&gt;
</span><span class='line'>      &lt;img src="pets.png" style="max-width: 30vw; max-height: 30vh;"&gt;
</span><span class='line'>      &lt;div&gt;Hello cats!&lt;/div&gt;
</span><span class='line'>    &lt;/div&gt;
</span><span class='line'>  &lt;/body&gt;
</span><span class='line'>&lt;/html&gt;</span></code></pre></td></tr></table></div></figure>


<p>To experience how Tilt facilitates the local development, change the content of the <code>index.html</code> file. After you save your changes, Tilt will instantly re-run the loop and deploy the updated application.</p>

<h2>Conclusion</h2>

<p>In this blog, we described how Tilt can facilitate the local development of containerized applications. We demonstrated Tilt&rsquo;s capabilities in a practical example that showed Tilt working along with buildah and CodeReady Containers. In this introductory article, we were able to only scratch the surface. There is much more that Tilt has to offer, including live updates that can update the application without restarting the container, and which can drastically speed up the edit-compile-run loop. I encourage you to read through <a href="https://docs.tilt.dev/">Tilt&rsquo;s documentation</a> to learn more about this tool.</p>

<p>Do you use Tilt for development on OpenShift or Kubernetes? What&rsquo;s your opinion on Tilt? I would be happy to hear about your experiences. You can leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Speaking at Red Hat Summit 2020]]></title>
    <link href="http://alesnosek.com/blog/2020/04/26/speaking-at-red-hat-summit-2020/"/>
    <updated>2020-04-26T20:33:11-07:00</updated>
    <id>http://alesnosek.com/blog/2020/04/26/speaking-at-red-hat-summit-2020</id>
    <content type="html"><![CDATA[<p>This year&rsquo;s <a href="https://www.redhat.com/en/summit">Red Hat Summit</a> is provided as a Virtual Experience on April 28-29, 2020. I will be presenting on the topic: <em>Design considerations and patterns for event-driven microservices</em>. The presentation will be available in three different time zones, and will cover patterns like transactional outbox, CQRS, and more:</p>

<ul>
<li>EMEA: Wednesday, April 29, 1:00 p.m. CEST</li>
<li>NA &amp; LATAM: Wednesday, April 29, 1:00 p.m. EDT</li>
<li>APAC: Wednesday, April 29, 4:00 p.m. SGT</li>
</ul>


<p>More information about the session can be found in the <a href="https://summit.redhat.com/conference/sessions?p1=eyJzcGVha2VyIjpbXSwidGltZXNsb3QiOltdLCJkYXkiOltdLCJyb29tIjpbXSwibG9jYXRpb24iOltdLCJzb3J0b3JkZXIiOiJkYXRlIiwic3RhcnQiOiIiLCJmaW5pc2giOiIiLCJwYWdlbnVtYmVyIjoxLCJzaGFyZWlkIjoiIiwiY2F0ZWdvcmllcyI6e30sImtleXdvcmQiOiJEZXNpZ24gY29uc2lkZXJhdGlvbnMgYW5kIHBhdHRlcm5zIGZvciBldmVudC1kcml2ZW4gbWljcm9zZXJ2aWNlcyJ9">session catalog</a>.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/red_hat_summit_2020.png"></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[OpenShift UPI Using Static IPs]]></title>
    <link href="http://alesnosek.com/blog/2020/04/21/openshift-upi-using-static-ips/"/>
    <updated>2020-04-21T20:29:52-07:00</updated>
    <id>http://alesnosek.com/blog/2020/04/21/openshift-upi-using-static-ips</id>
    <content type="html"><![CDATA[<p>Recently, I have been working on the <a href="https://github.com/noseka1/openshift-auto-upi">openshift-auto-upi</a> project, which automates UPI deployments of OpenShift.  I was looking for a way to configure OpenShift nodes with static IP addresses. After several failed attempts, I found a working approach that can be easily automated. If you prefer using static IPs over the default DHCP provisioning, please read on as I share my approach with you.</p>

<p>The blog is published at <a href="https://www.openshift.com/blog/openshift-upi-using-static-ips">openshift.com/blog</a>.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Open Policy Agent, Part III &mdash; Integrating with Your Application]]></title>
    <link href="http://alesnosek.com/blog/2019/12/03/open-policy-agent-part-iii-integrating-with-your-application/"/>
    <updated>2019-12-03T12:46:10-08:00</updated>
    <id>http://alesnosek.com/blog/2019/12/03/open-policy-agent-part-iii-integrating-with-your-application</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2019/10/27/open-policy-agent-part-ii-developing-policies/">previous entry</a> to this series, we discussed developing policies with Open Policy Agent. In this final article in the series, we are going to focus on how you can integrate Open Policy Agent with your application.</p>

<!-- more -->


<h2>Integrating OPA with your application</h2>

<p>There are several options how you can integrate OPA with your application. If you happen to build your application using the Go language, you can link OPA as a library straight into your application. Otherwise, you will run OPA as a stand-alone service (daemon). If you deploy your application on Kubernetes, you can run OPA service as a side-car container along with your application services. This minimizes the communication latency between OPA and your application. It also avoids possible communication issues between OPA and your application due to network failures. If you are deploying on virtual machines, you can run one replica of the OPA service on each of your virtual machines to achieve the same benefits. In summary, deploying OPA as a side-car service or a host-local service is the recommended approach.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_integration.png"></p>

<p>Another deployment option would be running multiple OPA services behind a load balancer. Your application and OPA services would in this case talk over the network and the communication would go through the load balancer. You would incur the cost of network latency. However, I am not sure how would the overall reliability of this approach compare to the side-car approach. OPA documentation doesn&rsquo;t really mention this option of deploying multiple OPA services behind a load balancer. However, if you are building your application as a set of Lambda functions, then this might be the way to go:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_integration_lambda.png"></p>

<h2>Utilizing Open Policy Agent APIs</h2>

<p>Open Policy Agent comes with a whole set of APIs that you can use in order to utilize OPA to its full potential. I depicted the possible API integrations in the following diagram:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_integration_full.png"></p>

<p>In the diagram above, the green box is your application invoking policy queries against OPA. The purple services are optional services that you can include in your architecture. These services have to be implemented by yourself and they must expose APIs that are specified by OPA. Two blue boxes depict the Prometheus monitoring server and Kubernetes. OPA can integrate with them right away. In the diagram, the direction of the arrows between services is significant. The arrows indicate which service from the pair initiates the TCP connection. In the following subsections, let&rsquo;s take a closer look at each of these OPA interfaces.</p>

<h3>Open Policy Agent REST API</h3>

<p>This is the main API provided by OPA that your application uses to manage data and policies, and to execute queries. It is well described in the OPA&rsquo;s <a href="https://www.openpolicyagent.org/docs/latest/rest-api/">REST API documentation</a>. I would like to highlight two things that I learned about the OPA REST APIs:</p>

<p>First, OPA allows you to set watches on policy queries in order for you to be notified whenever the result of the query evaluation changes. Watches utilize the HTTP long polling mechanism. For additional details, you can refer to the <a href="https://www.openpolicyagent.org/docs/latest/rest-api/#watches">Watches</a> section of the OPA&rsquo;s documentation.</p>

<p>Second, the communication between the client (i.e. your application) and the OPA service can be protected using TLS. OPA authenticates itself to the client by presenting a valid TLS certificate. Client can authenticate itself to OPA either by presenting a client TLS certificate or by presenting a security token. And guess how OPA handles API authorization? Of course, by evaluating a Rego policy that you supply. For further details on OPA&rsquo;s security settings, refer to the <a href="https://www.openpolicyagent.org/docs/latest/security/">Security</a> section of OPA&rsquo;s documentation.</p>

<h3>Optional APIs</h3>

<p>These APIs are specified by OPA  and you can opt to implement them in order to gain additional functionality and better integrate OPA into your system.</p>

<p>If you recall, in the first part of the series we imported data and policies into OPA by pushing it via the REST APIs. Pushing the data and policies into OPA is not always a feasible option. For example, if OPA is deployed as an ephemeral pod on Kubernetes, it would be difficult to ensure that the API call is made each time right after the pod has started.  How can you make OPA work in such scenarios? You can deploy a service which implements the <a href="https://www.openpolicyagent.org/docs/latest/bundles/#bundle-service-api">Bundle Service API</a> and configure OPA to periodically pull up-to-date policies and data from this service. In the simplest case, the service can be implemented as a static HTTP server that hosts the policy and data bundles. However, if your use case demands it, you can implement a service that generates policies and data for OPA on-the-fly. When pulling the policies and data, OPA checks the ETag to find out if a new version is available. The Bundle service allows you to ensure that your policies are consistent across many OPA instances and enables you to hot reload them at any time.</p>

<p>OPA can be configured using a set of static configuration files. In Kubernetes, you would likely manage these configuration files as ConfigMaps. However, OPA comes with its own mechanism to manage configuration files from a central place. You can implement the <a href="https://www.openpolicyagent.org/docs/latest/discovery/">Discovery Service API</a> to expose the configuration files as discovery bundles to OPA instances. On the startup, OPA will download its configuration from the Discovery Service.</p>

<p>OPA can send <a href="https://www.openpolicyagent.org/docs/latest/status/">status</a> updates to remote HTTP servers that implement a simple <a href="https://www.openpolicyagent.org/docs/latest/status/#status-service-api">Status Service API</a> . You will be notified whenever OPA downloads and actives a new bundle. Notifications are issued for both policy+data bundles and discovery bundles.</p>

<p>OPA can periodically report <a href="https://www.openpolicyagent.org/docs/latest/decision-logs/">decision logs</a> to remote HTTP servers that implement a <a href="https://www.openpolicyagent.org/docs/latest/decision-logs/#decision-log-service-api">Decision Log Service API</a>. The reported decision logs record all the policy decisions made by OPA. How could you make use of it? You could implement a simple Decision Log Service that would run co-located with the OPA service and that would store the decision logs into a durable storage like Kafka. And here you go, an awesome audit log was born!</p>

<h3>Health and Monitoring APIs</h3>

<p>OPA exposes a <a href="https://www.openpolicyagent.org/docs/latest/rest-api/#health-api">Health API</a> for you to periodically verify that the OPA service is operational. If you are deploying OPA on top of Kubernetes,  you can leverage the Health API to define the <a href="https://www.openpolicyagent.org/docs/latest/deployments/#readiness-and-liveness-probes">liveness and readiness probes</a>. OPA also exposes Prometheus metrics to <a href="https://www.openpolicyagent.org/docs/latest/monitoring/">monitor</a> the performance of OPA API calls. Both health and monitoring APIs can be secured the same way as the OPA REST API which we discussed before.</p>

<h2>Where to go from here?</h2>

<p>In addition to the written sources that you can find on the web, I would like to point you to a couple of excellent presentations about Open Policy Agent hosted on YouTube:</p>

<ul>
<li><a href="https://www.youtube.com/watch?v=CDDsjMOtJ-c">Intro: Open Policy Agent - Torin Sandall, Styra (2018)</a></li>
<li><a href="https://www.youtube.com/watch?v=n94_FNhuzy4">Deep Dive: Open Policy Agent - Torin Sandall &amp; Tim Hinrichs, Styra (2019)</a></li>
</ul>


<p>If you are evaluating Open Policy Agent from the security perspective, this <a href="https://github.com/open-policy-agent/opa/blob/master/SECURITY_AUDIT.pdf">audit report</a> might be of interest to you as well.</p>

<h2>Conclusion</h2>

<p>In this article, we discussed several ways for how you can integrate Open Policy Agent with your application. We also described the set of APIs defined by OPA that you can utilize to take full advantage of Open Policy Agent.</p>

<p>Open Policy Agent is a young and fast-moving project. Despite my rather short experience with OPA, I can already recommend that you consider using Open Policy Agent in your project before spending time on implementing your own domain specific language for writing policies or coding your policies in a general-purpose programming language. OPA will keep the policies consistent across your system, will allow you to hot reload the policies at any time and will make policy decisions with very low latency for you.</p>

<p>So far, each of the open source projects came up with its own way how to implement access control. System administrators have to learn how to grant access permissions in the Apache HTTP server, Kubernetes, and fill in your favorite open source project here. It would be great if OPA&rsquo;s Rego language would become an open standard for describing access control rules across the open source ecosystem. I hope that the future will show that this is possible.</p>

<p>Regardless of what other projects decide for themselves, we are planning to utilize Open Policy Agent in the SaaS project I am involved with as a consultant. As we are moving forward,  I intend to share the experience that we gain with OPA with you in some of the future blog posts.</p>

<p>I hope that you found this blog series about Open Policy Agent helpful. If you have any questions or comments, please leave them in the comment section below. I look forward to hearing from you.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Open Policy Agent, Part II &mdash; Developing Policies]]></title>
    <link href="http://alesnosek.com/blog/2019/10/27/open-policy-agent-part-ii-developing-policies/"/>
    <updated>2019-10-27T20:37:08-07:00</updated>
    <id>http://alesnosek.com/blog/2019/10/27/open-policy-agent-part-ii-developing-policies</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2019/10/08/open-policy-agent-part-i-the-introduction/">previous part</a> of the series, we explored Open Policy Agent and implemented an ACL-based access control for our application. In this entry, I am going to share with you some of the discoveries that I made while evaluating Open Policy Agent in regards to policy design and development.</p>

<!-- more -->


<h2>Notes on Policy Design</h2>

<p>After evaluating policy rules, OPA returns a result of the policy decision to your application. This result is a JSON structure. Based on your requirements, this JSON structure can contain a single member holding a <em>true</em> or <em>false</em> (authorized/not authorized) value. However, you can create policies whose evaluation results in an arbitrarily complex JSON document. For example, OPA can return a list of nodes on which Kubernetes should schedule a workload.</p>

<p>In microservice applications, OAuth 2.0 is a rather popular authorization framework used to secure service’s APIs. It typically leverages JSON Web Tokens (JWT) to convey claims. OPA comes with built-in functions that can decode the token and validate its signature and expiration time. Furthermore, your policy rules can make decisions based on the claims included in the token. Just forward the token as an input to OPA and offload the entire token processing from your application!</p>

<p>OPA makes policy decisions based on the data stored in memory. In the case of large data sets, replicating all the data in memory can be impractical. While evaluating policy rules, is OPA able to reach out to an external data store to get additional data for decision making? For example, send a query to LDAP to grab additional attributes or look up data in an SQL database? Based on my research, I think there are two possible approaches for leveraging external data sources in OPA. First, there is a built-in <a href="https://www.openpolicyagent.org/docs/latest/language-reference/#http">HTTP</a> function that can fetch data from external HTTP services during policy evaluation. Second, you can leverage Partial Evaluation as described in this <a href="https://blog.openpolicyagent.org/write-policy-in-opa-enforce-policy-in-sql-d9d24db93bf4">blog post</a>. While partially evaluating policies, OPA doesn’t return a complete policy decision but instead it returns a set of conditions. It is left to you to translate this set of conditions into a query appropriate for your data store and execute the query in order to obtain the final policy decision. Note that regardless of which approach you choose, reaching out to external data stores will have negative impact on latency and reliability of your solution. Caching data in OPA’s memory is always a better option assuming that it suits your use case.</p>

<p>If you have raw data that would be difficult to write a policy against, you can pre-process that data into a form that better suits the policy writing before importing it into OPA. Moreover, if you have multiple sources of data, e.g. data from LDAP and Active Directory, you can merge them outside of OPA and load the merged form into OPA.</p>

<p>RBAC (Role-Based Access Control) and ABAC (Attribute-Based Access Control) are two frequently used policy models. Are you wondering if you can implement them using OPA? Of course you can! Follow these two links to find sample implementations of <a href="https://www.openpolicyagent.org/docs/latest/comparison-to-other-systems/#role-based-access-control-rbac">RBAC</a> and <a href="https://www.openpolicyagent.org/docs/latest/comparison-to-other-systems/#attribute-based-access-control-abac">ABAC</a>.</p>

<p>Hierarchical group permissions are commonly found in practice, e.g. parent group permissions are a superset of child group permissions. These models can be elegantly described using recursive rules. However, at the time of this writing, OPA doesn’t support <a href="https://github.com/open-policy-agent/opa/issues/947">recursion in policies</a>.</p>

<h2>Developing policies</h2>

<p>While learning the OPA’s Rego language, I appreciated the built-in interactive shell (REPL) that I could use to write and test my policies instantly. Just type <code>opa run</code> and you are good to go. Alternatively, you can go on-line and utilize the <a href="https://play.openpolicyagent.org/">Rego Playground</a>, too.</p>

<p>If you are dealing with complex policies, how do you ensure that you implemented your policies correctly? OPA <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-test-policies/">allows</a> you to write test cases which you can run against your policies. You can use data mocking and calculate test coverage. See also the command <code>opa test</code>.</p>

<p>Is the evaluation of your policies too slow? OPA comes with a <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-test-policies/#profiling">profiler</a> to report on time spent on evaluating policy expressions. See also the <code>opa eval</code> command.</p>

<p>OPA comes with a formatting tool <code>opa fmt</code> to format Rego policy files. You don’t need to fight battles with other developers about how the Rego files should be formatted!</p>

<p>OPA is a relatively new project, however, additional tooling and integrations with OPA are showing up quickly. If you like to use Visual Studio Code, there is a feature-rich <a href="https://marketplace.visualstudio.com/items?itemName=tsandall.opa">VS Code plugin</a> available for you. Rego syntax highlighting is available for several other editors like VIM, <a href="https://github.com/open-policy-agent/opa/tree/master/misc/syntax/atom">Atom</a>, and <a href="https://github.com/open-policy-agent/opa/tree/master/misc/syntax/textmate">TextMate</a>.</p>

<h2>Conclusion</h2>

<p>In this blog post, I shared with you several tips and approaches for how to design policies in Open Policy Agent. In the <a href="http://alesnosek.com/blog/2019/12/03/open-policy-agent-part-iii-integrating-with-your-application/">final article</a> in the series we will focus on how you can integrate Open Policy Agent with your application.</p>

<p>If you have any comments or questions, please use the comment section below. I look forward to hearing from you.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Open Policy Agent, Part I &mdash; The Introduction]]></title>
    <link href="http://alesnosek.com/blog/2019/10/08/open-policy-agent-part-i-the-introduction/"/>
    <updated>2019-10-08T07:13:38-07:00</updated>
    <id>http://alesnosek.com/blog/2019/10/08/open-policy-agent-part-i-the-introduction</id>
    <content type="html"><![CDATA[<p>Recently I was looking for a way to implement access control for microservices. I needed a solution that would allow defining complex authorization rules that could be enforced across many services. After searching the web, I discovered a very promising <a href="https://www.openpolicyagent.org/">Open Policy Agent</a> project that seems to be the right tool for the job. In this series of three blog posts, I am going to introduce Open Policy Agent to you and highlight how it can help you.</p>

<!-- more -->


<h2>What is Open Policy Agent?</h2>

<p>Open Policy Agent (OPA) is a policy engine that can be used to implement fine-grained access control for your application. For example, you can use OPA to implement <a href="https://www.openpolicyagent.org/docs/latest/http-api-authorization/">authorization</a> across microservices. However, there is much more that can be accomplished with OPA. For your inspiration, there are several open-source projects that integrate with OPA to implement fine-grained access control like <a href="https://github.com/open-policy-agent/opa-docker-authz">Docker</a>, <a href="https://github.com/open-policy-agent/opa-istio-plugin">Istio</a> and <a href="https://github.com/open-policy-agent/contrib">others</a>. Furthermore, OPA as a general-purpose policy engine, can be leveraged in use cases beyond access control, for instance to make advanced pod placement decisions in <a href="https://github.com/open-policy-agent/opa-kube-scheduler">Kubernetes</a>.</p>

<p>OPA can be deployed as a standalone service along with your microservices. In order to protect your application, each request coming to a microservice must be authorized before it can be processed. To check the authorization, the microservice makes an API call to OPA to decide whether the request is authorized or not. Note that while you can offload authorization decisions from your application to OPA, your application still has to implement the enforcement of those decisions. For example, your application can ask OPA the question <em>&ldquo;Is user Alice allowed to invoke GET /protected/resource?&rdquo;</em> and if OPA answers <em>&ldquo;No&rdquo;</em>, your application has to send HTTP 403 Forbidden back to Alice.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_basic_flow.png"></p>

<p>OPA is written in the Go language and its source code is available on <a href="https://github.com/open-policy-agent/opa">GitHub</a> under the Apache License 2.0. The Open Policy Agent project is hosted by <a href="https://www.cncf.io/">CNCF</a> as an incubating project.</p>

<h2>Making policy decisions</h2>

<p>In this section, I am going to explain how OPA works. Don&rsquo;t worry if everything is not clear to you right away. In the following section, we are going to work through a practical example which will help clarify the details.</p>

<p>What does it take for OPA to make a policy decision? In OPA, there are three inputs into the decision-making process:</p>

<ol>
<li><strong>Data</strong> is a set of facts about the outside world that OPA refers to while making a decision. For example, when controlling access based on the access control list, the data would be a list of users along with the permissions they were granted. Another example: when deciding where to place the next pod on the Kubernetes cluster, the data would be a list of Kubernetes nodes and their currently available capacity. Note that data may change over time and OPA caches its latest state in memory. The data must be provided to OPA in the JSON format.</li>
<li><strong>Query Input</strong> triggers the decision computation. It specifies the question that OPA should decide upon. The query input must be formatted as JSON. For instance, for the question <em>&ldquo;Is user Alice allowed to invoke GET /protected/resource?&rdquo;</em> the query input would contain parameters: <em>Alice</em>, <em>GET</em>, and <em>/protected/resource</em>.</li>
<li><strong>Policy</strong> specifies the computational logic that for the given <em>data</em> and <em>query input</em> yields a policy decision aka query result. The computational logic is described as a set of policy rules in the OPA&rsquo;s custom policy language called <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-write-policies/">Rego</a>. Note that OPA doesn&rsquo;t come with any pre-defined policies. OPA is a policy engine that is able to interpret a policy, however, in order to make use of it you have to create a policy yourself and provide it to OPA.</li>
</ol>


<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_policy_decision.png"></p>

<p>In order to make a policy decision, all three inputs (data, query input, and the policy) are fed into the Policy Engine. The Policy Engine interprets the rules included in the policy and based on the data and the query input makes a policy decision. The policy decision generated by the Policy Engine is a JSON document.</p>

<p>That is how OPA works from a high-level perspective. In the next section, we will dive into a practical example.</p>

<h2>Hands-on tutorial</h2>

<p>This section is a hands-on tutorial where I will walk you through an example of working with OPA. Although, all sorts of access control models can be implemented using OPA, the goal of this exercise is to implement access control using an Access Control List (ACL). So, let&rsquo;s get started!</p>

<h3>Creating data</h3>

<p>Access control list specifies which users have access to the application as well as what operations they are allowed to invoke. For the purposes of this tutorial, I came up with a simple ACL definition:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "alice": [
</span><span class='line'>    "read",
</span><span class='line'>    "write"
</span><span class='line'>  ],
</span><span class='line'>  "bob": [
</span><span class='line'>    "read"
</span><span class='line'>  ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>According to this ACL, a user named <code>alice</code> was granted <code>read</code> and <code>write</code> access to the application. In addition, a user named <code>bob</code> was given <code>read</code> access. No other users were given any access to the application. For now, you can save this ACL definition as a file called <code>myapi-acl.json</code>.</p>

<p>Note that later on we are going to inject this access control list as <em>data</em> into OPA to allow it to make policy decisions based on this list. How did we know what the structure of the ACL document looks like? As a matter of fact, OPA doesn&rsquo;t prescribe how you should structure your data. It only requires the data to be in a JSON format. The recommendation is to structure your data in a way that makes it easy to write policy rules against it. I followed this recommendation and the above access control list is what I came up with.</p>

<h3>Defining query input</h3>

<p>Next, we are going to define a structure of the <em>query input</em>. On each access to our application, we are going to ask OPA whether the given access is authorized or not. To answer that question, OPA needs to know the name of the user that is trying to access the application and the operation that the user is trying to invoke. Here is a sample query input that conveys the two query arguments to OPA :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "input": {
</span><span class='line'>    "user": "alice",
</span><span class='line'>    "operation": "write"
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>You can interpret this query input as the question: &ldquo;Is user <em>alice</em> allowed <em>write</em> access to the application?&rdquo;. Note that it&rsquo;s up to you how you structure your query input. OPA&rsquo;s only requirement is for the input to be in the JSON format.</p>

<h3>Writing Rego policy</h3>

<p>After we decided how our data and the query input look like, we can create a <em>policy</em> that implements the ACL semantics. Using the Rego language, let&rsquo;s create a policy with two rules <code>allow</code> and <code>whocan</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package myapi.policy
</span><span class='line'>
</span><span class='line'>import data.myapi.acl
</span><span class='line'>import input
</span><span class='line'>
</span><span class='line'>default allow = false
</span><span class='line'>
</span><span class='line'>allow {
</span><span class='line'>        access = acl[input.user]
</span><span class='line'>        access[_] == input.access
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>whocan[user] {
</span><span class='line'>        access = acl[user]
</span><span class='line'>        access[_] == input.access
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>The <code>allow</code>  rule checks whether the user is allowed access according to the ACL. It instructs the policy engine to first look up the user&rsquo;s record in ACL and then to check whether the operation the user is trying to invoke is included on user&rsquo;s permission list. Only if there is an ACL record for the given user and the user was granted given access permission, the allow rule results to <code>true</code>. Otherwise it results to <code>false</code>.</p>

<p>The second rule in our policy is the <code>whocan</code> rule. This rule takes the operation as the input argument. For the given operation, <code>whocan</code> rule returns a list of all users that are allowed to invoke the given operation.</p>

<p>You can save the above policy as a file called <code>myapi-policy.rego</code>. We are going to upload it into OPA in just a moment. At this point, both the ACL file <code>myapi-acl.json</code> we created earlier and the policy file  <code>myapi-policy.rego</code> are sitting in our working directory. It&rsquo;s now time to put OPA to work!</p>

<h3>Starting up Open Policy Agent service</h3>

<p>You can grab the OPA binary for your  platform (Linux, MacOS, or Windows) from <a href="https://github.com/open-policy-agent/opa/releases">GitHub</a>. After downloading the binary, start the OPA service by issuing the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ opa run --server</span></code></pre></td></tr></table></div></figure>


<p>OPA service is now up and listening on port <code>8181</code>. Next, we are going to upload the ACL file and the policy file into OPA. Note that OPA stores both the data and policies in memory and so if you restart the OPA service, you will have to reload both of the files.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_upload_policy_and_data.png"></p>

<p>First, upload the ACL file <code>myapi-acl.json</code> into OPA using the following <code>curl</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X PUT http://localhost:8181/v1/data/myapi/acl --data-binary @myapi-acl.json</span></code></pre></td></tr></table></div></figure>


<p>Next, upload the policy file <code>myapi-policy.rego</code> into OPA by issuing:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X PUT http://localhost:8181/v1/policies/myapi --data-binary @myapi-policy.rego</span></code></pre></td></tr></table></div></figure>


<h3>Invoking policy queries</h3>

<p>Finally, if everything went well, we are now ready to issue our first  query.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/open_policy_agent/opa_query_policy.png"></p>

<p>Let&rsquo;s ask OPA whether the user <code>alice</code> can invoke a <code>write</code> operation on our application:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X POST http://localhost:8181/v1/data/myapi/policy/allow \
</span><span class='line'>--data-binary '{ "input": { "user": "alice", "access": "write" } }' \
</span><span class='line'>| jq
</span><span class='line'>{
</span><span class='line'>  "result": true
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>The query result returned by OPA says that the user <code>alice</code> is authorized for writing. Our application would now proceed with executing the write operation. And what about <code>bob</code>? Is user <code>bob</code> allowed to write?</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X POST http://localhost:8181/v1/data/myapi/policy/allow \
</span><span class='line'>--data-binary '{ "input": { "user": "bob", "access": "write" } }' \
</span><span class='line'>| jq
</span><span class='line'>{
</span><span class='line'>  "result": false
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>The query result says it clearly. User <code>bob</code> is denied <code>write</code> access. Our application would return HTTP 403 Forbidden to <code>bob</code> at this point.</p>

<p>From what we have seen so far, a query result can be a simple <code>true</code> or <code>false</code> value. However, this is not a limitation that OPA would impose. OPA allows you to write policy rules that can yield an arbitrarily complex JSON structure. For example, the <code>whocan</code> rule that we defined in our policy, returns a JSON list.</p>

<p>Let&rsquo;s give it a try and ask OPA to return a list of users that were granted the <code>read</code> permission:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X POST http://localhost:8181/v1/data/myapi/policy/whocan \
</span><span class='line'>--data-binary '{ "input": { "access": "read" } }' \
</span><span class='line'>| jq
</span><span class='line'>{
</span><span class='line'>  "result": [
</span><span class='line'>    "alice",
</span><span class='line'>    "bob"
</span><span class='line'>  ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>In this article, we took an initial look at Open Policy Agent. After discussing how OPA works, we went through an example of implementing an Access Control List policy. In the <a href="http://alesnosek.com/blog/2019/10/27/open-policy-agent-part-ii-developing-policies/">next entry</a> to this series, we are going to dive deeper into developing policies with OPA.</p>

<p>I hope that you found this article useful. If you have any questions or comments, please add them to the comment section below. I look forward to hearing from you.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Future-Proof Monolithic Applications with Modular Design]]></title>
    <link href="http://alesnosek.com/blog/2019/09/23/future-proof-monolithic-applications-with-modular-design/"/>
    <updated>2019-09-23T14:34:26-07:00</updated>
    <id>http://alesnosek.com/blog/2019/09/23/future-proof-monolithic-applications-with-modular-design</id>
    <content type="html"><![CDATA[<p>The <a href="https://www.redhat.com/en/events/webinar/develop-deploy-deliver-continuously">Cloud Native Virtual Event</a>, presented by Red Hat, is coming up on October 10th, 2019. As part of the Development track, I will be co-presenting on the topic: <em>Future-proof monolithic applications with modular design</em>. If you are interested in hearing Eric Murphy and myself discussing the development of highly-modular applications, you can register for the event <a href="https://www.redhat.com/en/events/webinar/develop-deploy-deliver-continuously#registration">here</a>. As part of our presentation, we will be demonstrating a sample Quarkus + Vert.x application that can be deployed both as a monolith or as a set of microservices while using the same code and modular design.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Configuring Envoy to Auto-Discover Pods on Kubernetes]]></title>
    <link href="http://alesnosek.com/blog/2019/08/19/configuring-envoy-to-audo-discover-pods-on-kubernetes/"/>
    <updated>2019-08-19T11:04:51-07:00</updated>
    <id>http://alesnosek.com/blog/2019/08/19/configuring-envoy-to-audo-discover-pods-on-kubernetes</id>
    <content type="html"><![CDATA[<p>Pods on Kubernetes are ephemeral and can be created and destroyed at any time. In order for Envoy to load balance the traffic across pods, Envoy needs to be able to track the IP addresses of the pods over time. In this blog post, I am going to show you how to leverage Envoy&rsquo;s Strict DNS discovery in combination with a headless service in Kubernetes to accomplish this.</p>

<!-- more -->


<h2>Overview</h2>

<p>Envoy provides several <a href="https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/service_discovery">options</a> on how to discover back-end servers. When using the <a href="https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/service_discovery#strict-dns">Strict DNS</a> option,  Envoy will periodically query a specified DNS name. If there are multiple IP addresses included in the response to Envoy&rsquo;s query, each returned IP address will be considered a back-end server. Envoy will load balance the inbound traffic across all of them.</p>

<p>How to configure a DNS server to return multiple IP addresses to Envoy? Kubernetes comes with a <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a> object which, roughly speaking, provides two functions. It can create a single DNS name for a group of pods for discovery and it can load balance the traffic across those pods. We are not interested in the load balancing feature as we aim to use Envoy for that. However, we can make a good use of the discovery mechanism. The Service configuration we are looking for is called a <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">headless service</a> with selectors.</p>

<p>The diagram below depicts how to configure Envoy to auto-discover pods on Kubernetes. We are combining Envoy&rsquo;s Strict DNS service discovery with a headless service in Kubernetes:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/envoy_auto_discovery.png"></p>

<h2>Practical implementation</h2>

<p>To put this configuration into practice, I used <a href="https://www.okd.io/minishift/">Minishift</a> 3.11 which is a variant of Minikube developed by Red Hat. First, I deployed two replicas of the httpd server on Kubernetes to play the role of back-end services. Next, I created a headless service using the following definition:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">apiVersion</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">v1</span>
</span><span class='line'><span class="l-Scalar-Plain">kind</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Service</span>
</span><span class='line'><span class="l-Scalar-Plain">metadata</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd-discovery</span>
</span><span class='line'><span class="l-Scalar-Plain">spec</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusterIP</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">None</span>
</span><span class='line'>  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">http</span>
</span><span class='line'>      <span class="l-Scalar-Plain">port</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">8080</span>
</span><span class='line'>  <span class="l-Scalar-Plain">selector</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">app</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>  <span class="l-Scalar-Plain">type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ClusterIP</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that we are explicitly specifying &ldquo;None&rdquo; for the cluster IP in the service definition. As a result, Kubernetes creates the respective Endpoints object containing the IP addresses of the discovered httpd pods:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc get endpoints
</span><span class='line'>NAME              ENDPOINTS                                                        AGE
</span><span class='line'>httpd-discovery   172.17.0.21:8080,172.17.0.22:8080                                30s
</span></code></pre></td></tr></table></div></figure>


<p> If you ssh to one of the cluster nodes or rsh to any of the pods running on the cluster, you can verify that the DNS discovery is working:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>host httpd-discovery
</span><span class='line'>httpd-discovery.mynamespace.svc.cluster.local has address 172.17.0.21
</span><span class='line'>httpd-discovery.mynamespace.svc.cluster.local has address 172.17.0.22
</span></code></pre></td></tr></table></div></figure>


<p>Next, I used the container image <code>docker.io/envoyproxy/envoy:v1.7.0</code> to create an Envoy proxy. I deployed the proxy into the same Kubernetes namespace called <code>mynamespace</code> where I created the headless service before. A minimum Envoy configuration that can accomplish our goal looks as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">static_resources</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">listeners</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">listener_0</span>
</span><span class='line'>    <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>        <span class="l-Scalar-Plain">protocol</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">TCP</span>
</span><span class='line'>        <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0.0.0.0</span>
</span><span class='line'>        <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">10000</span>
</span><span class='line'>    <span class="l-Scalar-Plain">filter_chains</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">filters</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">envoy.http_connection_manager</span>
</span><span class='line'>        <span class="l-Scalar-Plain">config</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="l-Scalar-Plain">stat_prefix</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ingress_http</span>
</span><span class='line'>          <span class="l-Scalar-Plain">route_config</span><span class="p-Indicator">:</span>
</span><span class='line'>            <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">local_route</span>
</span><span class='line'>            <span class="l-Scalar-Plain">virtual_hosts</span><span class="p-Indicator">:</span>
</span><span class='line'>            <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">local_service</span>
</span><span class='line'>              <span class="l-Scalar-Plain">domains</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span><span class="s">&quot;*&quot;</span><span class="p-Indicator">]</span>
</span><span class='line'>              <span class="l-Scalar-Plain">routes</span><span class="p-Indicator">:</span>
</span><span class='line'>              <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">match</span><span class="p-Indicator">:</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">prefix</span><span class="p-Indicator">:</span> <span class="s">&quot;/&quot;</span>
</span><span class='line'>                <span class="l-Scalar-Plain">route</span><span class="p-Indicator">:</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">host_rewrite</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">cluster</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>          <span class="l-Scalar-Plain">http_filters</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">envoy.router</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusters</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>    <span class="l-Scalar-Plain">connect_timeout</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0.25s</span>
</span><span class='line'>    <span class="l-Scalar-Plain">type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">STRICT_DNS</span>
</span><span class='line'>    <span class="l-Scalar-Plain">dns_lookup_family</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">V4_ONLY</span>
</span><span class='line'>    <span class="l-Scalar-Plain">lb_policy</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ROUND_ROBIN</span>
</span><span class='line'>    <span class="l-Scalar-Plain">hosts</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd-discovery</span>
</span><span class='line'>          <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">8080</span>
</span><span class='line'><span class="l-Scalar-Plain">admin</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">access_log_path</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">/tmp/admin_access.log</span>
</span><span class='line'>  <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="l-Scalar-Plain">protocol</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">TCP</span>
</span><span class='line'>      <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">127.0.0.1</span>
</span><span class='line'>      <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">9901</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that in the above configuration,  I instructed Envoy to use the Strict DNS discovery and pointed it to the DNS name <code>httpd-discovery</code> that is managed by Kubernetes.</p>

<p>That&rsquo;s all that was needed to be done! Envoy is load balancing the inbound traffic across the two httpd pods now. And if you create a third pod replica, Envoy is going to route the traffic to this replica as well.</p>

<h2>Conclusion</h2>

<p>In this article, I shared with you the idea of using Envoy&rsquo;s Strict DNS service discovery in combination with the headless service in Kubernetes to allow Envoy to auto-discover the back-end pods. While writing this article, I discovered this <a href="https://blog.markvincze.com/how-to-use-envoy-as-a-load-balancer-in-kubernetes/">blog post</a> by Mark Vincze that describes the same idea and you should take a look at it as well.</p>

<p>This idea opens the door for you to utilize the advanced features of Envoy proxy in your microservices architecture. However, if you find yourself looking for a more complex solution down the road, I would suggest that you evaluate the <a href="https://istio.io/">Istio</a> project. Istio provides a control plane that can manage Envoy proxies for you achieving the so called service mesh.</p>

<p>Hope you found this article useful. If you are using Envoy proxy on top of Kubernetes I would be happy to hear about your experiences. You can leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Troubleshooting the Performance of Vert.x Applications, Part III &mdash; Troubleshooting Event Loop Delays]]></title>
    <link href="http://alesnosek.com/blog/2019/08/05/troubleshooting-the-performance-of-vert-dot-x-applications-troubleshooting-event-loop-delays/"/>
    <updated>2019-08-05T13:26:34-07:00</updated>
    <id>http://alesnosek.com/blog/2019/08/05/troubleshooting-the-performance-of-vert-dot-x-applications-troubleshooting-event-loop-delays</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays/">previous entry</a> to this series, we reviewed several techniques that help you to prevent event loop delays. However, even the best programmer makes mistakes. What should you do when your Vert.x application doesn&rsquo;t perform as expected? How to find out what part of your code is blocking the event loop threads? In the final part of the series, we are going to focus on troubleshooting event loop delays.</p>

<!-- more -->


<p>The event loop thread model is vastly different from the thread-per-request model employed by standard JEE or Spring frameworks. From my experience I can report that it takes developers some time to wrap their heads around it and that at the beginning they tend to make the mistake of introducing blocking calls into the event loop&rsquo;s code path. In the following sections, we will discuss several techniques of how to troubleshoot such situations.</p>

<h2>Blocked thread checker</h2>

<p>Vert.x comes with a built-in mechanism to detect delays on event loop and worker threads by checking the execution time of handlers that you registered with the Vert.x APIs. This mechanism operates in two steps. In the first step, Vert.x saves the timestamp of the moment when a handler starts executing. This <em>start timestamp</em> is saved to a storage attached to the thread that is executing the handler. Whenever the execution of the handler has completed the timestamp is reset. In the second step, Vert.x periodically checks the timestamps using a dedicated thread called <a href="https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/impl/BlockedThreadChecker.java"><code>vertx-blocked-thread-checker</code></a>. This thread is spawned by Vert.x during the creation of the Vert.x instance for example when you call <code>Vertx.vertx()</code>. The vertx-blocked-thread-checker thread can be seen in <a href="https://visualvm.github.io/">VisualVM</a>:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/vertx_blocked_thread_checker.png"></p>

<p>The blocked thread checker serves as a watchdog that periodically checks the Vert.x threads. It iterates over all Vert.x threads and for each thread it subtracts the threads start timestamp from the current time to compute how long the thread has already been executing the handler code. If the execution time exceeds the specified threshold a warning message is dropped into the logs:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-5,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">39</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-6,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">26</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-1,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">31</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-3,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">42</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-2,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">20</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-4,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">21</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>Mar 01, <span class="m">2019</span> 11:53:24 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-7,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">19</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span></code></pre></td></tr></table></div></figure>


<p>You can use grep to routinely search through your application logs for this message. Vert.x can also log the entire stack trace to help you pinpoint the location in your code where your handler is blocking the thread:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>Mar 24, <span class="m">2019</span> 9:34:23 AM io.vertx.core.impl.BlockedThreadChecker
</span><span class='line'>WARNING: Thread Thread<span class="o">[</span>vert.x-eventloop-thread-6,5,main<span class="o">]</span> has been blocked <span class="k">for</span> <span class="m">24915</span> ms, <span class="nb">time </span>limit is <span class="m">10</span> ms
</span><span class='line'>io.vertx.core.VertxException: Thread blocked
</span><span class='line'>        at java.lang.Thread.sleep<span class="o">(</span>Native Method<span class="o">)</span>
</span><span class='line'>        at MyComputingVerticle.start<span class="o">(</span>HelloServer.java:72<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.DeploymentManager.lambda<span class="nv">$doDeploy$8</span><span class="o">(</span>DeploymentManager.java:494<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.DeploymentManager<span class="nv">$$</span>Lambda<span class="nv">$8</span>/644460953.handle<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.ContextImpl.executeTask<span class="o">(</span>ContextImpl.java:320<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.EventLoopContext.lambda<span class="nv">$executeAsync$0</span><span class="o">(</span>EventLoopContext.java:38<span class="o">)</span>
</span><span class='line'>        at io.vertx.core.impl.EventLoopContext<span class="nv">$$</span>Lambda<span class="nv">$9</span>/1778535015.run<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute<span class="o">(</span>AbstractEventExecutor.java:163<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks<span class="o">(</span>SingleThreadEventExecutor.java:404<span class="o">)</span>
</span><span class='line'>        at io.netty.channel.nio.NioEventLoop.run<span class="o">(</span>NioEventLoop.java:462<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.SingleThreadEventExecutor<span class="nv">$5</span>.run<span class="o">(</span>SingleThreadEventExecutor.java:897<span class="o">)</span>
</span><span class='line'>        at io.netty.util.concurrent.FastThreadLocalRunnable.run<span class="o">(</span>FastThreadLocalRunnable.java:30<span class="o">)</span>
</span><span class='line'>        at java.lang.Thread.run<span class="o">(</span>Thread.java:748<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that the stack trace is generated at the moment when Vert.x detects that the threshold has been exceeded which is not necessarily the moment when the thread was actually blocking. In other words, it is probable but it is not guaranteed that the stack trace is showing the actual location where your event loop thread is blocking. You may need to examine multiple stack traces to pinpoint the right location.</p>

<p>You can tweak the watchdog check period and the warning thresholds. Here is an example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">VertxOptions</span> <span class="n">options</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">VertxOptions</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// check for blocked threads every 5s</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setBlockedThreadCheckInterval</span><span class="o">(</span><span class="mi">5</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setBlockedThreadCheckIntervalUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// warn if an event loop thread handler took more than 100ms to execute</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxEventLoopExecuteTime</span><span class="o">(</span><span class="mi">100</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxEventLoopExecuteTimeUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">MILLISECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// warn if an worker thread handler took more than 10s to execute</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxWorkerExecuteTime</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setMaxWorkerExecuteTimeUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'> <span class="c1">// log the stack trace if an event loop or worker handler took more than 20s to execute</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setWarningExceptionTime</span><span class="o">(</span><span class="mi">20</span><span class="o">);</span>
</span><span class='line'><span class="n">options</span><span class="o">.</span><span class="na">setWarningExceptionTimeUnit</span><span class="o">(</span><span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="n">Vertx</span> <span class="n">vertx</span> <span class="o">=</span> <span class="n">Vertx</span><span class="o">.</span><span class="na">vertx</span><span class="o">(</span><span class="n">options</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that the first check is not executed right at the application start but is delayed by one check period. In our example the first check is executed 5 seconds after the application start followed by checks executed every 5 seconds. The concrete thresholds shown in the example worked well for one of my projects, however, your mileage may vary.  Also, the very first execution of the handlers can be rather slow due to JVM class loading. Performance further improves when the JVM moves from interpreting the byte code to compiling it into the native code and running it directly on the CPU. Hence, you are more likely to hit the warning thresholds shortly after the application start than later on during the application run. It would be great if the threshold values could be dynamically adjusted to avoid the warnings before the JVM warms up. Unfortunately, there&rsquo;s no way how to adjust the thresholds in runtime.</p>

<p>It goes without saying that Vert.x only checks the threads that were created as a result of calling Vert.x APIs. If you instantiate your own thread pool outside of Vert.x those threads won&rsquo;t be checked. If you want Vert.x to check the threads in your custom thread pool, you can ask Vert.x to instantiate a checked thread pool for you like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// create a thread pool with 20 threads, set blocked thread warning threshold to 10 seconds</span>
</span><span class='line'><span class="n">WorkerExecutor</span> <span class="n">executor</span> <span class="o">=</span> <span class="n">vertx</span><span class="o">.</span><span class="na">createSharedWorkerExecutor</span><span class="o">(</span><span class="s">&quot;mypool&quot;</span><span class="o">,</span> <span class="mi">20</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>The good thing about the blocked thread checker is that it is able to detect thread delays regardless of whether they were caused by a call to a blocking API or by executing a compute intensive task. As such it can serve as a good indicator that there is something seriously wrong with your application.</p>

<h2>Inspecting stack traces</h2>

<p>Some event loop delays can be so subtle that they can go unnoticed by the blocked thread checker. Imagine a situation where you have a handler that causes a very short delay.  The blocked thread checker won&rsquo;t catch this short delay because it is not long enough to reach the threshold. However, if this handler is called very frequently, the aggregate delay caused by this handler can have a great impact on the performance of your application. How to uncover this kind of issue?</p>

<p>A good option is to analyze Java thread dumps by hand. You can refer to <a href="https://dzone.com/articles/how-analyze-java-thread-dumps">this article</a> if you want to learn how to do it. Alternatively, you can use a Java profiler like <a href="[https://visualvm.github.io/](https://visualvm.github.io/">VisualVM</a> to find out in what parts of your code the most processing time is spent. Instead of writing a long prose about how to use VisualVM to troubleshoot a Vert.x application, I created a short video for you. You can watch this demo using <a href="[https://jmeter.apache.org/](https://jmeter.apache.org/">JMeter</a> and VisualVM to figure out the cause of delays of the Vert.x event loop:</p>

<div style="text-align:center;">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/xxLVQMssLCk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>


<h2>Conclusion</h2>

<p>In this article, we talked about the blocked thread checker as a first indicator of the event loop delays. Next, I showed you in the video how to troubleshoot event loop delays in practice using VisualVM.</p>

<p>I hope that I didn&rsquo;t scare you throughout this series by analyzing all the things that can go wrong when working with the thread model Vert.x is based on. In reality it&rsquo;s not so bad. One just has to pay attention to the event loop model while coding. The awesome performance that Vert.x applications can achieve is definitely a sufficient reward for the extra effort.</p>

<p>If you got some battle scars while working with the event loop thread model in Vert.x, I would be interested in hearing your stories. Also, let me know if you found the video demonstration helpful or if you have suggestions for future videos. If you have any further questions or comments, feel free to add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Troubleshooting the Performance of Vert.x Applications, Part II &mdash; Preventing Event Loop Delays]]></title>
    <link href="http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays/"/>
    <updated>2019-07-22T11:15:42-07:00</updated>
    <id>http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays</id>
    <content type="html"><![CDATA[<p>In the <a href="http://alesnosek.com/blog/2019/06/30/troubleshooting-the-performance-of-vert-dot-x-applications-part-i-the-event-loop-model/">previous part</a> of the series, we took a closer look at the event loop model. In this article, we are going to discuss several techniques that help you to prevent event loop delays.</p>

<!-- more -->


<p>The causes of event loop delays can be divided into two categories. The first category contains event loop delays caused by a handler calling a blocking API. The second category covers delays caused by a handler code taking a great amount of CPU time to complete. Let&rsquo;s start with the first category and talk about blocking API calls.</p>

<h2>Working with blocking APIs</h2>

<p>Calling a blocking API on the event loop thread is especially hurtful for the performance of your application and you should avoid it at all cost. When you call a blocking API from the event loop thread, the event loop thread will be put to sleep, i.e. it will relinquish the CPU. The duration of the sleep can be rather long in comparison to how much work the event loop thread could have accomplished if it would remain executing on the CPU. This is going to result in a serious decrease of the throughput of your application. In addition to impacting the throughput, the latency of your application is going to raise, too. Because as the event loop thread is sleeping no processing is taking place and so all the outstanding work is going to be pushed back by the duration of the sleep.</p>

<p>Common examples of blocking APIs that you should not call from the event loop thread are:</p>

<ul>
<li>&ldquo;Old&rdquo; Java  I/O APIs found in the <code>java.io</code> package</li>
<li>JDBC APIs</li>
<li>Locking APIs in the <code>java.util.concurrent.locks</code> package</li>
<li>Using <code>synchronized</code> keyword in your code</li>
<li>Other blocking APIs</li>
</ul>


<p>You should also check the various third-party libraries you may be using to ensure that their APIs are non-blocking. Sometimes the differences can be really subtle. For example, if you are using <a href="https://logging.apache.org/log4j/2.x/">Apache Log4j 2</a> library for logging, you may want to configure it to use <a href="https://logging.apache.org/log4j/log4j-2.0/manual/async.html">asynchronous loggers</a> when logging from the event loop.</p>

<p>There are situations where you cannot avoid using blocking APIs. A typical example is when a third-party library you want to use provides only blocking APIs. As there is no way how to execute a blocking API on the event loop thread without putting this thread to sleep, your only option in Vert.x is to offload the blocking calls to a worker thread. I am going to show you two techniques how you can accomplish this.</p>

<p>The first technique is straight forward. It leverages the <code>executeBlocking</code> method provided by Vert.x. In the following example, the event loop thread schedules a <code>blockingCodeHandler</code> to run on a worker thread by calling the <code>vertx.executeBlocking()</code> method. After the execution of the <code>blockingCodeHandler</code> is complete, the <code>resultHandler</code> will be executed  on the event loop thread that made the original <code>vertx.executeBlocking()</code> call:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">class</span> <span class="nc">ExecuteBlockingExample</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// on the event loop thread</span>
</span><span class='line'>      <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Calling from &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">Future</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">blockingCodeHandler</span> <span class="o">=</span> <span class="n">future</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// executed on a worker thread</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Work executed on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>          <span class="n">future</span><span class="o">.</span><span class="na">complete</span><span class="o">(</span><span class="s">&quot;OK&quot;</span><span class="o">);</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">AsyncResult</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">resultHandler</span> <span class="o">=</span> <span class="n">result</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// back on the calling event loop thread</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Result &#39;&quot;</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="na">result</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; received on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">executeBlocking</span><span class="o">(</span><span class="n">blockingCodeHandler</span><span class="o">,</span> <span class="n">resultHandler</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>After running the example code, you will see the following output:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">Calling</span> <span class="n">from</span> <span class="n">vert</span><span class="o">.</span><span class="na">x</span><span class="o">-</span><span class="n">eventloop</span><span class="o">-</span><span class="n">thread</span><span class="o">-</span><span class="mi">0</span>
</span><span class='line'><span class="n">Work</span> <span class="n">executed</span> <span class="n">on</span> <span class="n">vert</span><span class="o">.</span><span class="na">x</span><span class="o">-</span><span class="n">worker</span><span class="o">-</span><span class="n">thread</span><span class="o">-</span><span class="mi">0</span>
</span><span class='line'><span class="n">Result</span> <span class="err">&#39;</span><span class="n">OK</span><span class="err">&#39;</span> <span class="n">received</span> <span class="n">on</span> <span class="n">vert</span><span class="o">.</span><span class="na">x</span><span class="o">-</span><span class="n">eventloop</span><span class="o">-</span><span class="n">thread</span><span class="o">-</span><span class="mi">0</span>
</span></code></pre></td></tr></table></div></figure>


<p>The second technique for offloading the blocking API calls to a worker thread is a bit more involved. We are going to deploy a worker verticle and send it the work as a message using the event bus. After the worker thread completes the work it will reply sending the result back to us.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">AbstractVerticle</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">(</span><span class="n">Future</span><span class="o">&lt;</span><span class="n">Void</span><span class="o">&gt;</span> <span class="n">startFuture</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// work handler</span>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">Message</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">handler</span> <span class="o">=</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Received message on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'>          <span class="c1">// do work</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Working ...&quot;</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>          <span class="n">message</span><span class="o">.</span><span class="na">reply</span><span class="o">(</span><span class="s">&quot;OK&quot;</span><span class="o">);</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// wait for work</span>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">eventBus</span><span class="o">().</span><span class="na">consumer</span><span class="o">(</span><span class="s">&quot;worker&quot;</span><span class="o">,</span> <span class="n">handler</span><span class="o">).</span><span class="na">completionHandler</span><span class="o">(</span><span class="n">r</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">startFuture</span><span class="o">.</span><span class="na">complete</span><span class="o">();</span>
</span><span class='line'>      <span class="o">});</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">},</span> <span class="k">new</span> <span class="nf">DeploymentOptions</span><span class="o">().</span><span class="na">setWorker</span><span class="o">(</span><span class="kc">true</span><span class="o">));</span>
</span><span class='line'>
</span><span class='line'><span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">AbstractVerticle</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// reply handler</span>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">AsyncResult</span><span class="o">&lt;</span><span class="n">Message</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;&gt;&gt;</span> <span class="n">replyHandler</span> <span class="o">=</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span>
</span><span class='line'>              <span class="s">&quot;Received reply &#39;&quot;</span> <span class="o">+</span> <span class="n">message</span><span class="o">.</span><span class="na">result</span><span class="o">().</span><span class="na">body</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; on &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// dispatch work</span>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">eventBus</span><span class="o">().</span><span class="na">send</span><span class="o">(</span><span class="s">&quot;worker&quot;</span><span class="o">,</span> <span class="s">&quot;request&quot;</span><span class="o">,</span> <span class="n">replyHandler</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>After running the above code  you will receive the following output:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>Received message on vert.x-worker-thread-1
</span><span class='line'>Working ...
</span><span class='line'>Received reply <span class="s1">&#39;OK&#39;</span> on vert.x-eventloop-thread-0
</span></code></pre></td></tr></table></div></figure>


<h2>Executing compute intensive tasks</h2>

<p>What is a compute intensive task? It is a task that makes heavy use of CPU and memory. Common examples of compute intensive tasks are parsing, encryption, compression and others. Executing compute intensive task within the event loop handler doesn&rsquo;t affect the throughput of your application because the event loop thread is busy doing useful work which would need to be done anyway. However, as the event loop thread is kept busy, other handlers on the event loop will be processed with a delay. How can we improve the situation and allow other handlers to be processed in a timely fashion?</p>

<p>Let&rsquo;s assume that you are able to chunk up the compute intensive task into several chunks. Then instead of running the entire compute intensive task at once:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">workChunk1</span><span class="o">();</span>
</span><span class='line'><span class="n">workChunk2</span><span class="o">();</span>
</span><span class='line'><span class="n">workChunk3</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can distribute the execution of individual chunks in time allowing the event loop to process other handlers in between. In the following example, we are creating pauses of 100 milliseconds between the work chunks to allow the event loop to interleave other handlers:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kt">long</span> <span class="n">delay</span> <span class="o">=</span> <span class="mi">100</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="n">workChunk1</span><span class="o">();</span>
</span><span class='line'><span class="n">vertx</span><span class="o">.</span><span class="na">setTimer</span><span class="o">(</span><span class="n">delay</span><span class="o">,</span> <span class="n">timerId</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">workChunk2</span><span class="o">();</span>
</span><span class='line'>  <span class="n">vertx</span><span class="o">.</span><span class="na">setTimer</span><span class="o">(</span><span class="n">delay</span><span class="o">,</span> <span class="n">timerId2</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">workChunk3</span><span class="o">();</span>
</span><span class='line'>  <span class="o">});</span>
</span><span class='line'><span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>You may encounter scenarios where you won&rsquo;t be able to chunk up the compute intensive task. For example, the compute intensive task&rsquo;s code is contained within a third-party library and executes all at once. In this case, you will have to defer to running this task on a worker thread and incur the cost of context switching. The operating system scheduler will periodically preempt the compute intensive task to prevent it from hogging the CPU and giving your event loop threads a chance to run.</p>

<h2>Conclusion</h2>

<p>In this article, we discussed how to work with blocking APIs in Vert.x. A blocking API call has to be made on a worker thread and not on an event loop thread. Futhermore, we described a technique that allows you to execute compute intensive tasks on the event loop without considerably delaying the processing of other tasks on the same event loop.</p>

<p>If you have any comments or questions please feel free to use the comment section below. In the final article in the series we will cover some techniques for troubleshooting event loop delays.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Installing OpenShift 4.1 Using Libvirt and KVM]]></title>
    <link href="http://alesnosek.com/blog/2019/07/08/installing-openshift-4-dot-1-using-libvirt-and-kvm/"/>
    <updated>2019-07-08T11:53:54-07:00</updated>
    <id>http://alesnosek.com/blog/2019/07/08/installing-openshift-4-dot-1-using-libvirt-and-kvm</id>
    <content type="html"><![CDATA[<p>In this blog post, I am going to talk about how I installed OpenShift 4.1 on a Fedora laptop with 16 GB of RAM. If you are interested in deploying your own OpenShift instance whether for evaluation or testing please follow along with me.</p>

<!-- more -->


<p>OpenShift 4.1 is the first GA release in the OpenShift 4 series. It is a significant leap forward in the evolution of OpenShift mainly due to the incorporation of features developed by the folks at CoreOS. In order to take a closer look at the latest and greatest version of OpenShift, I installed OpenShift 4.1 on my laptop using Libvirt and KVM. How did I accomplish this?</p>

<p>I essentially followed the <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html">guide</a> for installing the OpenShift cluster on bare metal and I recommend that you read this guide first. After you make yourself familiar with the bare metal installation process, read on to learn the details on how I made this process work on Libvirt and KVM.</p>

<h2>Deployment overview</h2>

<p>First, let&rsquo;s take a look at the diagram showing the deployment of the OpenShift cluster on Libvirt/KVM. In addition to the OpenShift cluster nodes, the diagram also depicts supplementary pieces of the user-provisioned infrastructure that you will need to deploy:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/openshift_4_on_libvirt.png"></p>

<p>In the diagram, you can see that there is an HTTP server and an oc client installed directly on the host machine. The remaining boxes in the diagram are virtual machines. I outlined the purpose of the virtual machines for you in the following table:</p>

<table>
<thead>
<tr>
<th> VM Name </th>
<th> Operating System </th>
<th> Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td> <em>dns</em> </td>
<td> RHEL7 </td>
<td> Custom Dnsmasq DNS server used by the load balancer, bootstrap node and OpenShift nodes. </td>
</tr>
<tr>
<td> <em>loadbalancer</em> </td>
<td> RHEL 7 </td>
<td> HAProxy load balancer. Facilitates bootstrapping, balances the load between the master nodes and also between the ingress router pods. </td>
</tr>
<tr>
<td> <em>bootstrap</em> </td>
<td> RHCOS </td>
<td> The bootstrap machine. Used one-time to initialize the OpenShift cluster. </td>
</tr>
<tr>
<td> <em>master</em> </td>
<td> RHCOS </td>
<td> OpenShift master node. </td>
</tr>
<tr>
<td> <em>worker-1</em> </td>
<td> RHCOS </td>
<td> OpenShift worker node. </td>
</tr>
</tbody>
</table>


<p>Note that the virtual machines are deployed across two Libvirt networks: <code>openshift-dns</code> and <code>openshift-cluster</code>. Using two Libvirt networks allowed me to meet the OpenShift DNS requirements and I will elaborate on this design later on in this post.</p>

<p>After reviewing the big picture, let&rsquo;s roll up our sleeves and get to work. We are going to deal with the HTTP server first.</p>

<h2>Setting up HTTP server</h2>

<p>The OpenShift installation process assumes installation on empty virtual machines with no operating system pre-installed. There are two provisioning methods available to choose from. You can either provision OpenShift nodes by booting from an ISO image or you can leverage the PXE boot. I find the PXE boot option to take a bit more effort to configure and hence went with the ISO image method.</p>

<p>Using the ISO image method, you are supposed to boot the virtual machines using the <code>rhcos-4.1.0-x86_64-installer.iso</code> CD-ROM image. During the boot from this image, the Red Hat CoreOS installer starts up and provisions an empty virtual machine in two steps:</p>

<ol>
<li>It downloads a disk image <code>rhcos-4.1.0-x86_64-metal-bios.raw.gz</code> from a URL you specify and writes it to the virtual machine&rsquo;s disk.</li>
<li>It downloads one of the ignition files (e.g. <code>bootstrap.ign</code>, <code>master.ign</code>, or <code>worker.ign</code>) and installs it on the virtual machine&rsquo;s file system.  This ignition file contains configuration required for the bootstrap of the OpenShift cluster that is triggered on the next reboot.</li>
</ol>


<p>You are expected to host the aforementioned files on an HTTP server that is reachable from the OpenShift nodes during the provisioning process. To meet this requirement, I installed an Apache HTTP server on my Fedora host machine and copied the disk image and ignition files to the <code>/var/www/html</code> directory which is the default <code>DocumentRoot</code> directory on a Fedora host.</p>

<h2>Addressing OpenShift DNS requirements</h2>

<p>OpenShift <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html#installation-dns-user-infra_installing-bare-metal">requires</a> a set of records to be configured in your DNS. In addition to simple A records, you must also configure a wildcard DNS record that points to the load balancer and an SRV DNS record for each of the etcd nodes.</p>

<p>Libvirt allows you to insert custom A and SRV records into DNS. You can specify them using the <a href="https://libvirt.org/formatnetwork.html">network descriptor</a>. However, Libvirt doesn&rsquo;t support creating wildcard DNS records. The respective feature request can be found <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1532856">here</a>. It would be great if it would be possible to meet the OpenShift DNS requirements by just configuring the DNS records in the Libvirt&rsquo;s network descriptor. However, as the wildcard DNS records were not supported at the time of this writing, I had to look for an alternative solution. After giving it some thought, I decided to spin up my own DNS server and instructed Libvirt to forward the DNS queries sent by the OpenShift nodes to this server. In order to achieve this, I had to define two networks in Libvirt: <code>openshift-dns</code> and <code>openshift-cluster</code>.</p>

<p>Let&rsquo;s tackle the <code>openshift-dns</code> network first. A single virtual machine is connected to this network. This virtual machine hosts the custom DNS server. Here is the respective network XML descriptor:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;network&gt;</span>
</span><span class='line'>  <span class="nt">&lt;name&gt;</span>openshift-dns<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>  <span class="nt">&lt;forward</span> <span class="na">mode=</span><span class="s">&#39;nat&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;nat&gt;</span>
</span><span class='line'>      <span class="nt">&lt;port</span> <span class="na">start=</span><span class="s">&#39;1024&#39;</span> <span class="na">end=</span><span class="s">&#39;65535&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/nat&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/forward&gt;</span>
</span><span class='line'>  <span class="nt">&lt;bridge</span> <span class="na">name=</span><span class="s">&#39;virbr-oshd&#39;</span> <span class="na">stp=</span><span class="s">&#39;on&#39;</span> <span class="na">delay=</span><span class="s">&#39;0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;mac</span> <span class="na">address=</span><span class="s">&#39;52:54:00:2c:00:00&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;domain</span> <span class="na">name=</span><span class="s">&#39;mycluster.example.com&#39;</span> <span class="na">localOnly=</span><span class="s">&#39;no&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;ip</span> <span class="na">address=</span><span class="s">&#39;192.168.130.1&#39;</span> <span class="na">netmask=</span><span class="s">&#39;255.255.255.0&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;dhcp&gt;</span>
</span><span class='line'>      <span class="nt">&lt;range</span> <span class="na">start=</span><span class="s">&#39;192.168.130.10&#39;</span> <span class="na">end=</span><span class="s">&#39;192.168.130.254&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:00:10&#39;</span> <span class="na">name=</span><span class="s">&#39;dns.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.130.10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dhcp&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/ip&gt;</span>
</span><span class='line'><span class="nt">&lt;/network&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see in the descriptor, I prefer to manage virtual machine&rsquo;s MAC addresses and the associated IP addresses and host names by hand. The virtual machine <code>dns</code> that hosts my DNS server is connected to the <code>openshift-dns</code> network by including these settings in its domain configuration:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;domain</span> <span class="na">type=</span><span class="s">&#39;kvm&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;name&gt;</span>dns.mycluster.example.com<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>  ...
</span><span class='line'>    <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">&#39;network&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;mac</span> <span class="na">address=</span><span class="s">&#39;52:54:00:2c:00:10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;source</span> <span class="na">network=</span><span class="s">&#39;openshift-dns&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;model</span> <span class="na">type=</span><span class="s">&#39;virtio&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;address</span> <span class="na">type=</span><span class="s">&#39;pci&#39;</span> <span class="na">domain=</span><span class="s">&#39;0x0000&#39;</span> <span class="na">bus=</span><span class="s">&#39;0x00&#39;</span> <span class="na">slot=</span><span class="s">&#39;0x03&#39;</span> <span class="na">function=</span><span class="s">&#39;0x0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/interface&gt;</span>
</span><span class='line'>    ...
</span><span class='line'><span class="nt">&lt;/domain&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>I installed Dnsmasq on this <code>dns</code> virtual machine and replaced the content of <code>/etc/dnsmasq.conf</code> with my own configuration:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ini'><span class='line'><span class="na">local</span><span class="o">=</span><span class="s">/mycluster.example.com/</span>
</span><span class='line'><span class="na">address</span><span class="o">=</span><span class="s">/apps.mycluster.example.com/192.168.131.10</span>
</span><span class='line'><span class="na">srv-host</span><span class="o">=</span><span class="s">_etcd-server-ssl._tcp.mycluster.example.com,master.mycluster.example.com,2380,0,10</span>
</span><span class='line'><span class="err">no-hosts</span>
</span><span class='line'><span class="na">addn-hosts</span><span class="o">=</span><span class="s">/etc/dnsmasq.openshift.addnhosts</span>
</span><span class='line'><span class="na">conf-dir</span><span class="o">=</span><span class="s">/etc/dnsmasq.d,.rpmnew,.rpmsave,.rpmorig</span>
</span></code></pre></td></tr></table></div></figure>


<p>The listing of the <code>/etc/dnsmasq.openshift.addnhosts</code> file referred to in the above configuration looks as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>192.168.130.10 dns.mycluster.example.com
</span><span class='line'>192.168.131.10 loadbalancer.mycluster.example.com  api.mycluster.example.com  api-int.mycluster.example.com
</span><span class='line'>192.168.131.11 bootstrap.mycluster.example.com
</span><span class='line'>192.168.131.12 master.mycluster.example.com  etcd-0.mycluster.example.com
</span><span class='line'>192.168.131.13 worker-1.mycluster.example.com
</span></code></pre></td></tr></table></div></figure>


<p>This configuration addresses the user-provisioned DNS requirements as specified in the <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html">installation guide</a>.</p>

<p>In the next step, we want to make the load balancer machine and OpenShift nodes resolve their DNS queries using our custom DNS server. In order to achieve that, we define a second Libvirt network called <code>openshift-cluster</code> and place the load balancer and OpenShift nodes onto this network. The definition of the <code>openshift-cluster</code> network looks like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;network&gt;</span>
</span><span class='line'>  <span class="nt">&lt;name&gt;</span>openshift-cluster<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>  <span class="nt">&lt;forward</span> <span class="na">mode=</span><span class="s">&#39;nat&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;nat&gt;</span>
</span><span class='line'>      <span class="nt">&lt;port</span> <span class="na">start=</span><span class="s">&#39;1024&#39;</span> <span class="na">end=</span><span class="s">&#39;65535&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/nat&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/forward&gt;</span>
</span><span class='line'>  <span class="nt">&lt;bridge</span> <span class="na">name=</span><span class="s">&#39;virbr-osh&#39;</span> <span class="na">stp=</span><span class="s">&#39;on&#39;</span> <span class="na">delay=</span><span class="s">&#39;0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;mac</span> <span class="na">address=</span><span class="s">&#39;52:54:00:2c:01:00&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;domain</span> <span class="na">name=</span><span class="s">&#39;mycluster.example.com&#39;</span> <span class="na">localOnly=</span><span class="s">&#39;no&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;dns&gt;</span>
</span><span class='line'>    <span class="nt">&lt;forwarder</span> <span class="na">addr=</span><span class="s">&#39;192.168.130.10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/dns&gt;</span>
</span><span class='line'>  <span class="nt">&lt;ip</span> <span class="na">address=</span><span class="s">&#39;192.168.131.1&#39;</span> <span class="na">netmask=</span><span class="s">&#39;255.255.255.0&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;dhcp&gt;</span>
</span><span class='line'>      <span class="nt">&lt;range</span> <span class="na">start=</span><span class="s">&#39;192.168.131.10&#39;</span> <span class="na">end=</span><span class="s">&#39;192.168.131.254&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:10&#39;</span> <span class="na">name=</span><span class="s">&#39;loadbalancer.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.10&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:11&#39;</span> <span class="na">name=</span><span class="s">&#39;bootstrap.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.11&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:12&#39;</span> <span class="na">name=</span><span class="s">&#39;master.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.12&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;host</span> <span class="na">mac=</span><span class="s">&#39;52:54:00:2c:01:13&#39;</span> <span class="na">name=</span><span class="s">&#39;worker-1.mycluster.example.com&#39;</span> <span class="na">ip=</span><span class="s">&#39;192.168.131.13&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dhcp&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/ip&gt;</span>
</span><span class='line'><span class="nt">&lt;/network&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note the <code>&lt;forwarder addr='192.168.130.10'/&gt;</code> setting which allows all DNS requests from the load balancer and OpenShift nodes deployed on this network to be forwarded to our custom DNS server. Remember that the IP address <code>192.168.130.10</code> is the address of our custom DNS server that we configured previously.</p>

<p>With the DNS configuration out of the way, let&rsquo;s continue with deploying a load balancer in the next section.</p>

<h2>Setting up a load balancer</h2>

<p>Installing OpenShift on a user-provisioned infrastructure requires you to provision a load balancer. The details on how the load balancer should be configured can be found in the <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html#installation-network-user-infra_installing-bare-metal">networking requirements</a> section of the OpenShift installation guide.</p>

<p>The load balancer is used during the bootstrapping process to route the requests to the bootstrap and the master nodes. After the OpenShift installation is complete, the load balancer remains part of the deployment and balances load between the master nodes and also between the ingress router pods.</p>

<p>I created a dedicated virtual machine called <code>loadbalancer</code> and installed HAProxy on top of it. The HAProxy configuration is pretty straight forward. Here is the listing of the <code>/etc/haproxy/haproxy.cfg</code> file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>global
</span><span class='line'>    log         127.0.0.1 local2 info
</span><span class='line'>    chroot      /var/lib/haproxy
</span><span class='line'>    pidfile     /var/run/haproxy.pid
</span><span class='line'>    maxconn     4000
</span><span class='line'>    user        haproxy
</span><span class='line'>    group       haproxy
</span><span class='line'>    daemon
</span><span class='line'>
</span><span class='line'>defaults
</span><span class='line'>    timeout connect         5s
</span><span class='line'>    timeout client          30s
</span><span class='line'>    timeout server          30s
</span><span class='line'>    log                     global
</span><span class='line'>
</span><span class='line'>frontend kubernetes_api
</span><span class='line'>    bind 0.0.0.0:6443
</span><span class='line'>    default_backend kubernetes_api
</span><span class='line'>
</span><span class='line'>backend kubernetes_api
</span><span class='line'>    balance roundrobin
</span><span class='line'>    option ssl-hello-chk
</span><span class='line'>    server bootstrap bootstrap.mycluster.example.com:6443 check
</span><span class='line'>    server master master.mycluster.example.com:6443 check
</span><span class='line'>
</span><span class='line'>frontend machine_config
</span><span class='line'>    bind 0.0.0.0:22623
</span><span class='line'>    default_backend machine_config
</span><span class='line'>
</span><span class='line'>backend machine_config
</span><span class='line'>    balance roundrobin
</span><span class='line'>    option ssl-hello-chk
</span><span class='line'>    server bootstrap bootstrap.mycluster.example.com:22623 check
</span><span class='line'>    server master master.mycluster.example.com:22623 check
</span><span class='line'>
</span><span class='line'>frontend router_https
</span><span class='line'>    bind 0.0.0.0:443
</span><span class='line'>    default_backend router_https
</span><span class='line'>
</span><span class='line'>backend router_https
</span><span class='line'>    balance roundrobin
</span><span class='line'>    option ssl-hello-chk
</span><span class='line'>    server worker-1 worker-1.mycluster.example.com:443 check
</span><span class='line'>
</span><span class='line'>frontend router_http
</span><span class='line'>    mode http
</span><span class='line'>    option httplog
</span><span class='line'>    bind 0.0.0.0:80
</span><span class='line'>    default_backend router_http
</span><span class='line'>
</span><span class='line'>backend router_http
</span><span class='line'>    mode http
</span><span class='line'>    balance roundrobin
</span><span class='line'>    server worker-1 worker-1.mycluster.example.com:80 check</span></code></pre></td></tr></table></div></figure>


<p>With the load balancer in place, we will move on to creating OpenShift virtual machines in the next section.</p>

<h2>Creating OpenShift virtual machines</h2>

<p>The official installation guide <a href="https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html#machine-requirements_installing-bare-metal">defines</a> minimum machine requirements for installing an OpenShift cluster as follows:</p>

<ul>
<li>One bootstrap machine</li>
<li>Three control plane, or master, machines</li>
<li>At least two compute, or worker, machines</li>
</ul>


<p>If you can meet these requirements, you will achieve the smallest <em>highly available</em> OpenShift cluster. However, do we really need high availability for our test installation?</p>

<p>Internally, OpenShift uses <a href="https://etcd.io/">etcd</a> to store its state. Since etcd is a quorum-based cluster, it requires at least three nodes to achieve high availability. These etcd nodes are installed on OpenShift master machines which is the reason for the minimum requirement of three OpenShift master machines. In our limited environment, we are going to give up on high availability and instead save up two master machines. OpenShift can install with a single master machine just fine if you can accept the fact that the OpenShift control plane won&rsquo;t be highly available.</p>

<p>And what about the requirement of two worker machines? The minimum requirement of two worker machines ensures that there will be at least two OpenShift routers running on the cluster. OpenShift router is an ingress point for external traffic to reach application pods running on OpenShift. Production installations require that at least two routers are installed to avoid a single point of failure. Furthermore, a highly available load balancer is deployed in front of the two routers. In a data center, a hardware load balancer is typically used, in cloud environments like AWS an Elastic Load Balancer can be utilized. As we don&rsquo;t pursue a highly available deployment, we are going to install an OpenShift cluster with a single worker machine. There will be a single router running on top of this cluster which we hereby accept.</p>

<p>This discussion leads us to the minimum requirements for a <em>not highly available</em> OpenShift cluster:</p>

<ul>
<li>One bootstrap machine</li>
<li>One control plane, or master, machine</li>
<li>One compute, or worker, machine</li>
</ul>


<p>In regards to the minimum memory requirements for each of the machines, I was able to install OpenShift on virtual machines with the following memory configuration:</p>

<table>
<thead>
<tr>
<th> Machine        </th>
<th> RAM  </th>
</tr>
</thead>
<tbody>
<tr>
<td> Bootstrap      </td>
<td> 4 GB </td>
</tr>
<tr>
<td> Control plane  </td>
<td> 6 GB </td>
</tr>
<tr>
<td> Compute        </td>
<td> 6 GB </td>
</tr>
</tbody>
</table>


<p>Note that the above memory requirements allow you to properly deploy the OpenShift cluster including the monitoring and log collection components. Furthermore, there will be enough capacity left on the worker node for you to run several hello world applications.</p>

<p>This concludes the user-provisioned infrastructure setup. At this point, we have HTTP server, DNS server, load balancer and a set of empty virtual machines in place. Let&rsquo;s dive into the OpenShift installation in the next section.</p>

<h2>Installing OpenShift 4.1</h2>

<p>The installation of OpenShift 4 starts with crafting an installation configuration file. You can use the <code>install-config.yaml</code> configuration file that I created, just remember to replace the placeholders with your own pull secret and public SSH key:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">apiVersion</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">v1</span>
</span><span class='line'><span class="l-Scalar-Plain">baseDomain</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">example.com</span>
</span><span class='line'><span class="l-Scalar-Plain">compute</span><span class="p-Indicator">:</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">hyperthreading</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Enabled</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">worker</span>
</span><span class='line'>  <span class="l-Scalar-Plain">platform</span><span class="p-Indicator">:</span> <span class="p-Indicator">{}</span>
</span><span class='line'>  <span class="l-Scalar-Plain">replicas</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0</span>
</span><span class='line'><span class="l-Scalar-Plain">controlPlane</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">hyperthreading</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Enabled</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">master</span>
</span><span class='line'>  <span class="l-Scalar-Plain">platform</span><span class="p-Indicator">:</span> <span class="p-Indicator">{}</span>
</span><span class='line'>  <span class="l-Scalar-Plain">replicas</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">1</span>
</span><span class='line'><span class="l-Scalar-Plain">metadata</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">creationTimestamp</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">null</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">mycluster</span>
</span><span class='line'><span class="l-Scalar-Plain">networking</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusterNetwork</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">cidr</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">10.128.0.0/14</span>
</span><span class='line'>    <span class="l-Scalar-Plain">hostPrefix</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">23</span>
</span><span class='line'>  <span class="l-Scalar-Plain">networkType</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">OpenShiftSDN</span>
</span><span class='line'>  <span class="l-Scalar-Plain">serviceNetwork</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">172.30.0.0/16</span>
</span><span class='line'><span class="l-Scalar-Plain">platform</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">none</span><span class="p-Indicator">:</span> <span class="p-Indicator">{}</span>
</span><span class='line'><span class="l-Scalar-Plain">pullSecret</span><span class="p-Indicator">:</span> <span class="s">&#39;&lt;INSERT_YOUR_PULL_SECRET_HERE&gt;&#39;</span>
</span><span class='line'><span class="l-Scalar-Plain">sshKey</span><span class="p-Indicator">:</span> <span class="s">&#39;&lt;INSERT_YOUR_PUBLIC_SSH_KEY_HERE&gt;&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The OpenShift installation is actually driven by the ignition configuration files. You can issue this command to generate ignition configuration files out of your <code>install-config.yaml</code> file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>./openshift-install create ignition-configs
</span></code></pre></td></tr></table></div></figure>


<p>Beware that the above command will remove your handcrafted <code>install-config.yaml</code> from the disk. I found this behavior of the    <code>openshift-install</code> tool rather annoying. In order to not lose my configuration settings, I protect the <code>install-config.yaml</code> file from deletion by creating a hard link like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ln install-config.yaml install-config.yaml.hardlink
</span></code></pre></td></tr></table></div></figure>


<p>And after the <code>install-config.yaml</code> file is deleted, I can simply recreate it with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ln install-config.yaml.hardlink install-config.yaml
</span></code></pre></td></tr></table></div></figure>


<p>Finally, we can use our ignition files to kick off the OpenShift installation process which deploys OpenShift cluster on our fleet of virtual machines. The whole process takes about 30 minutes and consists of several steps:</p>

<ol>
<li>Provision and reboot the bootstrap machine</li>
<li>Provision and reboot the master machine</li>
<li>Bootstrap the master machine</li>
<li>Shut down the bootstrap machine</li>
<li>Provision and reboot the worker machine</li>
<li>Worker machine joins the OpenShift cluster</li>
</ol>


<p>Note that after you bootstrap the master machine, you should shut down the bootstrap machine. Only after that, you should boot up the worker machine. On startup, the worker node registers with the master node and forms an OpenShift cluster.</p>

<h2>Conclusion</h2>

<p>In this blog post, we discussed how to deploy OpenShift 4.1 into the Libvirt/KVM-based virtualized environment. We created and configured a bunch of user-provisioned infrastructure which was a prerequisite for the OpenShift installation. With the user-provisioned infrastructure in place, we followed the OpenShift bare metal deployment guide to create an OpenShift cluster.</p>

<p>I hope that you found this article useful and you have your OpenShift 4.1 cluster running by now. If you have any questions or comments please feel free to add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Troubleshooting the Performance of Vert.x Applications, Part I &mdash; The Event Loop Model]]></title>
    <link href="http://alesnosek.com/blog/2019/06/30/troubleshooting-the-performance-of-vert-dot-x-applications-part-i-the-event-loop-model/"/>
    <updated>2019-06-30T10:16:31-07:00</updated>
    <id>http://alesnosek.com/blog/2019/06/30/troubleshooting-the-performance-of-vert-dot-x-applications-part-i-the-event-loop-model</id>
    <content type="html"><![CDATA[<p>This article is the first in a series of three articles which share my experience with troubleshooting the performance of Vert.x applications. The first article provides an overview of the Vert.x event loop model, the second acticle covers techniques to prevent delays on the event loop, and the third article focuses on troubleshooting of event loop delays.</p>

<!-- more -->


<p>Programming with Vert.x requires a good understanding of its event loop model. From what I saw in practice, delayed or blocked event loop threads are the number one contributor to performance problems with Vert.x applications. But don&rsquo;t worry. In this article, we are going to review the event loop model.</p>

<h2>Event loop theads and worker threads</h2>

<p>Depending on how you register your handler with Vert.x APIs, Vert.x will either execute your handler using an event loop thread or a worker thread. There are only these two options in Vert.x. The determination whether the handler is going to be executed on an event loop thread or a worker thread is made at the time you register the handler and doesn&rsquo;t change throughout the lifetime of your application. Take a look at this example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">class</span> <span class="nc">MyVerticle</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>  <span class="nd">@Override</span>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">Future</span><span class="o">&lt;</span><span class="n">Void</span><span class="o">&gt;&gt;</span> <span class="n">blockingCodeHandler</span> <span class="o">=</span> <span class="n">future</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// this handler will be executed on a worker thread</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">Handler</span><span class="o">&lt;</span><span class="n">AsyncResult</span><span class="o">&lt;</span><span class="n">Void</span><span class="o">&gt;&gt;</span> <span class="n">resultHandler</span> <span class="o">=</span> <span class="n">result</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// this handler will be executed on an event loop thread</span>
</span><span class='line'>      <span class="o">};</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">vertx</span><span class="o">.</span><span class="na">executeBlocking</span><span class="o">(</span><span class="n">blockingCodeHandler</span><span class="o">,</span> <span class="n">resultHandler</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The API call <code>vertx.executeBlocking()</code> registered two handlers. Vert.x will call the <code>blockingCodeHandler()</code> using a worker thread and the <code>resultHandler()</code> using an event loop thread. Because there are restrictions on what code can be executed on event loop threads, you want to structure your code so that it&rsquo;s clear to a casual reader whether a specific piece of code executes on a worker thread or an event loop thread.</p>

<p>Event loop frameworks like Vert.x employ a small amount of event loop threads at their core to do all the computational work. Using a low amount of threads minimizes the need for context switching which leads to a better performance than what a thread-per-request model can achieve.</p>

<blockquote><p>In an ideal situation, your Vert.x application would exclusively use event loop threads.</p></blockquote>

<p>The increased utilization of computing resources resulting in increased performance is a great benefit that event loop frameworks bring to the table. However, there are situations where employing worker threads is inevitable. We are going to show you some examples of such situations in the second article of this series. Just keep in mind that an excessive use of worker threads results in frequent context switching which will impact the overall performance of your application. This context switching negates the benefit of employing event loop frameworks like Vert.x in the first place.</p>

<h2>Taking the event loop for a spin</h2>

<p>The whole purpose of the event loop is to react to events which are delivered to the event loop by the operating system. Event loop processes those events by executing handlers. To explain how the event loop operates, let&rsquo;s imagine a typical HTTP server application serving multiple client connections at the same time. There&rsquo;s data being sent back and forth between the server and the client on each of the connections. And here is how the event loop handles it. First, the event loop waits for any of the events like incoming data available on the connection, or connection is ready to send more data. If any of those events happens, the event loop executes handlers that were registered to handle that specific event. For example, if there is incoming data available, the event loop calls the respective handler that stores the incoming data into a buffer and passes that buffer through a chain of handlers to your handler to process it. Handlers registered with a given event loop are executed one by one because the event loop is a single thread after all. After the processing of the event is finished, event loop returns back to wait for the next event.</p>

<p><img class="center" src="http://alesnosek.com/images/posts/vertx_event_loop.png"></p>

<p>I would like to highlight that the event loop is a single thread that executes the handlers sequentially. In order for this scheme to work smoothly:</p>

<blockquote><p>Handlers should not run code that would delay the event loop.</p></blockquote>

<p>In the case that the application is under full load, the events are queuing up while the event loop is busy executing handlers. In this case, the event loop doesn&rsquo;t really wait for events. Instead, it just picks up the next event and continues with executing handlers straight away.</p>

<p>On the other hand, if the application is idle and there are no events to process, the event loop will wait for events by blocking. It means the event loop thread will relinquish the CPU. Later on when the events arrive, the operating system scheduler will wake up the event loop thread again. Blocking while waiting for events is part of the event loop implementation and it is the only place where the event loop thread is supposed block. In contrast, handlers registered with the event loop  should never issue a blocking call.</p>

<p>On my Linux machine, if I dump a stack trace of an idle event loop thread I will get this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="s">&quot;vert.x-eventloop-thread-0&quot;</span> <span class="err">#</span><span class="mi">13</span> <span class="n">prio</span><span class="o">=</span><span class="mi">5</span> <span class="n">os_prio</span><span class="o">=</span><span class="mi">0</span> <span class="n">tid</span><span class="o">=</span><span class="mh">0x00007f89e0523800</span> <span class="n">nid</span><span class="o">=</span><span class="mh">0x1d67</span> <span class="n">runnable</span> <span class="o">[</span><span class="mh">0x00007f89cc4e0000</span><span class="o">]</span>
</span><span class='line'>   <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Thread</span><span class="o">.</span><span class="na">State</span><span class="o">:</span> <span class="n">RUNNABLE</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollArrayWrapper</span><span class="o">.</span><span class="na">epollWait</span><span class="o">(</span><span class="n">Native</span> <span class="n">Method</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollArrayWrapper</span><span class="o">.</span><span class="na">poll</span><span class="o">(</span><span class="n">EPollArrayWrapper</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">269</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollSelectorImpl</span><span class="o">.</span><span class="na">doSelect</span><span class="o">(</span><span class="n">EPollSelectorImpl</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">93</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">SelectorImpl</span><span class="o">.</span><span class="na">lockAndDoSelect</span><span class="o">(</span><span class="n">SelectorImpl</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">86</span><span class="o">)</span>
</span><span class='line'>        <span class="o">-</span> <span class="n">locked</span> <span class="o">&lt;</span><span class="mh">0x000000076ee73e18</span><span class="o">&gt;</span> <span class="o">(</span><span class="n">a</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">SelectedSelectionKeySet</span><span class="o">)</span>
</span><span class='line'>        <span class="o">-</span> <span class="n">locked</span> <span class="o">&lt;</span><span class="mh">0x000000076ee72be0</span><span class="o">&gt;</span> <span class="o">(</span><span class="n">a</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">Collections$UnmodifiableSet</span><span class="o">)</span>
</span><span class='line'>        <span class="o">-</span> <span class="n">locked</span> <span class="o">&lt;</span><span class="mh">0x000000076ee72ac8</span><span class="o">&gt;</span> <span class="o">(</span><span class="n">a</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">EPollSelectorImpl</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">ch</span><span class="o">.</span><span class="na">SelectorImpl</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">SelectorImpl</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">97</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">SelectedSelectionKeySetSelector</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">SelectedSelectionKeySetSelector</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">62</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">NioEventLoop</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">NioEventLoop</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">753</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">channel</span><span class="o">.</span><span class="na">nio</span><span class="o">.</span><span class="na">NioEventLoop</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">NioEventLoop</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">408</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">SingleThreadEventExecutor$5</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">SingleThreadEventExecutor</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">897</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">io</span><span class="o">.</span><span class="na">netty</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">FastThreadLocalRunnable</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">FastThreadLocalRunnable</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">30</span><span class="o">)</span>
</span><span class='line'>        <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Thread</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">Thread</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">748</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Vert.x tool-kit is built on top of <a href="https://netty.io/">Netty</a> framework and the event loop implementation is actually part of Netty. In the stack trace you can see that the Java thread is executing the Netty&rsquo;s event loop code which calls the Java NIO APIs which somewhere in the native code invokes the <code>epoll_wait</code> system call. This system call puts the event loop thread to sleep until the next event arrives.</p>

<p>Interestingly, while blocking in the <code>epoll_wait</code> system call, from the Java standpoint the thread is in a <code>RUNNABLE</code> state and not for example in the state <code>BLOCKED</code> which I would intuitively expect. JVM as an abstraction on top of the operating system has its own <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.State.html">definition of thread states</a>. According to this definition the thread is indeed in the <code>RUNNABLE</code> state even when from the stand point of the operating system it is in the state <em>interruptible sleep</em> and hence blocked.</p>

<h2>Conclusion</h2>

<p>In this article, we familiarized ourselves with the event loop model which is rather different from the thread-per-request model. The <a href="http://alesnosek.com/blog/2019/07/22/troubleshooting-the-performance-of-vert-dot-x-applications-preventing-event-loop-delays/">next part</a> in the series will cover techniques to prevent delays on the event loop.</p>

<p>Comment below if you found this article helpful or if you have suggestions for future blog subjects.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Speaking at Red Hat Summit 2019]]></title>
    <link href="http://alesnosek.com/blog/2019/04/21/speaking-at-red-hat-summit-2019/"/>
    <updated>2019-04-21T12:41:43-07:00</updated>
    <id>http://alesnosek.com/blog/2019/04/21/speaking-at-red-hat-summit-2019</id>
    <content type="html"><![CDATA[<p>This year&rsquo;s <a href="https://www.redhat.com/en/summit/2019">Red Hat Summit</a> is going to be hosted in Boston on May 7-9, 2019. I will be co-presenting on the topic: <em>Using Domain-driven Design to Reimagine Monolithic Applications in a World of Microservices</em>. If you are interested in hearing about how to design monolithic applications in a practical, decomposable, and agile fashion, you can come and see Eric Murphy and myself at the Boston Convention &amp; Exhibition Center on Wednesday, May 8, 10:30 a.m.-11:15 a.m. Feel free to drop by to say hi!</p>

<!-- more -->


<p><strong> Update 05/10/2019 </strong></p>

<p>I enjoyed having the opportunity to be a co-presenter with Eric Murphy at this week’s Red Hat Summit. Discussing DDD, event storming, and why a monolithic architecture can still be the right choice despite the current push for microservices:</p>

<p><img class="center" src="http://alesnosek.com/images/posts/using_ddd.jpeg"></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Remote Debugging of Java Applications on OpenShift]]></title>
    <link href="http://alesnosek.com/blog/2019/02/26/remote-debugging-of-java-applications-on-openshift/"/>
    <updated>2019-02-26T13:08:30-08:00</updated>
    <id>http://alesnosek.com/blog/2019/02/26/remote-debugging-of-java-applications-on-openshift</id>
    <content type="html"><![CDATA[<p>In this article I am going to show you how to attach a debugger and a VisualVM profiler to the Java application running on OpenShift. The approach described here doesn&rsquo;t make use of the <a href="https://jolokia.org/">Jolokia</a> bridge. Instead, we are going to leverage the port-forwarding feature of OpenShift.</p>

<!-- more -->


<p>The whole setup can be divided into three steps:</p>

<ol>
<li>Enable debug and JMX ports on the JVM</li>
<li>Set up port forwarding</li>
<li>Attach debugger and VisualVM to the forwarded ports</li>
</ol>


<p>I am going to use OpenShift v3.11 that I installed using Minishift and a test application built with Java OpenJDK 1.8. This is how the complete setup is going to look like:</p>

<p><img src="http://alesnosek.com/images/posts/remote_debugging_of_java_applications_on_openshift.svg"></p>

<h2>Hello world application</h2>

<p>For those of you who want to follow along, let&rsquo;s set up a test application which we will use for debugging. If you already have your Java application running on OpenShift, you can jump ahead to the next section.</p>

<p>Let&rsquo;s deploy a Hello world application that I found on <a href="https://github.com/vert-x3/vertx-openshift-s2i">GitHub</a>. This application was originally created to demonstrate how to build <a href="https://vertx.io/">Vert.x</a>-based microservices on OpenShift. You can get this application up and running in just two steps.</p>

<p>First, issue this command to build an S2I builder image for Vert.x applications:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc create -f https://raw.githubusercontent.com/vert-x3/vertx-openshift-s2i/master/vertx-s2i-all.json
</span><span class='line'>buildconfig.build.openshift.io/vertx-s2i created
</span><span class='line'>imagestream.image.openshift.io/vertx-centos created
</span><span class='line'>imagestream.image.openshift.io/vertx-s2i created
</span><span class='line'>template.template.openshift.io/vertx-helloworld-maven created
</span></code></pre></td></tr></table></div></figure>


<p>OpenShift started the build of the builder image and you can follow the progress with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc log -f bc/vertx-s2i
</span><span class='line'>
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>Removing intermediate container fc4bff8f426c
</span><span class='line'>Successfully built bd4a858867e9
</span><span class='line'>Pushing image 172.30.1.1:5000/myproject/vertx-s2i:latest ...
</span><span class='line'>Pushed 1/8 layers, 50% <span class="nb">complete</span>
</span><span class='line'>Pushed 2/8 layers, 25% <span class="nb">complete</span>
</span><span class='line'>Pushed 3/8 layers, 38% <span class="nb">complete</span>
</span><span class='line'>Pushed 4/8 layers, 50% <span class="nb">complete</span>
</span><span class='line'>Pushed 5/8 layers, 63% <span class="nb">complete</span>
</span><span class='line'>Pushed 6/8 layers, 97% <span class="nb">complete</span>
</span><span class='line'>Pushed 7/8 layers, 99% <span class="nb">complete</span>
</span><span class='line'>Pushed 8/8 layers, 100% <span class="nb">complete</span>
</span><span class='line'>Push successful
</span></code></pre></td></tr></table></div></figure>


<p>At the end of the build process OpenShift pushed the new image into the integrated Docker registry. Next, we are going to use the builder image to build and run a sample Vert.x application:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc new-app vertx-helloworld-maven
</span><span class='line'>--&gt; Deploying template <span class="s2">&quot;myproject/vertx-helloworld-maven&quot;</span> to project myproject
</span><span class='line'>
</span><span class='line'>     vertx-helloworld-maven
</span><span class='line'>     ---------
</span><span class='line'>     Sample Vert.x application build with Maven
</span><span class='line'>
</span><span class='line'>     * With parameters:
</span><span class='line'>        * <span class="nv">APPLICATION_NAME</span><span class="o">=</span>hello-world
</span><span class='line'>        * <span class="nv">APPLICATION_HOSTNAME</span><span class="o">=</span>
</span><span class='line'>        * <span class="nv">GIT_URI</span><span class="o">=</span>https://github.com/vert-x3/vertx-openshift-s2i.git
</span><span class='line'>        * <span class="nv">GIT_REF</span><span class="o">=</span>master
</span><span class='line'>        * <span class="nv">CONTEXT_DIR</span><span class="o">=</span><span class="nb">test</span>/test-app-maven
</span><span class='line'>        * <span class="nv">APP_OPTIONS</span><span class="o">=</span>
</span><span class='line'>        * <span class="nv">GITHUB_TRIGGER_SECRET</span><span class="o">=</span>EM325a5K <span class="c"># generated</span>
</span><span class='line'>        * <span class="nv">GENERIC_TRIGGER_SECRET</span><span class="o">=</span>CBCcCIWr <span class="c"># generated</span>
</span><span class='line'>
</span><span class='line'>--&gt; Creating resources ...
</span><span class='line'>    buildconfig.build.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    imagestream.image.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    deploymentconfig.apps.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    route.route.openshift.io <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>    service <span class="s2">&quot;hello-world&quot;</span> created
</span><span class='line'>--&gt; Success
</span><span class='line'>    Build scheduled, use <span class="s1">&#39;oc logs -f bc/hello-world&#39;</span> to track its progress.
</span><span class='line'>    Access your application via route <span class="s1">&#39;hello-world-myproject.192.168.42.115.nip.io&#39;</span>
</span><span class='line'>    Run <span class="s1">&#39;oc status&#39;</span> to view your app.
</span></code></pre></td></tr></table></div></figure>


<p>You can follow the build logs by issuing the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc log -f bc/hello-world
</span><span class='line'>
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> --- maven-clean-plugin:2.5:clean <span class="o">(</span>default-clean<span class="o">)</span> @ vertx-hello-world ---
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Deleting /opt/app-root/src/source/target
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> BUILD SUCCESS
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Total <span class="nb">time</span>:  1.102 s
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Finished at: 2019-02-26T20:21:57Z
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'>Application jar file is located in /opt/openshift/vertx-app.jar
</span><span class='line'>Files located in the application directory:
</span><span class='line'>total 13216
</span><span class='line'>-rw-r--r--. <span class="m">1</span> default root      <span class="m">286</span> Feb <span class="m">26</span> 20:21 additional_files.md
</span><span class='line'>-rw-r--r--. <span class="m">1</span> default root <span class="m">13525420</span> Feb <span class="m">26</span> 20:21 vertx-app.jar
</span><span class='line'>Pushing image 172.30.1.1:5000/myproject2/hello-world:latest ...
</span><span class='line'>Pushed 0/9 layers, 2% <span class="nb">complete</span>
</span><span class='line'>Pushed 1/9 layers, 11% <span class="nb">complete</span>
</span><span class='line'>Push successful
</span></code></pre></td></tr></table></div></figure>


<p>If everything went fine, you should be able to see the Hello world application running:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc get pod <span class="p">|</span> grep hello-world
</span><span class='line'>hello-world-1-build   0/1       Completed    <span class="m">0</span>          6m
</span><span class='line'>hello-world-1-dw5lf   1/1       Running      <span class="m">0</span>          42s
</span></code></pre></td></tr></table></div></figure>


<h2>Enabling Debug and JMX ports on JVM</h2>

<p>In the following, I am going to use OpenJDK 1.8. Note that the available JVM options may vary depending on the version of Java  platform you are using.</p>

<p>To enable a remote debug port on JVM, one has to pass the following option to the JVM:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-agentlib:jdwp=transport=dt_socket,server=y,address=8000,suspend=n</span></code></pre></td></tr></table></div></figure>


<p>In order to enable JMX, the following JVM options are needed:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-Dcom.sun.management.jmxremote=true
</span><span class='line'>-Dcom.sun.management.jmxremote.port=3000
</span><span class='line'>-Dcom.sun.management.jmxremote.rmi.port=3001
</span><span class='line'>-Djava.rmi.server.hostname=127.0.0.1
</span><span class='line'>-Dcom.sun.management.jmxremote.authenticate=false
</span><span class='line'>-Dcom.sun.management.jmxremote.ssl=false</span></code></pre></td></tr></table></div></figure>


<p>This set of options deserves a bit more explanation. By default, JMX utilizes RMI as the underlying technology for the communication between the JMX client and the remote JVM. And as a matter of fact, there are two RMI ports needed for this communication:
* RMI registry port
* RMI server port</p>

<p>At the beginning, the client connects to the RMI registry on port 3000 and looks up the connection to the RMI server. After the successful lookup, the client initiates a second connection to the RMI server. Based on our configuration, the client is going to connect to 127.0.0.1:3001. However, there&rsquo;s no RMI server running on the local machine, so what&rsquo;s the deal? As you will see in the next section, we are going to forward the local port 3001 back to the remote server.</p>

<p>Next, we need to convey our configuration options to the JVM running inside the OpenShift pod. It turns out that there exists an environment variable <code>JAVA_TOOL_OPTIONS</code> that is interpreted directly by the JVM and where you can put your JVM configuration options. I recommend using this variable as there is a great chance that this variable will work no matter how deep in your wrapper scripts you are launching the JVM. Go ahead and modify the DeploymentConfig or Pod descriptor of your application in OpenShift to add the <code>JAVA_TOOL_OPTIONS</code> variable. For example, you can open the DeloymentConfig for editing like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc edit dc hello-world
</span></code></pre></td></tr></table></div></figure>


<p>&hellip; and add the <code>JAVA_TOOL_OPTIONS</code> environment variable to the container section of the specification:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>...
</span><span class='line'>
</span><span class='line'>    spec:
</span><span class='line'>      containers:
</span><span class='line'>      - env:
</span><span class='line'>        - name: JAVA_TOOL_OPTIONS
</span><span class='line'>          value: -agentlib:jdwp=transport=dt_socket,server=y,address=8000,suspend=n
</span><span class='line'>            -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=3000
</span><span class='line'>            -Dcom.sun.management.jmxremote.rmi.port=3001 -Djava.rmi.server.hostname=127.0.0.1
</span><span class='line'>            -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
</span><span class='line'>
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>After applying the above changes, OpenShift will redeploy the application pod. At startup, JVM will print out the following line to the stderr which will show up in the container logs:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc logs dc/hello-world <span class="p">|</span> grep JAVA_TOOL_OPTIONS
</span><span class='line'>Picked up JAVA_TOOL_OPTIONS: -agentlib:jdwp<span class="o">=</span><span class="nv">transport</span><span class="o">=</span>dt_socket,server<span class="o">=</span>y,address<span class="o">=</span>8000,suspend<span class="o">=</span>n -Dcom.sun.management.jmxremote<span class="o">=</span><span class="nb">true</span> -Dcom.sun.management.jmxremote.port<span class="o">=</span><span class="m">3000</span> -Dcom.sun.management.jmxremote.rmi.port<span class="o">=</span><span class="m">3001</span> -Djava.rmi.server.hostname<span class="o">=</span>127.0.0.1 -Dcom.sun.management.jmxremote.authenticate<span class="o">=</span><span class="nb">false</span> -Dcom.sun.management.jmxremote.ssl<span class="o">=</span><span class="nb">false</span>
</span></code></pre></td></tr></table></div></figure>


<p>This verifies that our JVM options are in effect and the debug port and JMX ports are open. How are we going to connect to these ports? Let&rsquo;s set up port forwarding on the local machine next.</p>

<h2>Setting up port forwarding</h2>

<p>OpenShift features <a href="https://docs.okd.io/latest/dev_guide/port_forwarding.html">port forwarding</a> that allows you to connect to an arbitrary port of a pod running on OpenShift. Port forwarding doesn&rsquo;t require you to define any additional objects like Service or Route to enable it. What you need though is to start a port forwarding proxy on your local machine. Issue the following command on your local machine to start the proxy and forward the three ports 8000, 3000, and 3001 to the remote pod running on OpenShift:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc port-forward &lt;POD&gt; <span class="m">8000</span> <span class="m">3000</span> 3001
</span></code></pre></td></tr></table></div></figure>


<p>In the above command, remember to replace <code>&lt;POD&gt;</code> with the name of your application pod. If everything worked well, you should see the following output :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc port-forward hello-world-2-55zlq <span class="m">8000</span> <span class="m">3000</span> 3001
</span><span class='line'>Forwarding from 127.0.0.1:8000 -&gt; 8000
</span><span class='line'>Forwarding from 127.0.0.1:3000 -&gt; 3000
</span><span class='line'>Forwarding from 127.0.0.1:3001 -&gt; 3001
</span></code></pre></td></tr></table></div></figure>


<p>Note that the proxy keeps running on the foreground.</p>

<h2>Attaching to the JVM running on OpenShift</h2>

<p>Having our port-forwarding proxy all set, let&rsquo;s fire up a debugger and attach it to our application. Note that we instruct the debugger to connect to the localhost on port 8000. This port is in turn forwarded to the port 8000 on the JVM:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>jdb -connect com.sun.jdi.SocketAttach:hostname<span class="o">=</span>localhost,port<span class="o">=</span>8000
</span></code></pre></td></tr></table></div></figure>


<p>After the debugger attaches, you can list existing JVM threads using the <code>threads</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>> threads
</span><span class='line'>Group system:
</span><span class='line'>  (java.lang.ref.Reference$ReferenceHandler)0x133a                                             Reference Handler                                   cond. waiting
</span><span class='line'>  (java.lang.ref.Finalizer$FinalizerThread)0x133b                                              Finalizer                                           cond. waiting
</span><span class='line'>  (java.lang.Thread)0x133c                                                                     Signal Dispatcher                                   running
</span><span class='line'>  (java.lang.Thread)0x133d                                                                     RMI TCP Accept-3001                                 running
</span><span class='line'>  (java.lang.Thread)0x133e                                                                     RMI TCP Accept-3000                                 running
</span><span class='line'>  (java.lang.Thread)0x133f                                                                     RMI TCP Accept-0                                    running
</span><span class='line'>Group main:
</span><span class='line'>  (java.util.TimerThread)0x1342                                                                vertx-blocked-thread-checker                        cond. waiting
</span><span class='line'>  (io.vertx.core.impl.VertxThread)0x1343                                                       vert.x-worker-thread-0                              cond. waiting
</span><span class='line'>
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>Next, let&rsquo;s check out if we can attach <a href="https://visualvm.github.io/">VisualVM</a> to our application as well:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>visualvm --openjmx localhost:3000
</span></code></pre></td></tr></table></div></figure>


<p>Works like a charm, doesn&rsquo;t it?</p>

<p><img src="http://alesnosek.com/images/posts/visualvm_attached.png"></p>

<h2>Conclusion</h2>

<p>In this blog post, we were able to attach a debugger and VisualVM to the Java application running on OpenShift. We didn&rsquo;t need to deploy Jolokia proxy or create additional Service or Route objects to make our setup work. Instead, we leveraged the port-forwarding feature already available in OpenShift. The demonstrated method has additional security benefits as we are not exposing any additional ports of the application container.</p>

<p>Hope you enjoyed this article and was able to reproduce this setup for yourself. If you have any thoughts or questions feel free to add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Comparing OpenAPI with gRPC]]></title>
    <link href="http://alesnosek.com/blog/2019/01/25/comparing-openapi-with-grpc/"/>
    <updated>2019-01-25T15:22:46-08:00</updated>
    <id>http://alesnosek.com/blog/2019/01/25/comparing-openapi-with-grpc</id>
    <content type="html"><![CDATA[<p>Are you still coding your API client libraries by hand? Is your manually maintained API documentation drifting away from what was actually implemented? You may be interested in reviewing the two popular technologies that solve this problem. In this article, we are going to look at OpenAPI and gRPC side-by-side.</p>

<!-- more -->


<p>Both OpenAPI and gRPC are communication technologies very much needed in the today&rsquo;s world of microservices applications. They allow you to describe your APIs using  a formal language. This description then serves as a source of truth from which you can generate the client and server code and API documentation. As there are two viable alternatives, the question is which one is going to work better for you? As I was trying to answer the same question I did some research on the Internet and came up with a comparison table. I didn&rsquo;t include every single detail, however, this table could perhaps be a good starting point for you:</p>

<table>
<thead>
<tr>
<th> Criteria </th>
<th> OpenAPI </th>
<th> gRPC </th>
</tr>
</thead>
<tbody>
<tr>
<td> Origins </td>
<td> <a href="https://www.openapis.org/">OpenAPI</a> evolved from the <a href="https://swagger.io/">Swagger</a> project. Swagger started out as a specification for documenting RESTful APIs. Later on, tools to generate client and server code and generating of test-cases were added. While the original Swagger Specification was donated to the <a href="https://linuxfoundation.org">Linux Foundation</a> and renamed the OpenAPI,  Swagger remains one of the most widely used open source tool sets for developing OpenAPIs. </td>
<td> <a href="https://grpc.io/">gRPC</a> was originally developed at Google. Later on, it was donated to <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a>. </td>
</tr>
<tr>
<td> Communication Protocol </td>
<td> OpenAPI uses HTTP/1.1 protocol for transport. For the data representation, JSON is generally assumed. </td>
<td> gRPC uses HTTP/2 protocol for transport and <a href="https://developers.google.com/protocol-buffers/">Protocol Buffers</a> as a serialization format. </td>
</tr>
<tr>
<td> API Description Format </td>
<td> Developers describe their APIs using JSON or YAML documents that follow the <a href="https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md">OpenAPI Specification</a> schema. You can find a large archive of sample OpenAPI descriptions at <a href="https://apis.guru/openapi-directory/">apis.guru/openapi-directory</a>. </td>
<td> APIs are described using <code>.proto</code> files written in a <a href="https://developers.google.com/protocol-buffers/docs/proto3">Protocol Buffer Language</a>. </td>
</tr>
<tr>
<td> Description Style </td>
<td> REST APIs are described using HTTP verbs and URIs. Each URI represents a resource in your system, and the HTTP verbs represent actions you take on your resources. <br/><br/> REST APIs use <a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP status codes</a> to signalize the results of the operation invocations. As the HTTP status codes were primarily meant to convey the results of the transport operations, the mapping of status codes to the results of your API functions may be a bit loose. </td>
<td> With gRPC, you can describe your API in terms of methods or procedures. However, if a lot of methods are added over time, the end result can be a complex and confusing API due to the fact that developers must understand what each method does individually. Instead, Google suggests to use a <a href="https://cloud.google.com/apis/design/resources">resource-oriented design</a> which applies the REST design principles to gRPC. This results in more comprehensible APIs. Also, if you intend to transcode HTTP/JSON API into gRPC, you will greatly benefit from a gRPC API designed using the resource-oriented approach. <br/><br/> gRPC offers a set of <a href="https://godoc.org/google.golang.org/grpc/codes">error codes</a> that are well suited to describe the outcome of API operations. </td>
</tr>
<tr>
<td> Client and Server Code Generation </td>
<td>  There are several tools for generating code based on the OpenAPI description. The most widely used code generation project is <a href="https://swagger.io/tools/swagger-codegen/">Swagger Codegen</a>. Other projects include <a href="https://github.com/Azure/autorest">AutoRest</a> and <a href="https://github.com/capitalone/oas-nodegen">oas-nodegen</a>. </td>
<td> gRPC comes with a modular code generator called <em>protoc</em>. Each supported language is implemented as a separate plugin. The code generator was part of the gRPC project from its inception. </td>
</tr>
<tr>
<td> Interactive Documentation </td>
<td> <a href="https://swagger.io/tools/swagger-ui/">Swagger UI</a> is a great tool to visualize your API and execute test requests against your API. </td>
<td> <a href="https://github.com/sourcegraph/prototools">prototools</a> and <a href="https://github.com/pseudomuto/protoc-gen-doc">protoc-gen-doc</a> can generate documentation based on your <code>.proto</code> files. </td>
</tr>
<tr>
<td> Tooling </td>
<td> <a href="https://swagger.io/">Swagger Tools</a>, <a href="https://curl.haxx.se/">curl</a>, <a href="https://www.getpostman.com/">Postman</a>, web browsers, <a href="https://www.tcpdump.org/">tcpdump</a>, <a href="https://www.wireshark.org/">Wireshark</a> </td>
<td> <a href="https://github.com/grpc-ecosystem/awesome-grpc">Awesome gRPC</a>, <a href="https://github.com/fullstorydev/grpcurl">gRPCurl</a>. At the time of this writing, Wireshark supports gRPC only partially. </td>
</tr>
<tr>
<td> Performance </td>
<td> HTTP/1.1 protocol is a request/response protocol. When sending multiple requests over a single TCP connection, the next request can only be sent after the response to the previous request was received. This would normally result in a poor performance especially on the connections with higher latency. To increase the performance, HTTP client opens multiple TCP connections to a single server and sends multiple HTTP requests in parallel. New connections are opened as they are needed. As establishing a new TCP connection is associated with a cost, clients implement <em>connection pooling</em> to reuse the existing TCP connections. Remember to tune the clients connection pool to achieve good performance. <br/><br/> Some HTTP clients/servers may support HTTP/1.1 <em>pipelining</em>. Each HTTP request over the TCP connection may be made immediately without waiting for the previous request&rsquo;s response to return. As request responses must be returned in the order requested, this is prone to head of line blocking. <br/><br/> HTTP/1.1 is a text-based protocol and JSON is a text-based serialization format which hurts the performance. </td>
<td> By default HTTP/2 client opens a single TCP connection to the server and multiplexes multiple requests on this connection. Requests and responses are split into chunks and can be returned in an intermingled fashion. This prevents the head of line blocking that HTTP/1.1 pipelining may suffer from. In addition to that, the client can open multiple HTTP/2 connections to a single server and implement connection pooling. However, it is common to use a single TCP connection only. <br/><br/> HTTP/2 is a binary protocol. Also, according to <a href="https://medium.com/apis-and-digital-transformation/openapi-and-grpc-side-by-side-b6afb08f75ed">this</a> article by Tim Burks of Google, the Protocol Buffers binary format can be orders of magnitude faster to read than corresponding JSON serializations. <br/><br/> Overall, gRPC offers a better performance than OpenAPI. </td>
</tr>
<tr>
<td> Overall Summary </td>
<td> OpenAPI offers a great interoperability due to leveraging widely used HTTP/1.1 protocol and the JSON format. There is a great amount of tools available that will work with OpenAPI-based interfaces. </td>
<td> If you are looking for maximum performance, gRPC is a great choice for you. Also, HTTP/2 protocol is gradually gaining market share. Why not start using it today? </td>
</tr>
</tbody>
</table>


<h2>Where to go from here?</h2>

<p>The comparison table in the previous section highlights only the basic characteristics of OpenAPI and gRPC. I constructed the table based on many great articles that I found on the web. If you are interested in further details on how OpenAPI and gRPC compares I recommend to you to visit the following references:</p>

<ul>
<li><a href="https://medium.com/apis-and-digital-transformation/openapi-and-grpc-side-by-side-b6afb08f75ed">OpenAPI and gRPC Side-by-Side</a></li>
<li><a href="https://sookocheff.com/post/api/swagger-thrift-or-grpc/">Comparing Swagger with Thrift or gRPC</a></li>
<li><a href="https://code.tutsplus.com/tutorials/rest-vs-grpc-battle-of-the-apis--cms-30711">REST vs. gRPC: Battle of the APIs</a></li>
<li><a href="http://www.andrewconnell.com/blog/grpc-and-protocol-buffers-an-alternative-to-rest-apis-and-json">gRPC and Protocol Buffers: an Alternative to REST APIs and JSON</a></li>
<li><a href="https://www.sajari.com/blog/grpc-and-displacement-of-rest-apis">gRPC and the displacement of REST-based APIs</a></li>
<li><a href="https://improbable.io/games/blog/grpc-web-moving-past-restjson-towards-type-safe-web-apis">gRPC-Web: Moving past REST+JSON towards type-safe Web APIs</a></li>
<li><a href="https://husobee.github.io/golang/rest/grpc/2016/05/28/golang-rest-v-grpc.html">REST v. gRPC</a></li>
<li><a href="https://blogs.dropbox.com/tech/2019/01/courier-dropbox-migration-to-grpc/">Courier: Dropbox migration to gRPC</a></li>
</ul>


<h2>Combining OpenAPI and gRPC</h2>

<p>Do you have to use either OpenAPI or gRPC? If you like the awesome performance offered by gRPC but still need to provide REST interfaces to the external third-party clients there is a solution for you. You can leverage one of the proxies (<a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/http_filters/grpc_json_transcoder_filter">Envoy</a>,  <a href="https://github.com/grpc-ecosystem/grpc-gateway">grpc-gateway</a>) that can transcode the REST interface into gRPC. If you design your gRPC interfaces in a <a href="https://cloud.google.com/apis/design/resources">resource-oriented</a> fashion the transcoding process is straight forward. The resulting system architecture may look like this:</p>

<p><img src="http://alesnosek.com/images/posts/comparing_openapi_with_grpc.svg"></p>

<p>The third-party REST client talks to the proxy using HTTP/JSON. Client requests are transcoded on-the-fly into gRPC requests. After the requests are processed, the resulting responses are transcoded from gRPC back to HTTP/JSON and delivered to the client.</p>

<h2>Conclusion</h2>

<p>In this blog post, we compared the basic characteristics of OpenAPI and gRPC. OpenAPI is a great choice due to its interoperability. On the other hand, gRPC offers a better performance. However, you don&rsquo;t have to choose one or the other. You can happily combine both technologies in a single system.</p>

<p>I hope you enjoyed this article. If you are looking into OpenAPI or gRPC I would be happy to hear about your thoughts. Please, feel free to leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Tips for Passing the Red Hat Certified Specialist in Gluster Storage Administration Exam]]></title>
    <link href="http://alesnosek.com/blog/2018/12/28/tips-for-passing-the-red-hat-certified-specialist-in-gluster-storage-administration-exam/"/>
    <updated>2018-12-28T11:24:40-08:00</updated>
    <id>http://alesnosek.com/blog/2018/12/28/tips-for-passing-the-red-hat-certified-specialist-in-gluster-storage-administration-exam</id>
    <content type="html"><![CDATA[<p>Recently I passed the <a href="https://www.redhat.com/en/services/training/ex236-red-hat-certified-specialist-in-gluster-storage-administration-exam">Red Hat Certified Specialist in Gluster Storage Administration</a> exam. In this blog post, I would like to share some of my experience and exam tips with you.</p>

<!-- more -->


<p>There are two major open-source storage technologies available today: <a href="https://ceph.com/">Ceph</a> and <a href="https://www.gluster.org/">Gluster</a>. For a couple of years, I used Ceph as a provider of a block and object storage for an OpenStack cluster with great success. I was curious to learn about what Gluster has to offer. To explore Gluster, I leveraged the training materials and labs included in my <a href="https://www.redhat.com/en/services/training/learning-subscription">Red Hat Learning Subscription</a>. Also, to give myself a particular goal to achieve, I signed up for the Red Hat Certified Specialist in Gluster Storage Administration exam. The main topics included on the exam are creating different types of Gluster volumes, volume snapshotting, exporting Gluster volumes via highly-available NFS and Samba, asynchronous replication (geo-replication), tiered volumes and transport security.</p>

<p>As I was working through the learning materials for the first time, I used the provided virtual machines to solve the lab exercises. I liked that after I completed the exercise I could run a grading script that would check my configuration and to see if anything was still missing. However, after I realized that setting up a Gluster cluster from scratch doesn&rsquo;t take much effort, I decided to spin up my own practice environment. I created three virtual machines (2 GB RAM, 4 vCPUs) on my laptop using libvirt/QEMU/KVM and installed CentOS 7 and Gluster 4.1. The software on the real exam is RHEL 7 and Gluster 3, however, it didn&rsquo;t make much difference to me. Switching to my custom practice environment removed the perceived latency while typing and allowed me to easily copy and paste between console windows. In addition to that, I could keep my virtual machines running all the time. Virtual machines in the lab environment provided by Red Hat shutdown automatically after two hours unless you bump up the timer.</p>

<p>If you are preparing for the Gluster certification exam, here are several things that are good to know:</p>

<ul>
<li>The complete <a href="https://access.redhat.com/documentation/en-us/red_hat_gluster_storage">Red Hat Gluster Storage documentation</a> is available to you during the exam in a searchable PDF format. The Red Hat Gluster Storage Administration Guide turned out to be particularly useful. I recommend reading through the guide as a part of the preparation for the exam. You will learn where the important configuration parts are located in the guide and will be able to quickly refer to them during the exam.</li>
<li>Preparing underlying LVM volumes for Gluster bricks takes quite a bit of time which you won&rsquo;t have plenty of in the exam. Here is my advice: at the beginning of the exam, walk through the exam tasks and create all the LVM volumes that you will need up front.</li>
<li>Command <code>gluster volume set help</code> lists all the Gluster volume parameters along with their short descriptions. If you cannot remember the exact parameter name just grep through the output of this command.</li>
<li>If you cannot remember the Gluster mount options, you can find them by typing <code>man mount.glusterfs</code></li>
<li>Provisioning of LVM thin volumes is thoroughly documented in <code>man lvmthin</code></li>
<li>To list all services that you can enable on the firewall, type <code>firewall-cmd --get-services</code></li>
<li>To find out whether SELinux denied access, issue the command  <code>grep denied /var/log/audit/audit.log</code>. SELinux can provide a hint on how to possibly solve the access issue, use the command <code>sealert -a /var/log/audit/audit.log</code></li>
<li>To list SELinux types related to Gluster, you can type <code>strings /sys/fs/selinux/policy | grep gluster</code></li>
<li>And last but not least, you can list volumes exported by the NFS server with <code>showmount -e &lt;HOST&gt;</code>. To show volumes available on a Samba server, issue the command <code>smbclient -L &lt;HOST&gt; -U %</code></li>
</ul>


<p>And how did I do on the exam? Well, I would not say that the exam was difficult, however, I also didn&rsquo;t practice much before the exam. Unfortunately, I ran out of time before I could complete the last exam task. Overall, I achieved 236 points out of 300. As the passing score was 210, I did pass!</p>

<p>Are you preparing for the Red Hat Gluster Storage exam? I would love to hear from you! Please, leave your comments or questions in the comment section below.</p>

<p><img src="http://alesnosek.com/images/posts/rhcs_gluster_storage_administration_badge.png"></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Speaking at the Red Hat Training Partner &amp; Instructor Conference]]></title>
    <link href="http://alesnosek.com/blog/2018/09/24/speaking-at-the-red-hat-training-partner-and-instructor-conference/"/>
    <updated>2018-09-24T08:47:00-07:00</updated>
    <id>http://alesnosek.com/blog/2018/09/24/speaking-at-the-red-hat-training-partner-and-instructor-conference</id>
    <content type="html"><![CDATA[<p>On September 21, 2018 I spoke at the <a href="https://www.redhat.com/en/events/training-partner-conference-emea">Red Hat Training Partner &amp; Instructor Conference</a> in Prague, Czech Republic. Why was I invited, and what did I learn? Read on if you want to find out.</p>

<!-- more -->


<h2>Why was I invited to speak at this conference?</h2>

<p>In this conference, Red Hat shares updates on their learning and certification programs, as well as the current status and trends. This conference is geared towards Red Hat’s training partners, instructors, and Red Hat Academy representatives.</p>

<p>To date, one of my most popular blog posts has been <a href="http://alesnosek.com/blog/2017/08/01/how-i-became-a-red-hat-certified-architect-in-one-year/">How I Became a Red Hat Certified Architect in One Year</a>. In this post I described my path through the Red Hat certification process, using the Red Hat Learning Subscription (<a href="https://www.redhat.com/en/services/training/learning-subscription">RHLS</a>), to achieve the Red Hat Certified Architect title. As a result of this, the conference organizers invited me to speak and give a customer testimonial about my experience.</p>

<h2>What did I talk about?</h2>

<p>I shared a little bit about my background, my personal certification path using the RHLS, offered a couple of suggestions for improvement of RHLS, and also listed reasons why I would recommend the RHLS to others:</p>

<ul>
<li>Quality learning materials (concise yet complete)</li>
<li>Access to the training lab (closely resembles the exam environment)</li>
<li>Was able to learn at my own pace - flexibility</li>
<li>Designed for remote access which was much more convenient for me than attending classes</li>
<li>Cost effectiveness</li>
<li>After becoming RHCA I used RHLS to evaluate other Red Hat products</li>
</ul>


<h2>What did I learn at the conference?</h2>

<p>I learned that Red Hat builds their learning platform themselves. Additionally, changes have been made such that the proctoring of the exams will be handled directly by Red Hat, instead of leveraging a third party.</p>

<p>Red Hat has updated the score report emails to include the breakdown by topic areas. This could be especially helpful for those who were unsuccessful in their exam attempt and need more information about what to focus on before retaking the exam.</p>

<p>The Red Hat Certified Architect certification has been divided in to two different certifications, Red Hat Certified Architect in Infrastructure and Red Hat Certified Architect in Enterprise Applications. This change is well documented <a href="https://servicesblog.redhat.com/2018/08/20/red-hat-certified-architect-program-changes/">here</a>. I would like to point out that those of you who achieved the RHCA already, can log into your Red Hat account and download your certificate with the updated title.</p>
]]></content>
  </entry>

</feed>
