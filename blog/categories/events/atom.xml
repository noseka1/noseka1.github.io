<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: events | Ales Nosek - The Software Practitioner]]></title>
  <link href="http://alesnosek.com/blog/categories/events/atom.xml" rel="self"/>
  <link href="http://alesnosek.com/"/>
  <updated>2018-03-08T20:19:23-08:00</updated>
  <id>http://alesnosek.com/</id>
  <author>
    <name><![CDATA[Ales Nosek]]></name>

  </author>
  <generator uri="http://octopress.org/">Octopress</generator>


  <entry>
    <title type="html"><![CDATA[What I Learned at KubeCon + CloudNativeCon 2017]]></title>
    <link href="http://alesnosek.com/blog/2017/12/10/what-i-learned-at-kubecon-plus-cloudnativecon-2017/"/>
    <updated>2017-12-10T16:16:25-08:00</updated>
    <id>http://alesnosek.com/blog/2017/12/10/what-i-learned-at-kubecon-plus-cloudnativecon-2017</id>
    <content type="html"><![CDATA[<p>KubeCon + CloudNativeCon North America 2017 took place in Austin, Texas on December 6-8, 2017. I greatly enjoyed this conference. This blog post presents some of the notes I made during the conference talks. Would you like to learn about Amazon EKS, Kata Containers or the CRI-O project? Do you want to better understand Docker&rsquo;s Moby project and its relation to LinuxKit and InfraKit? Then read on!</p>

<!-- more -->


<p><img class="center" src="/images/posts/kubecon_2017.png" width="500" height="200"></p>

<h2>Keynotes</h2>

<ul>
<li><strong>Keynote: A Community of Builders</strong>

<ul>
<li>Linux Foundation created a <a href="https://www.edx.org/course/introduction-kubernetes-linuxfoundationx-lfs158x">Introduction to Kubernetes</a> course available to everybody who wants to learn Kubernetes. The course is provided free of charge on the edX platform.</li>
<li>CNCF in collaboration with The Linux Foundation created a certification program <a href="https://www.cncf.io/certification/expert/">Certified Kubernetes Administrator</a> (CKA). Check it out, if you want to demonstrate your Kubernetes skills.</li>
</ul>
</li>
<li><strong>Keynote: CNCF Project Updates</strong>

<ul>
<li>The recently released <a href="https://coredns.io/">CoreDNS</a> v1.0 is going to replace <a href="https://github.com/kubernetes/dns">Kube DNS</a> in Kubernetes v1.9.</li>
<li>Container runtime <a href="https://containerd.io/">containerd</a>, originally created by Docker and now hosted by CNCF, reached its v1.0 milestone.</li>
<li>Today, the CNCF logging project <a href="https://www.fluentd.org/">Fluentd</a> reached its v1.0 release.</li>
<li>A rather young project <a href="http://fluentbit.io/">Fluent Bit</a> is a log forwarder which allows you to collect your data/logs from various sources and forward them to multiple destinations. Supported destinations are among others: Elasticsearch, InfluxDB or Kafka. Fluent Bit is implemented in C and it only leverages asynchronous operations to collect and deliver data. It integrates well with the <a href="https://prometheus.io/">Prometheus</a> monitoring system.</li>
</ul>
</li>
<li><strong>Keynote: Cloud Native at AWS</strong>

<ul>
<li>AWS chose containerd as the runtime for their managed Kubernetes service <a href="https://aws.amazon.com/eks/">EKS</a>.</li>
<li>With the recent announcements of <a href="https://aws.amazon.com/about-aws/whats-new/2017/11/announcing-amazon-ec2-bare-metal-instances-preview/">Amazon EC2 Bare Metal instances</a> and <a href="https://aws.amazon.com/blogs/aws/amazon-elastic-container-service-for-kubernetes/">Amazon Elastic Container Service for Kubernetes</a>, there are now four first-class deployment entities available on AWS: bare metal, VMs, containers and functions.</li>
<li>Amazon ECS for Kubernetes will leverage IAM to authenticate identities and the Kubernetes&#8217; RBAC for authorization. Pods will be assigned IAM roles in order for them to be able to talk to other AWS services, e.g. S3.</li>
</ul>
</li>
</ul>


<h2>Sessions attended</h2>

<ul>
<li><strong>Embedding the Containerd Runtime for Fun and Profit</strong>

<ul>
<li>ShiftFS is trying to solve the problem with the access (uid/gid) to a single file system from two containers running in different user namespaces.</li>
</ul>
</li>
<li><strong>Kata Containers: Hypervisor-Based Container Runtime</strong>

<ul>
<li>The <a href="https://katacontainers.io/">Kata Containers</a> project is a merger of two projects: <a href="https://github.com/clearcontainers/runtime">Intel Clear Containers</a> and <a href="https://github.com/hyperhq/runv">Hyper runV</a>. The goal of the project is to create a container runtime that would run containers as virtual machines, however, with the speed comparable to the namespace-based containers. This would allow to bring the secure hypervisor-based isolation to containers.</li>
<li>Kata Containers would provide an alternative to the <a href="https://github.com/opencontainers/runc">runc</a> runtime which is used by the namespace-based containers. In the Kubernetes cluster, both namespace-based as well as hypervisor-based containers could run at the same time.</li>
<li>On Kubernetes, a Kubernetes pod would be implemented as a single VM.</li>
</ul>
</li>
<li><strong>Building Specialized Container-Based Systems with Moby: A Few Use Cases</strong>

<ul>
<li><a href="https://blog.docker.com/2017/04/introducing-the-moby-project/">Moby project</a> is pretty much an umbrella for all Docker open-source projects. Projects like <a href="https://github.com/containerd/containerd">containerd</a>, <a href="https://github.com/linuxkit/linuxkit">LinuxKit</a>, <a href="https://github.com/docker/infrakit">InfraKit</a>, and many more are part of the Moby project. From the components of the Moby project, Docker company builds their Docker SE product, from which the Docker EE product is derived. Moby project is governed by the Technical Steering Committee (<a href="https://github.com/moby/tsc">TSC</a>). In times before the TSC was established, technical disputes were resolved by the Benevolent Dictator for Life (BDFL) which was Solomon Hykes.</li>
<li><a href="https://github.com/linuxkit/linuxkit">LinuxKit</a> is a toolkit for building custom Linux images. The single purpose of these images is to run containerized applications. When creating an image, you can choose a Linux kernel, choose a container runtime and pick additional services that should be started on boot. If the basic containerd runtime doesn&rsquo;t suit you, LinuxKit can even install Kubernetes for you. Resulting images include only packages that you&rsquo;ve chosen and nothing else, hence reducing the attack surface and improving security. You can spin AWS instances off of your customized images and start scheduling containerized applications on them. Instances are considered immutable. In order to apply software updates, you must build a new version of the image and replace the instances running the old image.</li>
<li>In order to simplify the managing of the infrastructure running on top of immutable images (built with LinuxKit), Docker came up with another toolkit called <a href="https://github.com/docker/infrakit.git">InfraKit</a>. InfraKit allows you to create and manage clustered infrastructure like Swarm or Kubernetes clusters. Docker&rsquo;s motivation behind InfraKit was the deployment and management of their Docker SE and Docker EE products. Behind the scenes, InfraKit leverages Terraform for resource provisioning.</li>
</ul>
</li>
<li><strong>CRI-O: All the Runtime Kubernetes Needs and Nothing More</strong>

<ul>
<li>Container runtime containerd originally developed by Docker Inc. is used for various purposes. Besides Kubernetes and OpenShift, containerd powers Swarm clusters and the recently announced Amazon EKS is also going to leverage containerd. Being a general purpose runtime, containerd suffered from compatibility issues with Kubernetes, where an update of containerd would break the Kubernetes cluster. For the sake of stability and <a href="http://www.projectatomic.io/blog/2017/06/6-reasons-why-cri-o-is-the-best-runtime-for-kubernetes/">several other reasons</a>, Red Hat initiated a project <a href="http://cri-o.io/">CRI-O</a> which aims to create an alternative runtime that would be dedicated to Kubernetes only. CRI-O is available for testing in OpenShift 3.7 and it is going to ship as the default container runtime in the future OpenShift releases, replacing containerd.</li>
</ul>
</li>
<li><strong>Extending Kubernetes 101</strong>

<ul>
<li>Kubernetes can be extended by implementing a custom controller also called <em>operator</em>.</li>
<li>This controller runs as a pod on Kubernetes cluster. On startup, custom controller is supposed to register one or more custom resources with Kubernetes. After that, the controller watches the changes in the desired state of custom resources and acts upon them.</li>
<li>The concept of <a href="https://kubernetes.io/docs/concepts/api-extension/custom-resources/">Custom Resources</a> is supported by Kubernetes since version 1.7.</li>
<li>Custom resources are designed to feel like native Kubernetes resources. They are exposed as another API along with the native APIs. The kubectl client can discover and work with custom resources right away.</li>
<li>Using the kubectl, user can change the desired state of custom resources (add, update, delete). The custom controller that watches the desired state of the custom resources will carry on operations required to reach the desired state.</li>
<li>Btw., there&rsquo;s a generator available that speeds up the implementation of operators.</li>
<li>See also <a href="https://github.com/rook/operator-kit">Kubernetes Operator Kit</a>.</li>
</ul>
</li>
<li><strong>Certifik8ts: All You Need to Know about Certificates in Kubernetes</strong>

<ul>
<li>As of Kubernetes 1.8, the Kubelet can request a new client certificate when the current one is nearing its expiration.</li>
<li>Currently, Kubernetes cannot revoke certificates. This is good to know if you use client certificates to athenticate users. Once you issue a client certificate to the user, you won&rsquo;t be able to revoke it.</li>
</ul>
</li>
<li><strong>Istio: Saling to a Secure Services Mesh</strong>

<ul>
<li>Service mesh acts as a proxy on the communication path between your microservices. As a proxy, service mesh adds a host of useful functionality that you would otherwise have to implement yourself in your microservices: secure communication, traffic routing, load balancing, rate limiting, circuit breakers, timeouts and retries, metrics, reporting, etc.</li>
<li>Somebody on the conference has noted, that the year 2018 will be the year of the service mesh. Based on how many problems the service mesh can solve for distributed microservices, I can only agree with that.</li>
<li>In this talk, the security features of <a href="https://istio.io/">Istio</a> service mesh were presented.</li>
<li>Istio can establish a mutually authenticated TLS connections between your microservices, without the need to change your application code. It solves the problem of bootstrapping the TLS trust for you by establishing a custom CA.</li>
<li>Istio Ingress can expose the microservice outside of the service mesh.</li>
<li>Istio Egress controls which external hosts (hosts outside of the service mesh) your microservices can talk to.</li>
</ul>
</li>
<li><strong>Cost-effective Compute Clusters with Spot and Pre-emptible Instances</strong>

<ul>
<li>Quote: <em>Kubernetes is going to make spot instances mainstream</em>.</li>
<li>What applications work well with spot instances? Elastic/bursting applications, HPC workloads, HA cluster apps and horizontally scalable apps.</li>
</ul>
</li>
</ul>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[What I Learned at Red Hat Summit 2017]]></title>
    <link href="http://alesnosek.com/blog/2017/05/05/what-i-learned-at-red-hat-summit-2017/"/>
    <updated>2017-05-05T18:46:14-07:00</updated>
    <id>http://alesnosek.com/blog/2017/05/05/what-i-learned-at-red-hat-summit-2017</id>
    <content type="html"><![CDATA[<p>I had the great opportunity to visit the Red Hat Summit 2017. It was hosted in the Boston Convention and Exhibition Center in Boston in May 2-4, 2017. This blog post summarizes the interesting things I learned at the summit.</p>

<!-- more -->


<h2>Major announcements</h2>

<p><img class="right" src="/images/posts/rh_summit.png" width="200" height="200"></p>

<p><strong><a href="https://www.redhat.com/en/about/press-releases/red-hat-and-aws-extend-strategic-alliance-package-access-aws-services-within-red-hat-openshift">Red Hat OpenShift &amp; Amazon Web Services</a>.</strong> Red Hat will make AWS services accessible directly from the OpenShift web console. From within the OpenShift web console developers will be able to provision and configure AWS services such as CloudFront, ElastiCache, ELB, RDS, EMR, RedShift, S3 and Lambda.</p>

<p><strong><a href="https://www.redhat.com/en/about/press-releases/red-hat-unveils-end-end-cloud-native-development-environment-red-hat-openshiftio">Red Hat OpenShift.io</a>.</strong> <a href="https://openshift.io/">OpenShift.io</a> is an online development environment for building container-based applications. OpenShift.io can create a project in GitHub for you to store your source code. The source code editing can be done in the integrated Eclipse Che. OpenShift.io can create a project in OpenShift Online in order to build your application and deploy it. Jenkins pipelines are used to orchestrate the CI/CD process. Currently, OpenShift.io is available in a limited developer preview. You can sign up at <a href="https://openshift.io">https://openshift.io</a></p>

<h2>Sessions attended</h2>

<ul>
<li><strong>The future Red Hat Middleware portfolio: Stacks and services and solutions</strong>

<ul>
<li>Netflix OSS is interesting and Red Hat will support it because customers like it. However, some of the Netflix OSS features might be more efficiently implemented directly in Kubernetes instead of on top of Kubernetes. Netflix had to make architectural choices based on how AWS looked several years ago. AWS evolved since that time.</li>
<li>Architectural evolution: monolith -> n-tier architecture -> microservices.</li>
</ul>
</li>
<li><strong>Red Hat container technology strategy</strong>

<ul>
<li>Kubernetes has won. You may have just not realized it yet.</li>
<li>There are two reasons why the Kubernetes open source project is winning. First, it brings value to people. Second, people are excited to work on it.</li>
<li>Kubernetes = kernel of the cloud operating systems</li>
</ul>
</li>
<li><strong>Reproducible development to live applications with Java and Red Hat CDK</strong>

<ul>
<li>When developing containerized applications, developers can run them locally (outside of a container), locally on <a href="https://github.com/minishift/minishift">MiniShift</a>, or hosted on <a href="https://www.openshift.com/">OpenShift Online</a>.</li>
<li><a href="https://developers.redhat.com/products/cdk">Red Hat Container Development Kit</a> can help you develop container-based applications quickly. It uses MiniShift under the hood.</li>
</ul>
</li>
<li><strong>Modern Java and DevOps lightning talks</strong>

<ul>
<li>You can issue <code>oc cluster up</code> to create a local OpenShift all-in-one cluster (requires Origin >= 1.3).</li>
<li><a href="https://projects.eclipse.org/proposals/eclipse-microprofile">Eclipse MicroProfile</a> project is aimed at optimizing Enterprise Java for the microservices architecture. It focuses, among others, on application configuration, health-checking, fault tolerance and security.</li>
<li>You can use API Gateway (e.g <a href="https://apigee.com/about/cp/api-gateway">Apigee</a>, <a href="https://www.3scale.net/">3scale</a>) to dynamically route traffic into different OpenShift namespaces (test, staging, production).</li>
</ul>
</li>
<li><strong>Atomic BOF</strong>

<ul>
<li>In the future, the classic RHEL will be derived from the RHEL Atomic Host. It means that the new features will appear in the RHEL Atomic Host before being included into RHEL.</li>
</ul>
</li>
<li><strong>Stepping off a cliff: Common sense approaches to cloud security</strong>

<ul>
<li>VMs in the cloud are created and destroyed dynamically. This is one of the challenges for the security team.</li>
</ul>
</li>
<li><strong>Wicked fast PaaS: Performance tuning of OpenShift and Docker</strong>

<ul>
<li>RHEL 7.4 should support OverlayFS. For Docker storage, the OverlayFS is more memory efficient than the LVM thin pool provisioning, as with OverlayFS, the pages in the page cache can be shared between multiple containers.</li>
<li>Beginning with OpenShift 3.5, the container image metadata will be stored only in the Docker registry. In previous versions of OpenShift, a duplicate of the image metadata was stored in etcd, too.</li>
</ul>
</li>
<li><strong>The Truth about Microservices</strong>

<ul>
<li>&ldquo;Building a single microservice is easy. Building a microservices architecture is hard.&rdquo;</li>
</ul>
</li>
<li><strong>The hardest part of microservices is your data</strong>

<ul>
<li><a href="http://debezium.io/">Debezium</a> monitors the changes committed to the database (MySQL, MongoDB, PostgreSQL). For each database change, Debezium publishes an event to the Kafka broker. To consume the change events, an application can create a Kafka consumer that will consume all events for the topics associated with the database. In summary, Debezium turns a database transaction log into a Kafka stream that other applications can consume.</li>
</ul>
</li>
<li><strong>Reactive systems with Eclipse Vert.x and Red Hat OpenShift</strong>

<ul>
<li><a href="http://vertx.io/">Vert.x</a> is a toolkit for building reactive applications on the JVM. It can discover services on OpenShift and Kubernetes.</li>
</ul>
</li>
<li><strong>Container infrastructure trends: Optimizing for production workloads</strong>

<ul>
<li><a href="https://github.com/projectatomic/skopeo">skopeo</a> is a command line utility that allows you to inspect Docker images and image registries. It retrieves the required information from the repository metadata without the need to download the actual image. For example, with skopeo you can find out which tags are available for the given repository.</li>
<li><a href="https://github.com/projectatomic/buildah">buildah</a> a tool for building Docker images. It can build container images without using the Docker daemon. Ansible-container and OpenShift&rsquo;s S2I will be modified to use buildah under the hood.</li>
</ul>
</li>
<li><strong>Function as a Service (Faas) - why you should care and what you need to know</strong>

<ul>
<li>Architectural evolution: service -> microservice -> function.</li>
<li>Good serverless use-cases: processing web-hooks, scheduled tasks (a la cron), data transformation (converting small images).</li>
<li>Serverless architecture challenges: cannot use a larger programming framework to implement the function, as this would be too slow to initialize, increased latency in comparison to a long-running server process, large variance in latency, very complex at scale, debugging of functions is hard.</li>
<li>Red Hat participates on development of <a href="https://funktion.fabric8.io/">Funktion</a> that is part of the project <a href="https://fabric8.io/">fabric8</a>.</li>
</ul>
</li>
</ul>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Red Hat Summit 2016]]></title>
    <link href="http://alesnosek.com/blog/2016/07/04/red-hat-summit-2016/"/>
    <updated>2016-07-04T20:26:12-07:00</updated>
    <id>http://alesnosek.com/blog/2016/07/04/red-hat-summit-2016</id>
    <content type="html"><![CDATA[<p>I had the great opportunity to visit the Red Hat Summit 2016. Enjoy the photos attached.</p>

<!-- more -->


<p>The Red Hat summit was hosted at the Moscone Center in San Francisco in June 27-30, 2016. I greatly enjoyed the technical presentations by Red Hatters as well as the opportunity to discuss the OpenShift and Red Hat Atomic products directly with the lead engineers. At my company, we&rsquo;re looking at OpenShift+Atomic as the possible next platform to base our product upon. The frank opinions provided by the Red Hat engineers were very useful for our research. Next, take a look at the pics below.</p>

<p>General sessions and the Red Hat party at the end of the summit took place at Moscone Center North:</p>

<p><img class="center" src="/images/posts/redhatsummit2016/20160629_135631.jpg">
<img class="center" src="/images/posts/redhatsummit2016/20160628_134625.jpg"></p>

<p>Breakout sessions were hosted at the Moscone Center West:</p>

<p><img class="center" src="/images/posts/redhatsummit2016/20160630_152426.jpg">
<img class="center" src="/images/posts/redhatsummit2016/20160629_151110.jpg"></p>

<p>The big Red Hat logo at the entrance hall. The red and black colors really catch your eyes:</p>

<p><img class="center" src="/images/posts/redhatsummit2016/20160628_195533.jpg"></p>

<p>Jim Whitehurst, president and CEO of Red Hat, and myself. Check out my <a href="/blog/2016/07/04/what-i-learned-from-the-open-organization">next post</a> to find out, what I learned from the book I&rsquo;m holding in the picture.</p>

<p><img class="center" src="/images/posts/redhatsummit2016/20160629_132338.jpg"></p>
]]></content>
  </entry>

</feed>
