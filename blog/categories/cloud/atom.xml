<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cloud | Ales Nosek - The Software Practitioner]]></title>
  <link href="http://alesnosek.com/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="http://alesnosek.com/"/>
  <updated>2016-03-27T23:03:35-07:00</updated>
  <id>http://alesnosek.com/</id>
  <author>
    <name><![CDATA[Ales Nosek]]></name>

  </author>
  <generator uri="http://octopress.org/">Octopress</generator>


  <entry>
    <title type="html"><![CDATA[TripleO Installer - the Good, the Bad and the Ugly]]></title>
    <link href="http://alesnosek.com/blog/2016/03/27/tripleo-installer-the-good/"/>
    <updated>2016-03-27T19:39:15-07:00</updated>
    <id>http://alesnosek.com/blog/2016/03/27/tripleo-installer-the-good</id>
    <content type="html"><![CDATA[<p><a href="https://wiki.openstack.org/wiki/TripleO">TripleO</a> is an OpenStack deployment and management tool I&rsquo;ve been using since the Kilo release of OpenStack. It does its job pretty well, however not everything is perfect. My experience presented in this article applies more or less to the Red Hat&rsquo;s OpenStack director too, as the Red Hat OpenStack director is a downstream version of TripleO.</p>

<!-- more -->


<h2>The good things about TripleO</h2>

<h3>TripleO is a great idea</h3>

<p>TripleO, aka OpenStack-on-OpenStack, installs OpenStack cluster using OpenStack. At first, a minimum one-node OpenStack installation is created which is in turn used to provision a much bigger workload OpenStack cluster. I find this TripleO idea amazing. If OpenStack is the best way to manage your infrastructure, then why use something else to install it? As an administrator I would prefer to provision my OpenStack nodes with Ironic before introducing yet another tool like <a href="http://cobbler.github.io/">Cobbler</a> to do the same job. Needless to say that as the Ironic and Heat components improve, so improves the OpenStack installation experience.</p>

<p>One could argue that using the OpenStack to form an installer comes with a ton of complexity when installing the installer itself. In my experience, however, the installation of the undercloud OpenStack using the provided Puppet scripts doesn&rsquo;t impose any problem.</p>

<h3>TripleO has a vibrant community</h3>

<p>TripleO is used to continuously deploy and test the OpenStack cloud during its development. The RDO project adopted TripleO as their OpenStack installation tool. Red Hat derives their OpenStack director installer from the RDO project. A large community of TripleO users is a great plus.</p>

<h2>The bad things about TripleO</h2>

<h3>Configuration flexibility</h3>

<p>TripleO installer consists of a bunch of Heat templates to orchestrate the overcloud image provisioning and a number of Puppet and shell scripts for the following configuration of the overcloud nodes. These templates and scripts are heavily developed from release to release as the new TripleO features come in. To avoid the upgrade headaches, you should not modify the TripleO templates and scripts directly. Instead, TripleO provides extension points (via extra config) where you can put your customizations. This didn&rsquo;t work for me. My goal was to deploy an Ironic service in the overcloud OpenStack. For that to work, I needed to provision an additional undercloud network including a VIP for the load balancer. This was not possible without patching the Heat templates and Puppet scripts. I dread the day when I&rsquo;ll have to port these patches to the next TripleO release.</p>

<p>Furthermore, the current way to modify OpenStack configuration properties is less straight forward. To configure a property, I have to first grep through the Puppet scripts to find out whether the desired property is managed by Puppet or not. Afterwards, I grep through the TripleO Heat templates to find out whether TripleO provides a direct template parameter to set the Puppet variable or not. Afterwards, I can either pass the parameter to the TripleO template or I set the Puppet variable in the extra config section or I&rsquo;m on my own.</p>

<p><blockquote><p>I&rsquo;d like to be able to easily modify any property in any configuration file on any OpenStack node.</p></blockquote></p>

<p>OpenStack comes with tons of configuration properties and I think it would be great to have a more straight forward way to configure them.</p>

<h3>Deployment control</h3>

<p>TripleO uses Heat to deploy and configure the overcloud OpenStack. Heat orchestrates the infrastracture based on the description provided by the user in the Heat templates. In the Heat templates, we tell Heat what our deployment should look like, but we have no control over the steps Heat will take to get to the desired state. I find this lack of control rather problematic.</p>

<p><blockquote><p>A fine-grained deployment control would be desirable.</p></blockquote></p>

<p>Let&rsquo;s say I have an overcloud consisting of 100 nodes. After changing the configuration in my Heat templates, I can only re-run the entire Heat configuration process and hope that I won&rsquo;t end up with a broken cloud. Instead, I&rsquo;d like to apply the configuration changes to a couple of nodes to make sure that everything works before I continue with the rest of the cloud. The ability to apply only part of the configuration would be useful as well.</p>

<h2>The ugly experience with TripleO</h2>

<p>I&rsquo;d like to share one scary experience I had with the TripleO installer. While using TripleO for a couple of months, I have to say that this was the only serious problem I&rsquo;ve encountered.</p>

<p>One day I uploaded an updated node image into the undercloud OpenStack. I was about to create new nodes in the overcloud cluster and wanted to have them provisioned with this new image. After starting the Heat stack update, it occurred to me that the processing took longer than usual. Well, after I SSHed into the overcloud nodes I realized why. Heat simply wiped out the entire disk content of the existing nodes and replaced it with the fresh disk image. Wow, my entire workload cloud was gone!</p>

<p>I learned that when you update the disk image in the undercloud, Heat will find out what nodes have to be updated and will simply replace their disk content with the new image. If you are orchestrating cloud deployments where your machines are cattle, this is what you want, however:</p>

<p><blockquote><p>The overcloud baremetal nodes are pets and should not be handled as cattle.</p></blockquote></p>

<p>To protect the overcloud nodes from deletion, I run the following command for each node against the undercloud Nova database:
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">UPDATE</span> <span class="n">instances</span> <span class="k">SET</span> <span class="n">disable_terminate</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">WHERE</span> <span class="n">uuid</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="o">&lt;</span><span class="n">uuid</span> <span class="k">of</span> <span class="n">the</span> <span class="n">overcloud</span> <span class="n">instance</span><span class="o">&gt;&amp;</span><span class="n">rsquo</span><span class="p">;;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>So far, I haven&rsquo;t found a better way how to do it. This effectively prevents deleting the node whether by issuing a <code>nova delete</code> command or by Heat when updating the stack.</p>

<h2>Conclusion and suggestions</h2>

<p>TripleO installer is a great tool to deploy an OpenStack cloud. It&rsquo;s backed by a large user community and doesn&rsquo;t invent any new tools to install OpenStack.</p>

<p>On the other hand, I&rsquo;m somewhat sceptical about Heat being the right tool to do software configuration. Funneling the configuration options through the Heat templates down to the Puppet scripts seems cumbersome to me.</p>

<p>I&rsquo;d like to suggest the following approach: let Heat do the node provisioning, network configuration and perhaps a minimum node setup using cloud-init. At the end of the deployment, Heat would provide the information about the deployment in the format understandable to the configuration management tools like Puppet, Chef or Ansible. The configuration management tool then merges the facts provided by Heat with the tons of OpenStack configuration settings provided by the user. The following OpenStack installation, configuration, and later orchestration would solely be done by the configuration management tool more suitable for this job. Heat would not be involved at all in this stage.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Bootstrapping a Galera Cluster on RHEL7]]></title>
    <link href="http://alesnosek.com/blog/2016/01/31/bootstrapping-a-galera-cluster-on-rhel7/"/>
    <updated>2016-01-31T15:24:55-08:00</updated>
    <id>http://alesnosek.com/blog/2016/01/31/bootstrapping-a-galera-cluster-on-rhel7</id>
    <content type="html"><![CDATA[<p>The MariaDB Galera packages provided by the RDO project in their OpenStack repositories don&rsquo;t seem to include a command or script to bootstrap the cluster. Let&rsquo;s look at an alternative way to bring the cluster up.</p>

<!-- more -->


<p>RHEL7 comes with the init system <code>systemd</code>. Unfortunately, systemd doesn&rsquo;t provide a way to pass command-line arguments to the unit files. Hence, doing something like this won&rsquo;t work:
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="o">[</span>root@rhel1 ~<span class="o">]</span><span class="nv">$ </span>systemctl start mariadb <span class="p">&amp;</span>ndash<span class="p">;</span>wsrep_new_cluster
</span><span class='line'>systemctl: unrecognized option <span class="p">&amp;</span>lsquo<span class="p">;&amp;</span>ndash<span class="p">;</span>wsrep_new_cluster<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Instead of passing command-line arguments, systemd allows for creating <a href="http://0pointer.de/blog/projects/instances.html">multiple instances</a> of the same service where each instance can obtain it&rsquo;s own set of environment variables. The Percona XtraDB Cluster includes the standard and the bootstrap service instance definitions in the RPM package <code>Percona-XtraDB-Cluster-server</code>. To boostrap the Percona cluster, the first node can be started with the following command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="o">[</span>root@percona1 ~<span class="o">]</span><span class="nv">$ </span>systemctl start &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;&amp;#109;&amp;#x61;&amp;#105;&amp;#108;&amp;#x74;&amp;#111;&amp;#x3a;&amp;#x6d;&amp;#x79;&amp;#x73;&amp;#x71;&amp;#x6c;&amp;#64;&amp;#98;&amp;#x6f;&amp;#111;&amp;#116;&amp;#x73;&amp;#x74;&amp;#114;&amp;#97;&amp;#x70;&amp;#46;&amp;#x73;&amp;#101;&amp;#114;&amp;#118;&amp;#x69;&amp;#99;&amp;#101;&quot;</span>&gt;<span class="p">&amp;</span><span class="c">#x6d;&amp;#x79;&amp;#x73;&amp;#x71;&amp;#x6c;&amp;#64;&amp;#x62;&amp;#111;&amp;#x6f;&amp;#x74;&amp;#115;&amp;#116;&amp;#114;&amp;#97;&amp;#x70;&amp;#x2e;&amp;#115;&amp;#x65;&amp;#114;&amp;#x76;&amp;#x69;&amp;#99;&amp;#101;&lt;/a&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>At the moment, this boostrap service definition is missing in the RDO OpenStack packages. Before a similar <code>mysql@.service</code> script is available in RDO you can start the MariaDB Galera cluster as follows:</p>

<ul>
<li><p>On the first node, start the MariaDB with the <code>--wsrep-new-cluster</code> to create a new cluster:
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="o">[</span>root@rhel1 ~<span class="o">]</span><span class="nv">$ </span>/usr/bin/mysqld_safe <span class="p">&amp;</span>ndash<span class="p">;</span>wsrep-new-cluster
</span></code></pre></td></tr></table></div></figure>
Let the command run in the foreground.</p></li>
<li><p>On the remaining cluster nodes start the mariadb service as usual:
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="o">[</span>root@rhel2 ~<span class="o">]</span><span class="nv">$ </span>systemctl start mariadb
</span></code></pre></td></tr></table></div></figure></p></li>
<li><p>After the cluster has been fully formed, stop the mariadb on the first node by sending it a SIGQUIT (press CTRL + \ on the console).</p></li>
<li><p>On the first node, start the mariadb service via systemd:
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="o">[</span>root@rhel1 ~<span class="o">]</span><span class="nv">$ </span>systemctl start mariadb
</span></code></pre></td></tr></table></div></figure></p></li>
</ul>


<p>That&rsquo;s it. You can check the status of each of the cluster nodes by running the following command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="o">[</span>root@rhel1 ~<span class="o">]</span><span class="nv">$ </span>mysql -e <span class="p">&amp;</span>ldquo<span class="p">;</span>SHOW GLOBAL STATUS LIKE <span class="p">&amp;</span>lsquo<span class="p">;</span>wsrep%<span class="p">&amp;</span>rsquo<span class="p">;;&amp;</span>rdquo<span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Monitoring OpenStack Cluster with Icinga]]></title>
    <link href="http://alesnosek.com/blog/2015/11/30/monitoring-openstack-cluster-with-icinga/"/>
    <updated>2015-11-30T21:13:33-08:00</updated>
    <id>http://alesnosek.com/blog/2015/11/30/monitoring-openstack-cluster-with-icinga</id>
    <content type="html"><![CDATA[<p>If you don&rsquo;t monitor it, it&rsquo;s not in production! To get an OpenStack cloud ready for production, monitoring is a must. Let&rsquo;s take a look at two projects providing Nagios/Icinga plugins for checking the health of OpenStack services.</p>

<!-- more -->


<p>First, a few words about <a href="https://www.icinga.org/" title="Icinga">Icinga</a>. I started using Icinga 2 only recently and I&rsquo;m very pleased with this flexible and well-documented software. I&rsquo;ve listened to a German presentation about Icinga where they said that Icinga was not that widely spread in the US as it was the case in Europe. Dear Icinga team, you have one more happy user in the US now. Your software just works and your web GUI is beautiful.</p>

<p>I found two very useful projects for monitoring the OpenStack APIs both hosted on GitHub:</p>

<ul>
<li><a href="https://github.com/cirrax/openstack-nagios-plugins">OpenStack Nagios Plugins</a></li>
<li><a href="https://github.com/openstack/monitoring-for-openstack">Monitoring for OpenStack</a></li>
</ul>


<h2>OpenStack Nagios Plugins</h2>

<p><a href="https://github.com/cirrax/openstack-nagios-plugins">OpenStack Nagios Plugins</a> provides a collection of checks for the OpenStack services Nova, Neutron, Cinder, Keystone and Ceilometer. Available plugins worked right away with my OpenStack Liberty cluster. The Nova Hypervisor check monitors the &ldquo;virtual&rdquo; CPU and memory usage across your compute nodes. The name virtual CPU is a little misleading here. In reality, the number of physical cores is monitored as the Nova API actually reports the number of physical cores. I stick to the OpenStack default settings that overcommit the CPUs by factor of 16 and the memory by factor of 1.5. To accommodate this fact, I changed the warning and critical ranges for the check_nova-hypervisors plugin as follows:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>check_nova-hypervisors <span class="p">&amp;</span>ndash<span class="p">;</span>warn_memory_percent 0:135 <span class="p">&amp;</span>ndash<span class="p">;</span>critical_memory_percent 0:142 <span class="p">&amp;</span>ndash<span class="p">;</span>warn_vcpus_percent 0:1440 <span class="p">&amp;</span>ndash<span class="p">;</span>critical_vcpus_percent 0:1520
</span></code></pre></td></tr></table></div></figure></p>

<h2>Monitoring for OpenStack</h2>

<p>Plugins coming with the <a href="(https://github.com/openstack/monitoring-for-openstack">Monitoring for OpenStack</a> project provide deeper checks of OpenStack functionality. I liked the following ones the best:</p>

<ul>
<li><code>check_nova_instance</code>: Creates an instance on your cloud and deletes it again as soon as it is active. It&rsquo;s recommended to use a small disk image like cirros for this check.</li>
<li><code>cinder_volume</code>: Allocates a volume of size 1GB and deletes it again.</li>
<li><code>neutron_floating_ip</code>: Tries to allocate a floating IP. You have to configure the network where to allocate the IP from.</li>
<li><code>glance_upload</code>: Uploads 1MB of data as an image into Glance.</li>
<li><code>check_horizon_login</code>: Given a user name and a password the plugin will log into the Horizon dashboard.</li>
</ul>


<p>Some of the plugins didn&rsquo;t work for me due to incompatibilities with the Liberty client APIs. If you encounter the same problem you can try out my fixed version of the plugins on GitHub <a href="https://github.com/noseka1/monitoring-for-openstack">here</a>.</p>

<h2>Icinga 2 Screenshot</h2>

<p>And this is how the OpenStack APIs service group looks in Icinga Web 2. Happy monitoring!</p>

<p><img class="center" src="/images/posts/osmon.png"></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Assigning Roles to Nodes Directly in RDO]]></title>
    <link href="http://alesnosek.com/blog/2015/11/09/assigning-roles-to-nodes-directly-in-rdo/"/>
    <updated>2015-11-09T20:49:40-08:00</updated>
    <id>http://alesnosek.com/blog/2015/11/09/assigning-roles-to-nodes-directly-in-rdo</id>
    <content type="html"><![CDATA[<p>RDO Manager defines multiple roles that nodes can play in OpenStack deployment. For large-sized installations, RDO features automatic assignment of roles to nodes. This assignment is based on the facts that RDO obtained about each node during the introspection. However, for smaller deployments, you might prefer to assign the roles to the available nodes by hand. It was not straight forward for me to find out about this manual option even when it is described in the <a href="http://docs.openstack.org/developer/tripleo-docs/advanced_deployment/profile_matching.html#optional-manually-add-the-profiles-to-the-nodes" title="TripleO documentation">TripleO documentation</a>. Let&rsquo;s review the required configuration steps in this blogpost.</p>

<!-- more -->


<p>The relationship between roles and nodes is organized via flavors. A flavor is a set of properties that the target node must match in order to be eligible for deployment of a specific role. The manual assignment of a role to a node is a three-step process:</p>

<ol>
<li>Define a flavor with a property <code>capabilities:profile</code> set to the role name</li>
<li>Add the same profile to the capabilities list of the target node</li>
<li>Tell RDO what flavor to use for a specific role when beginning the deployment</li>
</ol>


<p>The creation of flavors with the associated <code>capabilities:profile</code> property looks like this:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>openstack flavor create <span class="p">&amp;</span>ndash<span class="p">;</span>id auto <span class="p">&amp;</span>ndash<span class="p">;</span>ram <span class="m">4096</span> <span class="p">&amp;</span>ndash<span class="p">;</span>disk <span class="m">40</span> <span class="p">&amp;</span>ndash<span class="p">;</span>vcpus <span class="m">1</span> ceph
</span><span class='line'>openstack flavor create <span class="p">&amp;</span>ndash<span class="p">;</span>id auto <span class="p">&amp;</span>ndash<span class="p">;</span>ram <span class="m">4096</span> <span class="p">&amp;</span>ndash<span class="p">;</span>disk <span class="m">40</span> <span class="p">&amp;</span>ndash<span class="p">;</span>vcpus <span class="m">1</span> cinder
</span><span class='line'>openstack flavor create <span class="p">&amp;</span>ndash<span class="p">;</span>id auto <span class="p">&amp;</span>ndash<span class="p">;</span>ram <span class="m">4096</span> <span class="p">&amp;</span>ndash<span class="p">;</span>disk <span class="m">40</span> <span class="p">&amp;</span>ndash<span class="p">;</span>vcpus <span class="m">1</span> compute
</span><span class='line'>openstack flavor create <span class="p">&amp;</span>ndash<span class="p">;</span>id auto <span class="p">&amp;</span>ndash<span class="p">;</span>ram <span class="m">4096</span> <span class="p">&amp;</span>ndash<span class="p">;</span>disk <span class="m">40</span> <span class="p">&amp;</span>ndash<span class="p">;</span>vcpus <span class="m">1</span> controller
</span><span class='line'>openstack flavor create <span class="p">&amp;</span>ndash<span class="p">;</span>id auto <span class="p">&amp;</span>ndash<span class="p">;</span>ram <span class="m">4096</span> <span class="p">&amp;</span>ndash<span class="p">;</span>disk <span class="m">40</span> <span class="p">&amp;</span>ndash<span class="p">;</span>vcpus <span class="m">1</span> swift&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;openstack flavor <span class="nb">set</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>cpu_arch<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>x86_64<span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:boot_option<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span><span class="nb">local</span><span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:profile<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>ceph<span class="p">&amp;</span>rdquo<span class="p">;</span> ceph
</span><span class='line'>openstack flavor <span class="nb">set</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>cpu_arch<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>x86_64<span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:boot_option<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span><span class="nb">local</span><span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:profile<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>cinder<span class="p">&amp;</span>rdquo<span class="p">;</span> cinder
</span><span class='line'>openstack flavor <span class="nb">set</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>cpu_arch<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>x86_64<span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:boot_option<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span><span class="nb">local</span><span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:profile<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>compute<span class="p">&amp;</span>rdquo<span class="p">;</span> compute
</span><span class='line'>openstack flavor <span class="nb">set</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>cpu_arch<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>x86_64<span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:boot_option<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span><span class="nb">local</span><span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:profile<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>controller<span class="p">&amp;</span>rdquo<span class="p">;</span> controller
</span><span class='line'>openstack flavor <span class="nb">set</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>cpu_arch<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>x86_64<span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:boot_option<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span><span class="nb">local</span><span class="p">&amp;</span>rdquo<span class="p">;</span> <span class="p">&amp;</span>ndash<span class="p">;</span>property <span class="p">&amp;</span>ldquo<span class="p">;</span>capabilities:profile<span class="p">&amp;</span>rdquo<span class="p">;</span><span class="o">=</span><span class="p">&amp;</span>ldquo<span class="p">;</span>swift<span class="p">&amp;</span>rdquo<span class="p">;</span> swift
</span></code></pre></td></tr></table></div></figure></p>

<p>Now we need to add the profiles to the capabilities list of the respective nodes:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ironic node-update &lt;node1 UUID here&gt; replace properties/capabilities<span class="o">=</span><span class="p">&amp;</span>lsquo<span class="p">;</span>profile:ceph,boot_option:local<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>ironic node-update &lt;node2 UUID here&gt; replace properties/capabilities<span class="o">=</span><span class="p">&amp;</span>lsquo<span class="p">;</span>profile:cinder,boot_option:local<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>ironic node-update &lt;node3 UUID here&gt; replace properties/capabilities<span class="o">=</span><span class="p">&amp;</span>lsquo<span class="p">;</span>profile:compute,boot_option:local<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>ironic node-update &lt;node4 UUID here&gt; replace properties/capabilities<span class="o">=</span><span class="p">&amp;</span>lsquo<span class="p">;</span>profile:controller,boot_option:local<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>ironic node-update &lt;node5 UUID here&gt; replace properties/capabilities<span class="o">=</span><span class="p">&amp;</span>lsquo<span class="p">;</span>profile:swift,boot_option:local<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>When deploying the OpenStack cloud, we need to tell the RDO manager what flavor to use for each specific role:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>openstack overcloud deploy <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>templates /usr/share/openstack-tripleo-heat-templates <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>ceph-storage-scale <span class="m">1</span> <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>block-storage-scale <span class="m">1</span> <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>compute-scale <span class="m">1</span> <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>control-scale <span class="m">1</span> <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>swift-storage-scale <span class="m">1</span> <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>ceph-storage-flavor ceph <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>block-storage-flavor cinder <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>compute-flavor compute <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>control-flavor controller <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>swift-storage-flavor swift
</span></code></pre></td></tr></table></div></figure></p>

<p>And that&rsquo;s all for today. Hope you&rsquo;re enjoying the full control over your OpenStack cloud deployment.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Installing OpenStack Liberty on RHEL7]]></title>
    <link href="http://alesnosek.com/blog/2015/10/19/installing-openstack-liberty-on-rhel7/"/>
    <updated>2015-10-19T22:30:48-07:00</updated>
    <id>http://alesnosek.com/blog/2015/10/19/installing-openstack-liberty-on-rhel7</id>
    <content type="html"><![CDATA[<p>The OpenStack Liberty was released last week. In this article I&rsquo;ll briefly describe how to deploy the OpenStack Liberty on RHEL7 using RDO Manager.</p>

<!-- more -->


<p>The <a href="https://www.rdoproject.org/" title="RDO project">RDO project</a> packages the OpenStack software for the Red Hat based platforms. Currently, there are Liberty packages in status testing/release candidate available from the project. Apart from a couple of configuration issues the installation went pretty well and I obtained a basic 2-node cluster.</p>

<p>If you intalled OpenStack Kilo using RDO Manager before I have a good news for you. The installation procedure remains pretty much the same. You can follow the <a href="http://docs.openstack.org/developer/tripleo-docs/" title="TripleO Doc">great guide</a> provided by the TripleO project to get the installation going. First, add the following two repositories:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;a href="http://trunk.rdoproject.org/centos7/current-tripleo/delorean.repo">http://trunk.rdoproject.org/centos7/current-tripleo/delorean.repo&lt;/a>
</span><span class='line'>&lt;a href="http://trunk.rdoproject.org/centos7/delorean-deps.repo">http://trunk.rdoproject.org/centos7/delorean-deps.repo&lt;/a></span></code></pre></td></tr></table></div></figure></p>

<p>Now you can install the RDO Manager with:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo yum install python-tripleoclient</span></code></pre></td></tr></table></div></figure></p>

<p>In the Kilo release, the <code>python-tripleoclient</code> package was called <code>python-rdomanager-oscplugin</code>. You can continue with the guide. To build the overcloud images I issue the commands:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nb">export </span><span class="nv">NODE_DIST</span><span class="o">=</span>rhel7
</span><span class='line'><span class="nb">export </span><span class="nv">DIB_LOCAL_IMAGE</span><span class="o">=</span>rhel-guest-image-7.1-20150224.0.x86_64.qcow2
</span><span class='line'><span class="nb">export </span><span class="nv">REG_METHOD</span><span class="o">=</span>disable
</span><span class='line'><span class="nb">export </span><span class="nv">DIB_DEBUG_TRACE</span><span class="o">=</span>1
</span><span class='line'><span class="nb">export </span><span class="nv">DIB_YUM_REPO_CONF</span><span class="o">=</span>/etc/yum.repos.d/rhel7_mirror.repo
</span><span class='line'><span class="nb">export </span><span class="nv">USE_DELOREAN_TRUNK</span><span class="o">=</span>1
</span><span class='line'><span class="nb">export </span><span class="nv">DELOREAN_TRUNK_REPO</span><span class="o">=</span>&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;http://trunk.rdoproject.org/centos7/current-tripleo&quot;</span>&gt;http://trunk.rdoproject.org/centos7/current-tripleo&lt;/a&gt;
</span><span class='line'><span class="nb">export </span><span class="nv">DELOREAN_REPO_FILE</span><span class="o">=</span>delorean.repo
</span><span class='line'>openstack overcloud image build <span class="p">&amp;</span>ndash<span class="p">;</span>all
</span></code></pre></td></tr></table></div></figure></p>

<p>As you can see, I&rsquo;m not really registering the OpenStack nodes with the Red Hat portal. Instead, I&rsquo;m pulling the RHEL7 packages from the local mirror.</p>

<p>After the installation of the overcloud has completed I realized that some of the OpenStack processes on the overcloud nodes were segfaulting. After switching SELinux from enforcing to permissive mode everything started working as expected.</p>

<h2>A final note</h2>

<p>The deployment of OpenStack is rather an involved process even when leveraging the tools like RDO Manager. To truly automate the installation in my specific environment I use a set of Ansible scripts to drive the RDO manager installation. Now that Red Hat acquired Ansible I&rsquo;m wondering if we&rsquo;re going to get an even better OpenStack installation experience on Red Hat based distributions.</p>
]]></content>
  </entry>

</feed>
