<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cloud | Ales Nosek - The Software Practitioner]]></title>
  <link href="https://alesnosek.com/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="https://alesnosek.com/"/>
  <updated>2022-09-17T10:52:24-07:00</updated>
  <id>https://alesnosek.com/</id>
  <author>
    <name><![CDATA[Ales Nosek]]></name>

  </author>
  <generator uri="http://octopress.org/">Octopress</generator>


  <entry>
    <title type="html"><![CDATA[Monitoring Apache Airflow using Prometheus]]></title>
    <link href="https://alesnosek.com/blog/2021/01/29/monitoring-apache-airflow-using-prometheus/"/>
    <updated>2021-01-29T12:59:58-08:00</updated>
    <id>https://alesnosek.com/blog/2021/01/29/monitoring-apache-airflow-using-prometheus</id>
    <content type="html"><![CDATA[<p>This blog covers a proof of concept, which shows how to monitor Apache Airflow using Prometheus and Grafana.</p>

<!-- more -->


<h2>Airflow monitoring diagram</h2>

<p>Let&rsquo;s discuss the big picture first. Apache Airflow can send <a href="https://airflow.apache.org/docs/1.10.12/metrics.html">metrics</a> using the statsd protocol. These metrics would normally be received by a <a href="https://github.com/statsd/statsd">statsd server</a> and stored in a backend of choice. Our goal though, is to send the metrics to <a href="https://prometheus.io/">Prometheus</a>. How can the statsd metrics be sent to Prometheus? It turns out that the Prometheus project comes with a <a href="https://github.com/prometheus/statsd_exporter">statsd_exporter</a> that functions as a bridge between statsd and Prometheus. The statsd_exporter receives statsd metrics on one side and exposes them as Prometheus metrics on the other side. The Prometheus server can then scrape the metrics exposed by the statsd_exporter. Overall, the Airflow monitoring diagram looks as follows:</p>

<p><img class="center" src="/images/posts/airflow_monitoring_diagram.png"></p>

<p>The diagram depicts three Airflow components: Webserver, Scheduler, and the Worker. The solid line starting at the Webserver, Scheduler, and Worker shows the metrics flowing from the Webserver, Scheduler, and the Worker to the statsd_exporter. The statsd_exporter aggregates the metrics, converts them to the Prometheus format, and exposes them as a Prometheus endpoint. This endpoint is periodically scraped by the Prometheus server, which persists the metrics in its database. Airflow metrics stored in Prometheus can then be viewed in the Grafana dashboard.</p>

<p>The remaining sections of this blog will create the setup depicted in the above diagram. We are going to:</p>

<ul>
<li>configure Airflow to publish the statsd metrics</li>
<li>convert the statsd metrics to Prometheus metrics using statsd_exporter</li>
<li>deploy the Prometheus server to collect the metrics and make them available to Grafana</li>
</ul>


<p>By the end of the blog, you should be able to watch the Airflow metrics in the Grafana dashboard. Follow me to the next section, where we are going to start by installing Apache Airflow.</p>

<h2>Enabling statsd metrics on Airflow</h2>

<p>In this tutorial, I am using Python 3 and Apache Airflow version 1.10.12. First, create a Python virtual environment where Airflow will be installed:</p>

<pre><code>$ python -m venv airflow-venv
</code></pre>

<p>Activate the virtual environment:</p>

<pre><code>$ . airflow-venv/bin/activate
</code></pre>

<p>Install Apache Airflow along with the statsd client library:</p>

<pre><code>$ pip install apache-airflow
$ pip install statsd
</code></pre>

<p>Create the Airflow home directory in the default location:</p>

<pre><code>$ mkdir ~/airflow
</code></pre>

<p>Create the Airflow database and the <code>airflow.cfg</code> configuration file:</p>

<pre><code>$ airflow initdb
</code></pre>

<p>Open the Airflow configuration file <code>airflow.cfg</code> for editing:</p>

<pre><code>$ vi ~/airflow/airflow.cfg
</code></pre>

<p>Turn on the statsd metrics by setting <code>statsd_on = True</code>. Before saving your changes, the statsd configuration should look as follows:</p>

<pre><code>statsd_on = True
statsd_host = localhost
statsd_port = 8125
statsd_prefix = airflow
</code></pre>

<p>Based on this configuration, Airflow is going to send the statsd metrics to the statsd server that will accept the metrics on <code>localhost:8125</code>.  We are going to start that server up in the next section.</p>

<p>The last step in this section is to start the Airflow webserver and scheduler process. You may want to run these commands in two separate terminal windows. Make sure that you activate the Python virtual environment before issuing the commands:</p>

<pre><code>$ airflow webserver
$ airflow scheduler
</code></pre>

<p>At this point, the Airflow is running and sending statsd metrics to <code>localhost:8125</code>.  In the next section, we will spin up statsd_exporter, which will collect statsd metrics and export them as Prometheus metrics.</p>

<h2>Converting statsd metrics to Prometheus metrics</h2>

<p>Let&rsquo;s start this section by installing statsd_exporter. If you have the Golang environment properly set up on your machine, you can install statsd_exporter by simply issuing:</p>

<pre><code>$ go get github.com/prometheus/statsd_exporter
</code></pre>

<p>Alternatively, you can deploy statsd_exporter using the <a href="https://registry.hub.docker.com/r/prom/statsd-exporter">prom/statsd-exporter</a> container image. The image documentation includes instructions on how to pull and run the image.</p>

<p>While Airflow is running, start the statsd_exporter on the same machine:
<code>
$ statsd_exporter --statsd.listen-udp localhost:8125 --log.level debug
level=info ts=2020-09-18T15:26:51.283Z caller=main.go:302 msg="Starting StatsD -&gt; Prometheus Exporter" version="(version=, branch=, revision=)"
level=info ts=2020-09-18T15:26:51.283Z caller=main.go:303 msg="Build context" context="(go=go1.14.7, user=, date=)"
level=info ts=2020-09-18T15:26:51.283Z caller=main.go:304 msg="Accepting StatsD Traffic" udp=localhost:8125 tcp=:9125 unixgram=
level=info ts=2020-09-18T15:26:51.283Z caller=main.go:305 msg="Accepting Prometheus Requests" addr=:9102
level=debug ts=2020-09-18T15:26:52.534Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.executor.open_slots:32|g
level=debug ts=2020-09-18T15:26:52.534Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.executor.queued_tasks:0|g
level=debug ts=2020-09-18T15:26:52.534Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.executor.running_tasks:0|g
level=debug ts=2020-09-18T15:26:52.534Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.dag_processing.processes:1|c
level=debug ts=2020-09-18T15:26:52.637Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.dag_processing.processes:-1|c
level=debug ts=2020-09-18T15:26:52.684Z caller=exporter.go:114 msg="counter must be non-negative value" metric=airflow_dag_processing_processes event_value=-1
level=debug ts=2020-09-18T15:26:54.535Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.executor.open_slots:32|g
level=debug ts=2020-09-18T15:26:54.535Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.executor.queued_tasks:0|g
level=debug ts=2020-09-18T15:26:54.535Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.executor.running_tasks:0|g
level=debug ts=2020-09-18T15:26:54.535Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.dag_processing.processes:1|c
level=debug ts=2020-09-18T15:26:54.542Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.dag.loading-duration.example_trigger_target_dag:0.004020|ms
level=debug ts=2020-09-18T15:26:54.546Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.scheduler_heartbeat:1|c
level=debug ts=2020-09-18T15:26:54.637Z caller=listener.go:69 msg="Incoming line" proto=udp line=airflow.dag_processing.processes:-1|c
...
</code></p>

<p>If everything went okay, you should see the Airflow metrics rolling on the screen, as in the above example. You can also verify that the statsd_exporter is doing its job and exposes the metrics in the Prometheus format. The Prometheus metrics should be reachable at <code>localhost:9102</code>. You can use curl to obtain the Prometheus metrics:</p>

<pre><code>$ curl localhost:9102/metrics
# HELP airflow_collect_dags Metric autogenerated by statsd_exporter.
# TYPE airflow_collect_dags gauge
airflow_collect_dags 50.056391
# HELP airflow_dag_loading_duration_example_bash_operator Metric autogenerated by statsd_exporter.
# TYPE airflow_dag_loading_duration_example_bash_operator summary
airflow_dag_loading_duration_example_bash_operator{quantile="0.5"} 1.108e-06
airflow_dag_loading_duration_example_bash_operator{quantile="0.9"} 4.942e-06
airflow_dag_loading_duration_example_bash_operator{quantile="0.99"} 4.942e-06
airflow_dag_loading_duration_example_bash_operator_sum 1.8886000000000002e-05
airflow_dag_loading_duration_example_bash_operator_count 7
# HELP airflow_dag_loading_duration_example_branch_dop_operator_v3 Metric autogenerated by statsd_exporter.
# TYPE airflow_dag_loading_duration_example_branch_dop_operator_v3 summary
airflow_dag_loading_duration_example_branch_dop_operator_v3{quantile="0.5"} 1.61e-06
airflow_dag_loading_duration_example_branch_dop_operator_v3{quantile="0.9"} 5.776e-06
airflow_dag_loading_duration_example_branch_dop_operator_v3{quantile="0.99"} 5.776e-06
airflow_dag_loading_duration_example_branch_dop_operator_v3_sum 1.8076e-05
airflow_dag_loading_duration_example_branch_dop_operator_v3_count 6
...
</code></pre>

<h2>Collecting metrics using Prometheus</h2>

<p>After completing the previous section, the Airflow metrics are now available in the Prometheus format. As a next step, we are going to deploy the Prometheus server that will collect these metrics. You can install the Prometheus server by running the command:</p>

<pre><code>$ go get github.com/prometheus/prometheus/cmd/...
</code></pre>

<p>Note that a working Golang environment is required for the above command to succeed. Instead of installing Prometheus from the source, you can choose to use the existing <a href="https://hub.docker.com/r/prom/prometheus/">Prometheus</a> container image instead.</p>

<p>The minimum Prometheus configuration that will collect the Airflow metrics looks like this:
<code>
scrape_configs:
  - job_name: airflow
    static_configs:
      - targets: ['localhost:9102']
</code>
It instructs the Prometheus server to scrape the metrics from the endpoint <code>localhost:9102</code> periodically. Save the above configuration as a file named <code>prometheus.yml</code> and start the Prometheus server by issuing the command:</p>

<pre><code>$ prometheus --config.file prometheus.yml
</code></pre>

<p>You can now use your browser to go to the Prometheus built-in dashboard at <a href="http://localhost:9090/graph">http://localhost:9090/graph</a> and check out the Airflow metrics.</p>

<h2>Displaying metrics in Grafana</h2>

<p>Finally, we are going to display the Airflow metrics using Grafana. Interestingly enough, I was not able to find any pre-existing Grafana dashboard for Airflow monitoring. So, I went ahead and created a basic dashboard that you can find on <a href="https://github.com/noseka1/monitoring-apache-airflow-using-prometheus">GitHub</a>. This dashboard may be a good start for you. If you make further improvements to the dashboard that you&rsquo;d like to share with the community, I would be happy to receive a pull request. Currently, the dashboard looks like this:</p>

<p><img class="center" src="/images/posts/airflow_grafana_dashboard.png"></p>

<h2>Conclusion</h2>

<p>In this post, we deployed a proof of concept of Airflow monitoring using Prometheus. We deployed and configured Airflow to send metrics. We leveraged statsd_exporter to convert the metrics to the Prometheus format. We collected the metrics and saved them in Prometheus. Finally, we displayed the metrics on the Grafana dashboard. This proof of concept was spurred by my search for a way to monitor Apache Airflow, and it may be a good starting point for you. If you make further improvements to the dashboard that you’d like to share with the community, I would be happy to receive a pull request.</p>

<p>I hope you enjoyed this blog. If you have any further questions or comments, please leave them in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Configuring Envoy to Auto-Discover Pods on Kubernetes]]></title>
    <link href="https://alesnosek.com/blog/2019/08/19/configuring-envoy-to-audo-discover-pods-on-kubernetes/"/>
    <updated>2019-08-19T11:04:51-07:00</updated>
    <id>https://alesnosek.com/blog/2019/08/19/configuring-envoy-to-audo-discover-pods-on-kubernetes</id>
    <content type="html"><![CDATA[<p>Pods on Kubernetes are ephemeral and can be created and destroyed at any time. In order for Envoy to load balance the traffic across pods, Envoy needs to be able to track the IP addresses of the pods over time. In this blog post, I am going to show you how to leverage Envoy&rsquo;s Strict DNS discovery in combination with a headless service in Kubernetes to accomplish this.</p>

<!-- more -->


<h2>Overview</h2>

<p>Envoy provides several <a href="https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/service_discovery">options</a> on how to discover back-end servers. When using the <a href="https://www.envoyproxy.io/docs/envoy/v1.10.0/intro/arch_overview/service_discovery#strict-dns">Strict DNS</a> option,  Envoy will periodically query a specified DNS name. If there are multiple IP addresses included in the response to Envoy&rsquo;s query, each returned IP address will be considered a back-end server. Envoy will load balance the inbound traffic across all of them.</p>

<p>How to configure a DNS server to return multiple IP addresses to Envoy? Kubernetes comes with a <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a> object which, roughly speaking, provides two functions. It can create a single DNS name for a group of pods for discovery and it can load balance the traffic across those pods. We are not interested in the load balancing feature as we aim to use Envoy for that. However, we can make a good use of the discovery mechanism. The Service configuration we are looking for is called a <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">headless service</a> with selectors.</p>

<p>The diagram below depicts how to configure Envoy to auto-discover pods on Kubernetes. We are combining Envoy&rsquo;s Strict DNS service discovery with a headless service in Kubernetes:</p>

<p><img class="center" src="/images/posts/envoy_auto_discovery.png"></p>

<h2>Practical implementation</h2>

<p>To put this configuration into practice, I used <a href="https://www.okd.io/minishift/">Minishift</a> 3.11 which is a variant of Minikube developed by Red Hat. First, I deployed two replicas of the httpd server on Kubernetes to play the role of back-end services. Next, I created a headless service using the following definition:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">apiVersion</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">v1</span>
</span><span class='line'><span class="l-Scalar-Plain">kind</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Service</span>
</span><span class='line'><span class="l-Scalar-Plain">metadata</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd-discovery</span>
</span><span class='line'><span class="l-Scalar-Plain">spec</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusterIP</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">None</span>
</span><span class='line'>  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">http</span>
</span><span class='line'>      <span class="l-Scalar-Plain">port</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">8080</span>
</span><span class='line'>  <span class="l-Scalar-Plain">selector</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">app</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>  <span class="l-Scalar-Plain">type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ClusterIP</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Note that we are explicitly specifying &ldquo;None&rdquo; for the cluster IP in the service definition. As a result, Kubernetes creates the respective Endpoints object containing the IP addresses of the discovered httpd pods:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc get endpoints
</span><span class='line'>NAME              ENDPOINTS                                                        AGE
</span><span class='line'>httpd-discovery   172.17.0.21:8080,172.17.0.22:8080                                30s
</span></code></pre></td></tr></table></div></figure></p>

<p> If you ssh to one of the cluster nodes or rsh to any of the pods running on the cluster, you can verify that the DNS discovery is working:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>host httpd-discovery
</span><span class='line'>httpd-discovery.mynamespace.svc.cluster.local has address 172.17.0.21
</span><span class='line'>httpd-discovery.mynamespace.svc.cluster.local has address 172.17.0.22
</span></code></pre></td></tr></table></div></figure></p>

<p>Next, I used the container image <code>docker.io/envoyproxy/envoy:v1.7.0</code> to create an Envoy proxy. I deployed the proxy into the same Kubernetes namespace called <code>mynamespace</code> where I created the headless service before. A minimum Envoy configuration that can accomplish our goal looks as follows:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">static_resources</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">listeners</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">listener_0</span>
</span><span class='line'>    <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>        <span class="l-Scalar-Plain">protocol</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">TCP</span>
</span><span class='line'>        <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0.0.0.0</span>
</span><span class='line'>        <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">10000</span>
</span><span class='line'>    <span class="l-Scalar-Plain">filter_chains</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">filters</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">envoy.http_connection_manager</span>
</span><span class='line'>        <span class="l-Scalar-Plain">config</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="l-Scalar-Plain">stat_prefix</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ingress_http</span>
</span><span class='line'>          <span class="l-Scalar-Plain">route_config</span><span class="p-Indicator">:</span>
</span><span class='line'>            <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">local_route</span>
</span><span class='line'>            <span class="l-Scalar-Plain">virtual_hosts</span><span class="p-Indicator">:</span>
</span><span class='line'>            <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">local_service</span>
</span><span class='line'>              <span class="l-Scalar-Plain">domains</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span><span class="nl">&amp;ldquo</span><span class="nv">;*&amp;rdquo;</span><span class="p-Indicator">]</span>
</span><span class='line'>              <span class="l-Scalar-Plain">routes</span><span class="p-Indicator">:</span>
</span><span class='line'>              <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">match</span><span class="p-Indicator">:</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">prefix</span><span class="p-Indicator">:</span> <span class="nl">&amp;ldquo</span><span class="l-Scalar-Plain">;/&amp;rdquo;</span>
</span><span class='line'>                <span class="l-Scalar-Plain">route</span><span class="p-Indicator">:</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">host_rewrite</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>                  <span class="l-Scalar-Plain">cluster</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>          <span class="l-Scalar-Plain">http_filters</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">envoy.router</span>
</span><span class='line'>  <span class="l-Scalar-Plain">clusters</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd</span>
</span><span class='line'>    <span class="l-Scalar-Plain">connect_timeout</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">0.25s</span>
</span><span class='line'>    <span class="l-Scalar-Plain">type</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">STRICT_DNS</span>
</span><span class='line'>    <span class="l-Scalar-Plain">dns_lookup_family</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">V4_ONLY</span>
</span><span class='line'>    <span class="l-Scalar-Plain">lb_policy</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">ROUND_ROBIN</span>
</span><span class='line'>    <span class="l-Scalar-Plain">hosts</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">httpd-discovery</span>
</span><span class='line'>          <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">8080</span>
</span><span class='line'><span class="l-Scalar-Plain">admin</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">access_log_path</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">/tmp/admin_access.log</span>
</span><span class='line'>  <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">socket_address</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="l-Scalar-Plain">protocol</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">TCP</span>
</span><span class='line'>      <span class="l-Scalar-Plain">address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">127.0.0.1</span>
</span><span class='line'>      <span class="l-Scalar-Plain">port_value</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">9901</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Note that in the above configuration,  I instructed Envoy to use the Strict DNS discovery and pointed it to the DNS name <code>httpd-discovery</code> that is managed by Kubernetes.</p>

<p>That&rsquo;s all that was needed to be done! Envoy is load balancing the inbound traffic across the two httpd pods now. And if you create a third pod replica, Envoy is going to route the traffic to this replica as well.</p>

<h2>Conclusion</h2>

<p>In this article, I shared with you the idea of using Envoy&rsquo;s Strict DNS service discovery in combination with the headless service in Kubernetes to allow Envoy to auto-discover the back-end pods. While writing this article, I discovered this <a href="https://blog.markvincze.com/how-to-use-envoy-as-a-load-balancer-in-kubernetes/">blog post</a> by Mark Vincze that describes the same idea and you should take a look at it as well.</p>

<p>This idea opens the door for you to utilize the advanced features of Envoy proxy in your microservices architecture. However, if you find yourself looking for a more complex solution down the road, I would suggest that you evaluate the <a href="https://istio.io/">Istio</a> project. Istio provides a control plane that can manage Envoy proxies for you achieving the so called service mesh.</p>

<p>Hope you found this article useful. If you are using Envoy proxy on top of Kubernetes I would be happy to hear about your experiences. You can leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[How I Achieved the AWS Associate Certifications]]></title>
    <link href="https://alesnosek.com/blog/2018/08/30/how-i-achieved-the-aws-associate-certifications/"/>
    <updated>2018-08-30T23:20:27-07:00</updated>
    <id>https://alesnosek.com/blog/2018/08/30/how-i-achieved-the-aws-associate-certifications</id>
    <content type="html"><![CDATA[<p>Over the course of the last year I was working towards transitioning our company’s products to the AWS cloud. I gained a solid experience with many of the AWS services, wrote lots of lines of CloudFormation code, and embraced AWS reference architectures and best practices. To round up my AWS experience I thought that accomplishing some certifications would be a good idea. In this post, I am going to share with you how I achieved the AWS associate certifications.</p>

<!-- more -->


<p><a href="https://aws.amazon.com/certification/">AWS certifications</a> are divided into three levels of difficulty: foundational, associate, and professional. The foundational level is optional. If you worked with AWS cloud hands-on for several months, I would recommend skipping the foundational level and start your certification path at the associate level. The associate level comes with three certification options: Solutions Architect, Developer, and SysOps Administrator. In order to achieve a specific certification, you have to pass the respective multiple-choice test. As the requirements for the three tests highly overlap, I decided to study for all three certifications at the same time.</p>

<p>AWS certification is rather popular these days. It&rsquo;s no wonder that there is an abundance of preparation materials available. So, which one should you choose? I started off by reading the three official study guides:</p>

<ul>
<li><a href="https://www.amazon.com/Certified-Solutions-Architect-Official-Study/dp/1119138558">AWS Certified Solutions Architect Official Study Guide: Associate Exam</a></li>
<li><a href="https://www.amazon.com/Certified-SysOps-Administrator-Official-Study/dp/1119377420">AWS Certified SysOps Administrator Official Study Guide: Associate Exam</a></li>
<li><a href="https://www.amazon.com/Certified-Advanced-Networking-Official-Study-ebook/dp/B079VKD1CN">AWS Certified Advanced Networking Official Study Guide: Specialty Exam</a></li>
</ul>


<p>The three study guides are well organized and go beyond the associate exam requirements. I would recommend reading them even when you don&rsquo;t plan to get certified as they provide a good source of information about AWS in general.</p>

<p>In addition to reading the books, I made use of the AWS training courses offered by <a href="https://acloud.guru/courses?vendors=aws">A Cloud Guru</a>. I watched most of the videos from the Solutions Architect course and some of the videos from the SysOps Administrator course. I enjoyed the presentation style of Ryan Kroonenburg a lot and appreciated the practical demonstrations on AWS and the included exam tips. As I didn&rsquo;t really want to spend the time watching all the videos, I used ffmpeg to extract the audio tracks and listened to the courses while driving or being in the gym. Besides the training courses by A Cloud Guru, people also recommend the AWS courses offered by <a href="https://linuxacademy.com/amazon-web-services/courses">Linux Academy</a>.</p>

<p>Another useful prep material for the exam is the Jayendra&rsquo;s <a href="http://jayendrapatil.com/aws-certification-exam-cheat-sheet/">AWS Certification Exam Cheat Sheet</a>. It includes study notes as well as sample questions.</p>

<p>Before taking the real exam, I practiced using mock exams. You can find many of them freely available on the Internet. I also used several mock exam applications for Android:</p>

<ul>
<li><a href="https://play.google.com/store/apps/details?id=com.embleton.awstrainer">AWS Certification Stress-Free: RocketPrep</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.magycbytes.aws">AWS Certified Solutions Architect Associate</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.gent.dev.awsninja">AWS Ninja</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.vikashiiit.aws">FREE AWS Practice Quiz - Associates</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.ywdrtt.awssa">PREP AWS Solutions Architect</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.magycbytes.awssys">Test prep. AWS SysOps Administrator - Associate</a></li>
</ul>


<p>Note that the quality of the available prep materials varies and some of the materials may contain errors.</p>

<p>Finally, after I completed my studying, I took the three associate exams. Here are my results:</p>

<ul>
<li>AWS Certified Solutions Architect - Associate exam passed with 89%</li>
<li>AWS Certified Developer - Associate exam passed with 94%</li>
<li>AWS Certified SysOps Administrator - Associate exam passed with 95%</li>
</ul>


<p>If you are preparing to get your AWS certifications, I hope that sharing my experience might have been helpful for you.</p>

<p><a href="https://www.youracclaim.com/badges/7ca4b13c-e705-4c83-927b-2574b6a3d1c0/public_url"><img src="/images/posts/aws_certified_solutions_architect_associate.png" width="220" height="220"></a>
<a href="https://www.youracclaim.com/badges/678684ce-5ae1-44e0-b40f-b8a48bdd7c06/public_url"><img src="/images/posts/aws_certified_developer_associate.png" width="220" height="220"></a>
<a href="https://www.youracclaim.com/badges/60aaf94d-6b0a-4fa8-9a09-dc8522d61400/public_url"><img src="/images/posts/aws_certified_sysops_administrator_associate.png" width="220" height="220"></a></p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Booting Amazon Linux 2 on OpenStack]]></title>
    <link href="https://alesnosek.com/blog/2018/04/21/booting-amazon-linux-2-on-openstack/"/>
    <updated>2018-04-21T22:21:04-07:00</updated>
    <id>https://alesnosek.com/blog/2018/04/21/booting-amazon-linux-2-on-openstack</id>
    <content type="html"><![CDATA[<p>Amazon Linux 2 runs on OpenStack perfectly fine. There is only one glitch that you should be aware of. Amazon Linux 2 won&rsquo;t accept metadata and user data provided by OpenStack on boot. That means that you won&rsquo;t be able to SSH into the instance after it comes up. In this brief tutorial, we are going to modify the Amazon Linux 2 image to fix this problem.</p>

<!-- more -->


<p>You can download Amazon Linux 2 images from <a href="https://cdn.amazonlinux.com/os-images/latest/.">https://cdn.amazonlinux.com/os-images/latest/.</a> An image suitable for OpenStack is located in the <code>kvm</code> subdirectory. I downloaded the <code>amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2</code> version of the image. By the time you are reading this tutorial, a newer version of the image may be available.</p>

<p>In the rest of this article, I&rsquo;m going to use my machine that is running RHEL7 to modify the Amazon Linux 2 image. First, let&#8217; download the image:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>wget &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://cdn.amazonlinux.com/os-images/2017.12.0.20180330/kvm/amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2&quot;</span>&gt;https://cdn.amazonlinux.com/os-images/2017.12.0.20180330/kvm/amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2&lt;/a&gt;
</span></code></pre></td></tr></table></div></figure></p>

<p>Next, let&rsquo;s install the <code>qemu-img</code> utility useful for manipulating qcow2 images:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo yum install qemu-img
</span></code></pre></td></tr></table></div></figure></p>

<p>Now we can convert the Amazon Linux 2 image from the qcow2 format to the raw format:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>qemu-img convert -f qcow2 -O raw amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2 amzn2-kvm.raw
</span></code></pre></td></tr></table></div></figure></p>

<p>The previous command creates a file <code>amzn2-kvm.raw</code> in the current working directory. This file is a binary image of the virtual machine disk. We can explore it using the <code>fdisk</code> command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>fdisk -l amzn2-kvm.raw
</span><span class='line'>Disk amzn2-kvm.raw: 26.8 GB, <span class="m">26843545600</span> bytes, <span class="m">52428800</span> sectors
</span><span class='line'><span class="nv">Units</span> <span class="o">=</span> sectors of <span class="m">1</span> * <span class="nv">512</span> <span class="o">=</span> <span class="m">512</span> bytes
</span><span class='line'>Sector size <span class="o">(</span>logical/physical<span class="o">)</span>: <span class="m">512</span> bytes / <span class="m">512</span> bytes
</span><span class='line'>I/O size <span class="o">(</span>minimum/optimal<span class="o">)</span>: <span class="m">512</span> bytes / <span class="m">512</span> bytes
</span><span class='line'>Disk label <span class="nb">type</span>: gpt
</span><span class='line'>Disk identifier: 88B4CB3B-A2F1-4C9C-82DC-F18B0F440F56&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h1&gt;Start          End    Size  Type            Name&lt;/h1&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt; <span class="m">1</span>         <span class="m">4096</span>     <span class="m">52428766</span>     25G  Linux filesyste Linux
</span><span class='line'><span class="m">128</span>         <span class="m">2048</span>         <span class="m">4095</span>      1M  BIOS boot       BIOS Boot Partition
</span></code></pre></td></tr></table></div></figure></p>

<p>The output of the <code>fdisk</code> command shows that the disk contains two partitions. The size of the first partition is 25 GB and it holds a Linux filesystem. On the disk, the Linux filesystem starts at the sector number 4096. Given that the size of the sector is 512 bytes, we can tell that the Linux filesystem starts at offset 2097152 (4096 * 512) bytes from the start of the disk image. Knowing the offset of the Linux filesystem, let&rsquo;s loop mount the Linux filesystem under <code>/mnt</code>:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo mount -o loop,offset<span class="o">=</span><span class="m">2097152</span> amzn2-kvm.raw /mnt
</span></code></pre></td></tr></table></div></figure></p>

<p>If everything went well, we can now take a look at the cloud-init configuration of the Amazon Linux 2 image:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo vi /mnt/etc/cloud/cloud.cfg
</span></code></pre></td></tr></table></div></figure></p>

<p>In the cloud-init configuration file, you can find the data source list set as follows:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>datasource_list: <span class="o">[</span> NoCloud, AltCloud, ConfigDrive, OVF, None <span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Sadly, none of the listed data sources is available on OpenStack. OpenStack supports its own data source called <code>OpenStack</code>. Alternatively, OpenStack is compatible with the AWS data source called <code>Ec2</code>. This compatibility ensures that virtual machine images designed for EC2 will work properly on OpenStack. I would expect that the <code>Ec2</code> data source would be included in the data source list of the Amazon Linux 2 image but it is not. Let&rsquo;s add the <code>OpenStack</code> data source to the list:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>datasource_list: <span class="o">[</span> OpenStack, NoCloud, AltCloud, ConfigDrive, OVF, None <span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>I put the <code>OpenStack</code> data source at the beginning of the list. You can choose to add it anywhere else. Just make sure that the <code>None</code> data source remains as the last one on the list. <code>None</code> is a fallback datasource used when no other datasources can be selected and it provides empty metadata and empty user data.</p>

<p>After you saved your changes, you can unmount the Linux filesystem:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo umount /mnt
</span></code></pre></td></tr></table></div></figure></p>

<p>And convert the modified image back to the qcow2 format:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>qemu-img convert -f raw -O qcow2 amzn2-kvm.raw amzn2-kvm.qcow2
</span></code></pre></td></tr></table></div></figure></p>

<p>Now you can upload the modified image into the OpenStack image repository:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openstack image create <span class="p">&amp;</span>ndash<span class="p">;</span>min-disk <span class="m">25</span> <span class="p">&amp;</span>ndash<span class="p">;</span>min-ram <span class="m">512</span> <span class="p">&amp;</span>ndash<span class="p">;</span>container-format bare <span class="p">&amp;</span>ndash<span class="p">;</span>disk-format qcow2 <span class="p">&amp;</span>ndash<span class="p">;</span>file amzn2-kvm.qcow2 amzn2-kvm
</span></code></pre></td></tr></table></div></figure></p>

<p>After the image upload into OpenStack has completed, you can create a test virtual machine off of this image:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openstack server create <span class="p">&amp;</span>ndash<span class="p">;</span>image amzn2-kvm <span class="p">&amp;</span>ndash<span class="p">;</span>flavor m1.medium <span class="p">&amp;</span>ndash<span class="p">;</span>key-name &lt;key-name&gt; <span class="p">&amp;</span>ndash<span class="p">;</span>nic net-id<span class="o">=</span>&lt;net-id&gt; amzn-test
</span></code></pre></td></tr></table></div></figure></p>

<p>Note that in the above command, you&rsquo;ll have to replace the <code>&lt;key-name&gt;</code> and <code>&lt;net-id&gt;</code> placeholders with the name of your key pair and the name of the network you want your instance to be attached to. After the virtual machine has booted up, you should be able to connect to it using SSH. Note that the default user enabled on the Amazon Linux 2 image is <code>ec2-user</code>:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ssh ec2-user@amzn-test
</span><span class='line'>Last login: Sun Apr <span class="m">22</span> 05:08:45 <span class="m">2018</span> from ales.dev.ussd.verimatrix.com&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;   __<span class="p">|</span>  __<span class="p">|</span>_  <span class="o">)</span>
</span><span class='line'>   _<span class="p">|</span>  <span class="o">(</span>     /   Amazon Linux <span class="m">2</span> AMI
</span><span class='line'>  ___<span class="p">|</span><span class="se">\_</span>__<span class="p">|</span>___<span class="p">|</span>
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://aws.amazon.com/amazon-linux-2/&quot;</span>&gt;https://aws.amazon.com/amazon-linux-2/&lt;/a&gt;
</span><span class='line'>No packages needed <span class="k">for</span> security<span class="p">;</span> <span class="m">8</span> packages available
</span><span class='line'>Run <span class="p">&amp;</span>ldquo<span class="p">;</span>sudo yum update<span class="p">&amp;</span>rdquo<span class="p">;</span> to apply all updates.
</span></code></pre></td></tr></table></div></figure></p>

<p>This is the end of the tutorial. You have a working Amazon Linux 2 image on OpenStack, congratulations! If you have any comments or questions, let me know in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[18 Months with OpenStack, Our Experience, Part II]]></title>
    <link href="https://alesnosek.com/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii/"/>
    <updated>2018-03-08T20:51:11-08:00</updated>
    <id>https://alesnosek.com/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii</id>
    <content type="html"><![CDATA[<p>In the <a href="/blog/2018/02/19/18-months-with-openstack-our-experience-part-i/">previous post</a>, we discussed our experience with the deployment of OpenStack. In this article, we&rsquo;re going to share the lessons learned when operating it. It took effort to tame the OpenStack beast and make it work reliably. If you want to know how we accomplished that, read on.</p>

<!-- more -->


<h2>Monitoring OpenStack using Icinga</h2>

<p>As the old sysadmin saying goes:</p>

<blockquote><p>If you don&rsquo;t monitor it, it&rsquo;s not in production.</p></blockquote>

<p>When looking for a tool to monitor OpenStack, we came across the <a href="https://wiki.openstack.org/wiki/Monasca">Monasca</a> project. Monasca is a monitoring-as-a-service solution built exclusively for OpenStack. The idea of deploying a system which was from the ground up designed for OpenStack was very appealing. However, after taking a closer look at Monasca we steered away from it. Firstly, Monasca was built around Big Data technologies like <a href="https://kafka.apache.org">Apache Kafka</a> and <a href="http://storm.apache.org/">Apache Storm</a> which are a great fit for large-scale deployments. For our rather low-scale use case they seemed to be a bit too heavy. Secondly, around Kilo release it was difficult to predict how much adoption Monasca would find in the community. Instead of Monasca, we eventually decided to go with <a href="https://www.icinga.com/">Icinga</a> which is a derivate of Nagios, a de facto industry standard between monitoring solutions. I wrote about the monitoring of OpenStack using Icinga in one of my previous <a href="/blog/2015/11/30/monitoring-openstack-cluster-with-icinga/">posts</a>. Setting up Icinga to monitor OpenStack meant to search for Nagios plugins to check various parts of the OpenStack cluster. In addition to the standard set of plugins that comes with the Nagios distribution, we ended up using many plugins that we found on the Internet:</p>

<ul>
<li><a href="https://github.com/justintime/nagios-plugins">check_mem</a> Monitor Linux system memory usage.</li>
<li><a href="https://github.com/mclarkson/check_diskstat">check_diskstat</a> Linux disk I/O checks, tps, read, write, avg. request size, avg. queue size and avg. wait time.</li>
<li><a href="https://github.com/nguttman/Nagios-Checks/tree/master/Unix/Check_Process">check_process</a> UNIX process monitoring.</li>
<li><a href="https://github.com/jonschipp/nagios-plugins/blob/master/check_service.sh">check_service</a> Monitors services managed by systemd.</li>
<li><a href="https://github.com/Crapworks/check_ceph_dash">check-ceph-dash</a> Monitors overall Ceph cluster status. Requires <a href="https://github.com/Crapworks/ceph-dash">ceph-dash</a> to be installed.</li>
<li><a href="https://github.com/noseka1/check_haproxy">check_haproxy</a> Monitors the health of HAProxy backends.</li>
<li><a href="https://github.com/polymorf/check_haproxy">haproxy_http_stats</a> Turns the HAProxy statistics into Nagios performance data.</li>
<li><a href="https://github.com/noseka1/nagios-plugin-check_galera_cluster">nagios-plugin-check_galera_cluster</a> Checks the status of a Galera cluster.</li>
<li><a href="https://github.com/alaskacommunications/nagios_check_keepalived">check_keepalived_vrrp</a> Monitors Keepalived VRRP subsystem.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_memcached.pl">check_memcached</a> Checks Memcached statistics.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_redis.pl">check_redis</a> Checks Redis status variables.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_uptime.pl">check_uptime</a> Tracks system uptime. Great to detect power outages.</li>
<li><a href="https://github.com/mzupan/nagios-plugin-mongodb">check_mongodb</a> Monitor MongoDB servers.</li>
<li><a href="https://github.com/noseka1/monitoring-for-openstack">monitoring-for-openstack</a> Monitor various OpenStack services (Nova, Cinder, Glance, Neutron &hellip;)</li>
<li><a href="https://github.com/noseka1/openstack-nagios-plugins">openstack-nagios-plugins</a> Yet another set of Nagios plugins to monitor OpenStack services.</li>
<li><a href="https://labs.consol.de/nagios/check_mysql_health/index.html">check_mysql_health</a> Monitor health and performance of a MySQL database.</li>
<li><a href="https://github.com/nagios-plugins-rabbitmq/nagios-plugins-rabbitmq">nagios-plugins-rabbitmq</a> Set of nagios checks useful for monitoring a RabbitMQ cluster.</li>
</ul>


<p>Besides monitoring the availability of OpenStack services, monitoring the performance of hypervisor hosts was another important point to ensure smooth operations and user happiness. You&rsquo;ve heard about the &ldquo;noisy neighbor&rdquo; problem before, haven&rsquo;t you? Time to time it happened to us that users unknowingly started a workload that would hog the CPU, disk or network I/O of the hypervisor to the extent that other virtual machines running on the same hypervisor were slowed down. In such a situation it was important that Icinga would alert the OpenStack operator that would resolve the problem before the affected users would notice.</p>

<h2>Ceilometer metrics and events</h2>

<p><a href="https://docs.openstack.org/ceilometer">Ceilometer</a> is an OpenStack data collection service that collects telemetry data across all OpenStack components. This telemetry data provides useful insights into the OpenStack operation and I would strongly recommend to you to deploy Ceilometer and configure it to store the telemetry data in the backend of your choice. The data provided by the Ceilometer service can be divided into two categories: measurements and events.</p>

<h3>Ceilometer measurements</h3>

<p><a href="https://docs.openstack.org/ceilometer/pike/admin/telemetry-measurements.html">Ceilometer measurements</a> are performance data. Ceilometer collects performance samples by polling the OpenStack infrastructure elements in regular intervals. For instance, Ceilometer measures CPU, memory, disk and network usage of individual virtual machines hosted on OpenStack, it can measure the performance of hypervisor hosts and much more. It&rsquo;s up to you to choose which data interests you. We ended up collecting merely the performance data of individual virtual machines. Monitoring of hypervisor hosts was better left to Icinga.</p>

<p>There are many options of how to process the performance data generated by Ceilometer. We configured Ceilometer to send the performance samples in the <a href="https://msgpack.org">MessagePack</a> format over UDP protocol to <a href="https://www.elastic.co/products/logstash">Logstash</a>. Logstash in turn forwards the data to the <a href="https://www.influxdata.com/">InfluxDB</a> storage. <a href="https://grafana.com/">Grafana</a> is used to view and graph the performance data stored in InfluxDB. We spent quite a bit of time configuring Logstash to enrich the data coming from Ceilometer to be able to create a beautiful Grafana dashboard that would display the performance graphs of individual virtual machines hosted on OpenStack. Our OpenStack users would be able to look up their virtual machine in the Grafana dashboard based on the OpenStack project and the display name of the instance. After investing all the effort to create the dashboard the practice showed that nobody really cared about the performance monitoring of most of the virtual machines. And if we deployed a virtual machine we wanted to monitor, we preferred to just install the Icinga monitoring agent on it.</p>

<h3>Ceilometer events</h3>

<p><a href="https://docs.openstack.org/ceilometer/pike/admin/telemetry-events.html">Ceilometer events</a> represent any action made in the OpenStack system, for example: successful user authentication, creating a virtual machine, terminating a virtual machine, creating a volume, attaching a volume to a virtual machine and many others. Ceilometer generates events based on the notifications that are published by the OpenStack services on the message bus. For instance, the list of notifications published by the Nova components can be found <a href="https://docs.openstack.org/nova/latest/reference/notifications.html">here</a>. In the past, I wrote an <a href="/blog/2015/05/25/openstack-nova-notifications-subscriber/">article</a> describing how to subscribe to the Nova notifications on the RabbitMQ message bus.</p>

<p>In our OpenStack deployment, we configured Ceilometer to send events to <a href="https://www.elastic.co/">Elasticsearch</a>. <a href="https://www.elastic.co/products/kibana">Kibana</a> is used to view and search for the collected events. Having all the OpenStack events collected and archived at one place turned out to be really helpful. One day, a co-worker of mine brought up a complaint that somebody deleted his virtual machine. Deleting virtual machines of other people, who would dare that? Instead of asking around and disturbing people on the team, we were able to look up all the events pertaining to the lost virtual machine. We found out that the termination event ran on behalf of the Jenkins user. It didn&rsquo;t take much longer to identify the Jenkins job which deleted the virtual machine. Finally, it turned out that the co-worker that complained about the loss of &ldquo;his&rdquo; virtual machine was actually handed over the virtual machine only temporarily and that the machine was deleted and recreated every night by Jenkins. And I told to myself, what an <em>automated</em> world!</p>

<h2>Log collection using ELK</h2>

<p>In addition to storing Ceilometer events in Elasticsearch, we also configured <a href="https://www.elastic.co/products/beats/filebeat">Filebeat</a> to collect OpenStack logs and Linux system logs from all the OpenStack nodes and store them in Elasticsearch. They will come handy in the future when explaining other &ldquo;mysteries&rdquo; happening in our OpenStack cluster.</p>

<h2>Tempest and Rally</h2>

<p>When you deploy an OpenStack cluster, how do you verify that your cluster functions correctly? Icinga checks cover a very small subset of the OpenStack functionality. To accomplish a thorough verification of the OpenStack cluster, we started using the <a href="https://docs.openstack.org/tempest/latest/">Tempest</a> project. Tempest is a battery of integration tests that are used to verify OpenStack&rsquo;s functionality and it is a part of the continuous integration pipeline of the OpenStack project. Tempest tests send requests to the OpenStack APIs and verify the responses. As the goal of the Tempest project is to verify the integration of OpenStack components during development,  the included integration tests were a bit too low-level for our use case of merely verifying that the OpenStack cluster functioned properly. However, there were no better tools available at the time and it did the trick for us.</p>

<p>After a while of using Tempest, we discovered yet another project called <a href="https://docs.openstack.org/developer/rally/">Rally</a>. Rally is a benchmarking tool that is used to measure OpenStack&rsquo;s performance and to identify performance bottlenecks. Rally builds on top of Tempest and it comes with a set of predefined scenarios that are executed against the OpenStack cluster. Example scenarios are: boot and delete server, boot server from volume, create a subnet, create and attach volume, create and delete a Heat stack, and many more. The available scenarios were just right to verify our cloud! On top of that, Rally generates beautiful reports with the overview of executed tasks and their duration. We ended up creating a cron job that schedules the Rally tests to run every two hours. The test results are monitored using Icinga which in the case of test failure sends an alert to the operator.</p>

<p>Because our OpenStack cluster was constantly exercised by the Rally tests, we were able to quickly spot resources that OpenStack didn&rsquo;t clean up properly and that were piling up. We have seen diverse OpenStack database tables growing infinitely.  We have experienced Neutron leaving processes running on the controller nodes, leaving empty network namespaces behind or filling up the <code>/var/log/neutron</code> directory with files. Remember that we experienced these issues while using the Mitaka release of OpenStack. I&rsquo;m sure that things improved since then. To address the resource leaks, we wrote custom clean-up scripts. I&rsquo;m publishing them for you to use at your own risk. You can find them on <a href="https://github.com/noseka1/openstack-periodic-cleanup">GitHub</a>.</p>

<h2>Tracking cloud resource usage</h2>

<p>In OpenStack, we were missing some kind of reporting on resource usage. In our organization, each development team has its dedicated project in OpenStack. It is important to us to understand, how much of the cloud resources each team is consuming, i.e. how many CPU cores, memory, and volumes. In addition to per project usage, we also monitor the total resource usage across the entire cluster. In the case, that the total usage is reaching the total capacity available we can organize additional hardware ahead of time.</p>

<p>Around OpenStack Mitaka release, we didn&rsquo;t find any tool that would generate the usage reports. However, OpenStack&rsquo;s MariaDB database contains all the input data required to create such reports. It was rather straightforward to create a set of SQL scripts to generate the reports directly out of the OpenStack&rsquo;s database. We run these scripts periodically using Icinga, so that we can see the report output on our monitoring dashboard. If you are interested, you can find our OpenStack usage report scripts on <a href="https://github.com/noseka1/openstack-cloud-report">GitHub</a>.</p>

<h2>Further notes</h2>

<p>I&rsquo;d like to describe several further observations that we made while operating OpenStack. Once again, our experience pertains to the Mitaka release of OpenStack only. Many of the issues we stumbled upon might have been resolved in the newer releases of OpenStack.</p>

<ul>
<li>In order to get OpenStack working smoothly, you should expect to use some amount of duct tape and bubble gum. As OpenStack was implemented in Python, patching OpenStack is relatively easy. Many times I was able to find fixes for our issues on the project development branches and needed just to port them to our OpenStack version.</li>
<li>OpenStack is deployed on many nodes. It was useful for us to write Ansible scripts to automate the restart of the RabbitMQ cluster and to automate the restart of all OpenStack services on all nodes (aka restart the world). Due to the issues with the OpenStack TripleO installer in the Mitaka release, we are still forced to restart the world after adding a compute node.</li>
<li>Switching to Keystone Fernet tokens considerably reduced the load on the MariaDB database. We enabled Fernet tokens even in the Mitaka release of OpenStack.</li>
<li>RabbitMQ, Cinder Backup and several other services require higher amount of open file descriptors. For instance, RabbitMQ <a href="https://www.rabbitmq.com/production-checklist.html">recommends</a> to allow at least 50K of open file descriptors. Insufficient amount of file descriptors caused our RabbitMQ to crash. As RabbitMQ is the communication backbone of OpenStack, you can imagine how much fun it caused.</li>
<li>Our OpenStack networking is set up to use Neutron&rsquo;s OpenVSwitch driver and VLANs. In the default configuration, it happened to us that the multicast traffic sent by a single virtual machine flooded the entire network and caused OpenVSwitch to begin dropping packets. We didn&rsquo;t do any further research on the multicast on OpenStack topic so far, just avoided sending multicast altogether.</li>
<li>Kudos goes to the <a href="https://ceph.com/">Ceph</a> storage. We are running the old Ceph v0.94 Hammer which was able to survive emergency situations like lost storage node and running out of space condition without any problems.</li>
</ul>


<h2>Conclusion</h2>

<p>In this blog post, we shared some of our experiences with operating OpenStack. We described the monitoring using Icinga, collecting Ceilometer metrics and events, collecting system logs using the ELK stack, verifying the OpenStack functionality with Rally and generating cloud resource usage reports.</p>

<p>OpenStack is not the easiest software to run, however, if you do your homework you will succeed. At the present time, OpenStack just works for us and brings a lot of value to the teams in our company.</p>

<p>If you&rsquo;d like to share your experience with operating OpenStack, I would love to hear from you. Please, feel free to use the comment section below.</p>
]]></content>
  </entry>

</feed>
