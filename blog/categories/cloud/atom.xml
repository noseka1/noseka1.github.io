<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cloud | Ales Nosek - The Software Practitioner]]></title>
  <link href="http://alesnosek.com/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="http://alesnosek.com/"/>
  <updated>2019-04-21T19:24:24-07:00</updated>
  <id>http://alesnosek.com/</id>
  <author>
    <name><![CDATA[Ales Nosek]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How I Achieved the AWS Associate Certifications]]></title>
    <link href="http://alesnosek.com/blog/2018/08/30/how-i-achieved-the-aws-associate-certifications/"/>
    <updated>2018-08-30T23:20:27-07:00</updated>
    <id>http://alesnosek.com/blog/2018/08/30/how-i-achieved-the-aws-associate-certifications</id>
    <content type="html"><![CDATA[<p>Over the course of the last year I was working towards transitioning our companyâ€™s products to the AWS cloud. I gained a solid experience with many of the AWS services, wrote lots of lines of CloudFormation code, and embraced AWS reference architectures and best practices. To round up my AWS experience I thought that accomplishing some certifications would be a good idea. In this post, I am going to share with you how I achieved the AWS associate certifications.</p>

<!-- more -->


<p><a href="https://aws.amazon.com/certification/">AWS certifications</a> are divided into three levels of difficulty: foundational, associate, and professional. The foundational level is optional. If you worked with AWS cloud hands-on for several months, I would recommend skipping the foundational level and start your certification path at the associate level. The associate level comes with three certification options: Solutions Architect, Developer, and SysOps Administrator. In order to achieve a specific certification, you have to pass the respective multiple-choice test. As the requirements for the three tests highly overlap, I decided to study for all three certifications at the same time.</p>

<p>AWS certification is rather popular these days. It&rsquo;s no wonder that there is an abundance of preparation materials available. So, which one should you choose? I started off by reading the three official study guides:</p>

<ul>
<li><a href="https://www.amazon.com/Certified-Solutions-Architect-Official-Study/dp/1119138558">AWS Certified Solutions Architect Official Study Guide: Associate Exam</a></li>
<li><a href="https://www.amazon.com/Certified-SysOps-Administrator-Official-Study/dp/1119377420">AWS Certified SysOps Administrator Official Study Guide: Associate Exam</a></li>
<li><a href="https://www.amazon.com/Certified-Advanced-Networking-Official-Study-ebook/dp/B079VKD1CN">AWS Certified Advanced Networking Official Study Guide: Specialty Exam</a></li>
</ul>


<p>The three study guides are well organized and go beyond the associate exam requirements. I would recommend reading them even when you don&rsquo;t plan to get certified as they provide a good source of information about AWS in general.</p>

<p>In addition to reading the books, I made use of the AWS training courses offered by <a href="https://acloud.guru/courses?vendors=aws">A Cloud Guru</a>. I watched most of the videos from the Solutions Architect course and some of the videos from the SysOps Administrator course. I enjoyed the presentation style of Ryan Kroonenburg a lot and appreciated the practical demonstrations on AWS and the included exam tips. As I didn&rsquo;t really want to spend the time watching all the videos, I used ffmpeg to extract the audio tracks and listened to the courses while driving or being in the gym. Besides the training courses by A Cloud Guru, people also recommend the AWS courses offered by <a href="https://linuxacademy.com/amazon-web-services/courses">Linux Academy</a>.</p>

<p>Another useful prep material for the exam is the Jayendra&rsquo;s <a href="http://jayendrapatil.com/aws-certification-exam-cheat-sheet/">AWS Certification Exam Cheat Sheet</a>. It includes study notes as well as sample questions.</p>

<p>Before taking the real exam, I practiced using mock exams. You can find many of them freely available on the Internet. I also used several mock exam applications for Android:</p>

<ul>
<li><a href="https://play.google.com/store/apps/details?id=com.embleton.awstrainer">AWS Certification Stress-Free: RocketPrep</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.magycbytes.aws">AWS Certified Solutions Architect Associate</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.gent.dev.awsninja">AWS Ninja</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.vikashiiit.aws">FREE AWS Practice Quiz - Associates</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.ywdrtt.awssa">PREP AWS Solutions Architect</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.magycbytes.awssys">Test prep. AWS SysOps Administrator - Associate</a></li>
</ul>


<p>Note that the quality of the available prep materials varies and some of the materials may contain errors.</p>

<p>Finally, after I completed my studying, I took the three associate exams. Here are my results:</p>

<ul>
<li>AWS Certified Solutions Architect - Associate exam passed with 89%</li>
<li>AWS Certified Developer - Associate exam passed with 94%</li>
<li>AWS Certified SysOps Administrator - Associate exam passed with 95%</li>
</ul>


<p>If you are preparing to get your AWS certifications, I hope that sharing my experience might have been helpful for you.</p>

<p><a href="https://www.certmetrics.com/amazon/public/badge.aspx?i=1&amp;t=c&amp;d=2018-08-08&amp;ci=AWS00414888"><img src="/images/posts/aws_certified_solutions_architect_associate.png"></a>
<a href="https://www.certmetrics.com/amazon/public/badge.aspx?i=2&amp;t=c&amp;d=2018-08-13&amp;ci=AWS00414888"><img src="/images/posts/aws_certified_developer_associate.png"></a>
<a href="https://www.certmetrics.com/amazon/public/badge.aspx?i=3&amp;t=c&amp;d=2018-08-28&amp;ci=AWS00414888"><img src="/images/posts/aws_certified_sysops_administrator_associate.png"></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Booting Amazon Linux 2 on OpenStack]]></title>
    <link href="http://alesnosek.com/blog/2018/04/21/booting-amazon-linux-2-on-openstack/"/>
    <updated>2018-04-21T22:21:04-07:00</updated>
    <id>http://alesnosek.com/blog/2018/04/21/booting-amazon-linux-2-on-openstack</id>
    <content type="html"><![CDATA[<p>Amazon Linux 2 runs on OpenStack perfectly fine. There is only one glitch that you should be aware of. Amazon Linux 2 won&rsquo;t accept metadata and user data provided by OpenStack on boot. That means that you won&rsquo;t be able to SSH into the instance after it comes up. In this brief tutorial, we are going to modify the Amazon Linux 2 image to fix this problem.</p>

<!-- more -->


<p>You can download Amazon Linux 2 images from <a href="https://cdn.amazonlinux.com/os-images/latest/.">https://cdn.amazonlinux.com/os-images/latest/.</a> An image suitable for OpenStack is located in the <code>kvm</code> subdirectory. I downloaded the <code>amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2</code> version of the image. By the time you are reading this tutorial, a newer version of the image may be available.</p>

<p>In the rest of this article, I&rsquo;m going to use my machine that is running RHEL7 to modify the Amazon Linux 2 image. First, let&#8217; download the image:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>wget &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://cdn.amazonlinux.com/os-images/2017.12.0.20180330/kvm/amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2&quot;</span>&gt;https://cdn.amazonlinux.com/os-images/2017.12.0.20180330/kvm/amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2&lt;/a&gt;
</span></code></pre></td></tr></table></div></figure></p>

<p>Next, let&rsquo;s install the <code>qemu-img</code> utility useful for manipulating qcow2 images:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo yum install qemu-img
</span></code></pre></td></tr></table></div></figure></p>

<p>Now we can convert the Amazon Linux 2 image from the qcow2 format to the raw format:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>qemu-img convert -f qcow2 -O raw amzn2-kvm-2017.12.0.20180330-x86_64.xfs.gpt.qcow2 amzn2-kvm.raw
</span></code></pre></td></tr></table></div></figure></p>

<p>The previous command creates a file <code>amzn2-kvm.raw</code> in the current working directory. This file is a binary image of the virtual machine disk. We can explore it using the <code>fdisk</code> command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>fdisk -l amzn2-kvm.raw
</span><span class='line'>Disk amzn2-kvm.raw: 26.8 GB, <span class="m">26843545600</span> bytes, <span class="m">52428800</span> sectors
</span><span class='line'><span class="nv">Units</span> <span class="o">=</span> sectors of <span class="m">1</span> * <span class="nv">512</span> <span class="o">=</span> <span class="m">512</span> bytes
</span><span class='line'>Sector size <span class="o">(</span>logical/physical<span class="o">)</span>: <span class="m">512</span> bytes / <span class="m">512</span> bytes
</span><span class='line'>I/O size <span class="o">(</span>minimum/optimal<span class="o">)</span>: <span class="m">512</span> bytes / <span class="m">512</span> bytes
</span><span class='line'>Disk label <span class="nb">type</span>: gpt
</span><span class='line'>Disk identifier: 88B4CB3B-A2F1-4C9C-82DC-F18B0F440F56&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h1&gt;Start          End    Size  Type            Name&lt;/h1&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt; <span class="m">1</span>         <span class="m">4096</span>     <span class="m">52428766</span>     25G  Linux filesyste Linux
</span><span class='line'><span class="m">128</span>         <span class="m">2048</span>         <span class="m">4095</span>      1M  BIOS boot       BIOS Boot Partition
</span></code></pre></td></tr></table></div></figure></p>

<p>The output of the <code>fdisk</code> command shows that the disk contains two partitions. The size of the first partition is 25 GB and it holds a Linux filesystem. On the disk, the Linux filesystem starts at the sector number 4096. Given that the size of the sector is 512 bytes, we can tell that the Linux filesystem starts at offset 2097152 (4096 * 512) bytes from the start of the disk image. Knowing the offset of the Linux filesystem, let&rsquo;s loop mount the Linux filesystem under <code>/mnt</code>:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo mount -o loop,offset<span class="o">=</span><span class="m">2097152</span> amzn2-kvm.raw /mnt
</span></code></pre></td></tr></table></div></figure></p>

<p>If everything went well, we can now take a look at the cloud-init configuration of the Amazon Linux 2 image:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo vi /mnt/etc/cloud/cloud.cfg
</span></code></pre></td></tr></table></div></figure></p>

<p>In the cloud-init configuration file, you can find the data source list set as follows:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>datasource_list: <span class="o">[</span> NoCloud, AltCloud, ConfigDrive, OVF, None <span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Sadly, none of the listed data sources is available on OpenStack. OpenStack supports its own data source called <code>OpenStack</code>. Alternatively, OpenStack is compatible with the AWS data source called <code>Ec2</code>. This compatibility ensures that virtual machine images designed for EC2 will work properly on OpenStack. I would expect that the <code>Ec2</code> data source would be included in the data source list of the Amazon Linux 2 image but it is not. Let&rsquo;s add the <code>OpenStack</code> data source to the list:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>datasource_list: <span class="o">[</span> OpenStack, NoCloud, AltCloud, ConfigDrive, OVF, None <span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>I put the <code>OpenStack</code> data source at the beginning of the list. You can choose to add it anywhere else. Just make sure that the <code>None</code> data source remains as the last one on the list. <code>None</code> is a fallback datasource used when no other datasources can be selected and it provides empty metadata and empty user data.</p>

<p>After you saved your changes, you can unmount the Linux filesystem:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>sudo umount /mnt
</span></code></pre></td></tr></table></div></figure></p>

<p>And convert the modified image back to the qcow2 format:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>qemu-img convert -f raw -O qcow2 amzn2-kvm.raw amzn2-kvm.qcow2
</span></code></pre></td></tr></table></div></figure></p>

<p>Now you can upload the modified image into the OpenStack image repository:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openstack image create <span class="p">&amp;</span>ndash<span class="p">;</span>min-disk <span class="m">25</span> <span class="p">&amp;</span>ndash<span class="p">;</span>min-ram <span class="m">512</span> <span class="p">&amp;</span>ndash<span class="p">;</span>container-format bare <span class="p">&amp;</span>ndash<span class="p">;</span>disk-format qcow2 <span class="p">&amp;</span>ndash<span class="p">;</span>file amzn2-kvm.qcow2 amzn2-kvm
</span></code></pre></td></tr></table></div></figure></p>

<p>After the image upload into OpenStack has completed, you can create a test virtual machine off of this image:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openstack server create <span class="p">&amp;</span>ndash<span class="p">;</span>image amzn2-kvm <span class="p">&amp;</span>ndash<span class="p">;</span>flavor m1.medium <span class="p">&amp;</span>ndash<span class="p">;</span>key-name &lt;key-name&gt; <span class="p">&amp;</span>ndash<span class="p">;</span>nic net-id<span class="o">=</span>&lt;net-id&gt; amzn-test
</span></code></pre></td></tr></table></div></figure></p>

<p>Note that in the above command, you&rsquo;ll have to replace the <code>&lt;key-name&gt;</code> and <code>&lt;net-id&gt;</code> placeholders with the name of your key pair and the name of the network you want your instance to be attached to. After the virtual machine has booted up, you should be able to connect to it using SSH. Note that the default user enabled on the Amazon Linux 2 image is <code>ec2-user</code>:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ssh ec2-user@amzn-test
</span><span class='line'>Last login: Sun Apr <span class="m">22</span> 05:08:45 <span class="m">2018</span> from ales.dev.ussd.verimatrix.com&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;   __<span class="p">|</span>  __<span class="p">|</span>_  <span class="o">)</span>
</span><span class='line'>   _<span class="p">|</span>  <span class="o">(</span>     /   Amazon Linux <span class="m">2</span> AMI
</span><span class='line'>  ___<span class="p">|</span><span class="se">\_</span>__<span class="p">|</span>___<span class="p">|</span>
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://aws.amazon.com/amazon-linux-2/&quot;</span>&gt;https://aws.amazon.com/amazon-linux-2/&lt;/a&gt;
</span><span class='line'>No packages needed <span class="k">for</span> security<span class="p">;</span> <span class="m">8</span> packages available
</span><span class='line'>Run <span class="p">&amp;</span>ldquo<span class="p">;</span>sudo yum update<span class="p">&amp;</span>rdquo<span class="p">;</span> to apply all updates.
</span></code></pre></td></tr></table></div></figure></p>

<p>This is the end of the tutorial. You have a working Amazon Linux 2 image on OpenStack, congratulations! If you have any comments or questions, let me know in the comment section below.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[18 Months with OpenStack, Our Experience, Part II]]></title>
    <link href="http://alesnosek.com/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii/"/>
    <updated>2018-03-08T20:51:11-08:00</updated>
    <id>http://alesnosek.com/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii</id>
    <content type="html"><![CDATA[<p>In the <a href="/blog/2018/02/19/18-months-with-openstack-our-experience-part-i/">previous post</a>, we discussed our experience with the deployment of OpenStack. In this article, we&rsquo;re going to share the lessons learned when operating it. It took effort to tame the OpenStack beast and make it work reliably. If you want to know how we accomplished that, read on.</p>

<!-- more -->


<h2>Monitoring OpenStack using Icinga</h2>

<p>As the old sysadmin saying goes:</p>

<blockquote><p>If you don&rsquo;t monitor it, it&rsquo;s not in production.</p></blockquote>

<p>When looking for a tool to monitor OpenStack, we came across the <a href="https://wiki.openstack.org/wiki/Monasca">Monasca</a> project. Monasca is a monitoring-as-a-service solution built exclusively for OpenStack. The idea of deploying a system which was from the ground up designed for OpenStack was very appealing. However, after taking a closer look at Monasca we steered away from it. Firstly, Monasca was built around Big Data technologies like <a href="https://kafka.apache.org">Apache Kafka</a> and <a href="http://storm.apache.org/">Apache Storm</a> which are a great fit for large-scale deployments. For our rather low-scale use case they seemed to be a bit too heavy. Secondly, around Kilo release it was difficult to predict how much adoption Monasca would find in the community. Instead of Monasca, we eventually decided to go with <a href="https://www.icinga.com/">Icinga</a> which is a derivate of Nagios, a de facto industry standard between monitoring solutions. I wrote about the monitoring of OpenStack using Icinga in one of my previous <a href="/blog/2015/11/30/monitoring-openstack-cluster-with-icinga/">posts</a>. Setting up Icinga to monitor OpenStack meant to search for Nagios plugins to check various parts of the OpenStack cluster. In addition to the standard set of plugins that comes with the Nagios distribution, we ended up using many plugins that we found on the Internet:</p>

<ul>
<li><a href="https://github.com/justintime/nagios-plugins">check_mem</a> Monitor Linux system memory usage.</li>
<li><a href="https://github.com/mclarkson/check_diskstat">check_diskstat</a> Linux disk I/O checks, tps, read, write, avg. request size, avg. queue size and avg. wait time.</li>
<li><a href="https://github.com/nguttman/Nagios-Checks/tree/master/Unix/Check_Process">check_process</a> UNIX process monitoring.</li>
<li><a href="https://github.com/jonschipp/nagios-plugins/blob/master/check_service.sh">check_service</a> Monitors services managed by systemd.</li>
<li><a href="https://github.com/Crapworks/check_ceph_dash">check-ceph-dash</a> Monitors overall Ceph cluster status. Requires <a href="https://github.com/Crapworks/ceph-dash">ceph-dash</a> to be installed.</li>
<li><a href="https://github.com/noseka1/check_haproxy">check_haproxy</a> Monitors the health of HAProxy backends.</li>
<li><a href="https://github.com/polymorf/check_haproxy">haproxy_http_stats</a> Turns the HAProxy statistics into Nagios performance data.</li>
<li><a href="https://github.com/noseka1/nagios-plugin-check_galera_cluster">nagios-plugin-check_galera_cluster</a> Checks the status of a Galera cluster.</li>
<li><a href="https://github.com/alaskacommunications/nagios_check_keepalived">check_keepalived_vrrp</a> Monitors Keepalived VRRP subsystem.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_memcached.pl">check_memcached</a> Checks Memcached statistics.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_redis.pl">check_redis</a> Checks Redis status variables.</li>
<li><a href="https://github.com/willixix/WL-NagiosPlugins/blob/master/check_uptime.pl">check_uptime</a> Tracks system uptime. Great to detect power outages.</li>
<li><a href="https://github.com/mzupan/nagios-plugin-mongodb">check_mongodb</a> Monitor MongoDB servers.</li>
<li><a href="https://github.com/noseka1/monitoring-for-openstack">monitoring-for-openstack</a> Monitor various OpenStack services (Nova, Cinder, Glance, Neutron &hellip;)</li>
<li><a href="https://github.com/noseka1/openstack-nagios-plugins">openstack-nagios-plugins</a> Yet another set of Nagios plugins to monitor OpenStack services.</li>
<li><a href="https://labs.consol.de/nagios/check_mysql_health/index.html">check_mysql_health</a> Monitor health and performance of a MySQL database.</li>
<li><a href="https://github.com/nagios-plugins-rabbitmq/nagios-plugins-rabbitmq">nagios-plugins-rabbitmq</a> Set of nagios checks useful for monitoring a RabbitMQ cluster.</li>
</ul>


<p>Besides monitoring the availability of OpenStack services, monitoring the performance of hypervisor hosts was another important point to ensure smooth operations and user happiness. You&rsquo;ve heard about the &ldquo;noisy neighbor&rdquo; problem before, haven&rsquo;t you? Time to time it happened to us that users unknowingly started a workload that would hog the CPU, disk or network I/O of the hypervisor to the extent that other virtual machines running on the same hypervisor were slowed down. In such a situation it was important that Icinga would alert the OpenStack operator that would resolve the problem before the affected users would notice.</p>

<h2>Ceilometer metrics and events</h2>

<p><a href="https://docs.openstack.org/ceilometer">Ceilometer</a> is an OpenStack data collection service that collects telemetry data across all OpenStack components. This telemetry data provides useful insights into the OpenStack operation and I would strongly recommend to you to deploy Ceilometer and configure it to store the telemetry data in the backend of your choice. The data provided by the Ceilometer service can be divided into two categories: measurements and events.</p>

<h3>Ceilometer measurements</h3>

<p><a href="https://docs.openstack.org/ceilometer/pike/admin/telemetry-measurements.html">Ceilometer measurements</a> are performance data. Ceilometer collects performance samples by polling the OpenStack infrastructure elements in regular intervals. For instance, Ceilometer measures CPU, memory, disk and network usage of individual virtual machines hosted on OpenStack, it can measure the performance of hypervisor hosts and much more. It&rsquo;s up to you to choose which data interests you. We ended up collecting merely the performance data of individual virtual machines. Monitoring of hypervisor hosts was better left to Icinga.</p>

<p>There are many options of how to process the performance data generated by Ceilometer. We configured Ceilometer to send the performance samples in the <a href="https://msgpack.org">MessagePack</a> format over UDP protocol to <a href="https://www.elastic.co/products/logstash">Logstash</a>. Logstash in turn forwards the data to the <a href="https://www.influxdata.com/">InfluxDB</a> storage. <a href="https://grafana.com/">Grafana</a> is used to view and graph the performance data stored in InfluxDB. We spent quite a bit of time configuring Logstash to enrich the data coming from Ceilometer to be able to create a beautiful Grafana dashboard that would display the performance graphs of individual virtual machines hosted on OpenStack. Our OpenStack users would be able to look up their virtual machine in the Grafana dashboard based on the OpenStack project and the display name of the instance. After investing all the effort to create the dashboard the practice showed that nobody really cared about the performance monitoring of most of the virtual machines. And if we deployed a virtual machine we wanted to monitor, we preferred to just install the Icinga monitoring agent on it.</p>

<h3>Ceilometer events</h3>

<p><a href="https://docs.openstack.org/ceilometer/pike/admin/telemetry-events.html">Ceilometer events</a> represent any action made in the OpenStack system, for example: successful user authentication, creating a virtual machine, terminating a virtual machine, creating a volume, attaching a volume to a virtual machine and many others. Ceilometer generates events based on the notifications that are published by the OpenStack services on the message bus. For instance, the list of notifications published by the Nova components can be found <a href="https://docs.openstack.org/nova/latest/reference/notifications.html">here</a>. In the past, I wrote an <a href="/blog/2015/05/25/openstack-nova-notifications-subscriber/">article</a> describing how to subscribe to the Nova notifications on the RabbitMQ message bus.</p>

<p>In our OpenStack deployment, we configured Ceilometer to send events to <a href="https://www.elastic.co/">Elasticsearch</a>. <a href="https://www.elastic.co/products/kibana">Kibana</a> is used to view and search for the collected events. Having all the OpenStack events collected and archived at one place turned out to be really helpful. One day, a co-worker of mine brought up a complaint that somebody deleted his virtual machine. Deleting virtual machines of other people, who would dare that? Instead of asking around and disturbing people on the team, we were able to look up all the events pertaining to the lost virtual machine. We found out that the termination event ran on behalf of the Jenkins user. It didn&rsquo;t take much longer to identify the Jenkins job which deleted the virtual machine. Finally, it turned out that the co-worker that complained about the loss of &ldquo;his&rdquo; virtual machine was actually handed over the virtual machine only temporarily and that the machine was deleted and recreated every night by Jenkins. And I told to myself, what an <em>automated</em> world!</p>

<h2>Log collection using ELK</h2>

<p>In addition to storing Ceilometer events in Elasticsearch, we also configured <a href="https://www.elastic.co/products/beats/filebeat">Filebeat</a> to collect OpenStack logs and Linux system logs from all the OpenStack nodes and store them in Elasticsearch. They will come handy in the future when explaining other &ldquo;mysteries&rdquo; happening in our OpenStack cluster.</p>

<h2>Tempest and Rally</h2>

<p>When you deploy an OpenStack cluster, how do you verify that your cluster functions correctly? Icinga checks cover a very small subset of the OpenStack functionality. To accomplish a thorough verification of the OpenStack cluster, we started using the <a href="https://docs.openstack.org/tempest/latest/">Tempest</a> project. Tempest is a battery of integration tests that are used to verify OpenStack&rsquo;s functionality and it is a part of the continuous integration pipeline of the OpenStack project. Tempest tests send requests to the OpenStack APIs and verify the responses. As the goal of the Tempest project is to verify the integration of OpenStack components during development,  the included integration tests were a bit too low-level for our use case of merely verifying that the OpenStack cluster functioned properly. However, there were no better tools available at the time and it did the trick for us.</p>

<p>After a while of using Tempest, we discovered yet another project called <a href="https://docs.openstack.org/developer/rally/">Rally</a>. Rally is a benchmarking tool that is used to measure OpenStack&rsquo;s performance and to identify performance bottlenecks. Rally builds on top of Tempest and it comes with a set of predefined scenarios that are executed against the OpenStack cluster. Example scenarios are: boot and delete server, boot server from volume, create a subnet, create and attach volume, create and delete a Heat stack, and many more. The available scenarios were just right to verify our cloud! On top of that, Rally generates beautiful reports with the overview of executed tasks and their duration. We ended up creating a cron job that schedules the Rally tests to run every two hours. The test results are monitored using Icinga which in the case of test failure sends an alert to the operator.</p>

<p>Because our OpenStack cluster was constantly exercised by the Rally tests, we were able to quickly spot resources that OpenStack didn&rsquo;t clean up properly and that were piling up. We have seen diverse OpenStack database tables growing infinitely.  We have experienced Neutron leaving processes running on the controller nodes, leaving empty network namespaces behind or filling up the <code>/var/log/neutron</code> directory with files. Remember that we experienced these issues while using the Mitaka release of OpenStack. I&rsquo;m sure that things improved since then. To address the resource leaks, we wrote custom clean-up scripts. I&rsquo;m publishing them for you to use at your own risk. You can find them on <a href="https://github.com/noseka1/openstack-periodic-cleanup">GitHub</a>.</p>

<h2>Tracking cloud resource usage</h2>

<p>In OpenStack, we were missing some kind of reporting on resource usage. In our organization, each development team has its dedicated project in OpenStack. It is important to us to understand, how much of the cloud resources each team is consuming, i.e. how many CPU cores, memory, and volumes. In addition to per project usage, we also monitor the total resource usage across the entire cluster. In the case, that the total usage is reaching the total capacity available we can organize additional hardware ahead of time.</p>

<p>Around OpenStack Mitaka release, we didn&rsquo;t find any tool that would generate the usage reports. However, OpenStack&rsquo;s MariaDB database contains all the input data required to create such reports. It was rather straightforward to create a set of SQL scripts to generate the reports directly out of the OpenStack&rsquo;s database. We run these scripts periodically using Icinga, so that we can see the report output on our monitoring dashboard. If you are interested, you can find our OpenStack usage report scripts on <a href="https://github.com/noseka1/openstack-cloud-report">GitHub</a>.</p>

<h2>Further notes</h2>

<p>I&rsquo;d like to describe several further observations that we made while operating OpenStack. Once again, our experience pertains to the Mitaka release of OpenStack only. Many of the issues we stumbled upon might have been resolved in the newer releases of OpenStack.</p>

<ul>
<li>In order to get OpenStack working smoothly, you should expect to use some amount of duct tape and bubble gum. As OpenStack was implemented in Python, patching OpenStack is relatively easy. Many times I was able to find fixes for our issues on the project development branches and needed just to port them to our OpenStack version.</li>
<li>OpenStack is deployed on many nodes. It was useful for us to write Ansible scripts to automate the restart of the RabbitMQ cluster and to automate the restart of all OpenStack services on all nodes (aka restart the world). Due to the issues with the OpenStack TripleO installer in the Mitaka release, we are still forced to restart the world after adding a compute node.</li>
<li>Switching to Keystone Fernet tokens considerably reduced the load on the MariaDB database. We enabled Fernet tokens even in the Mitaka release of OpenStack.</li>
<li>RabbitMQ, Cinder Backup and several other services require higher amount of open file descriptors. For instance, RabbitMQ <a href="https://www.rabbitmq.com/production-checklist.html">recommends</a> to allow at least 50K of open file descriptors. Insufficient amount of file descriptors caused our RabbitMQ to crash. As RabbitMQ is the communication backbone of OpenStack, you can imagine how much fun it caused.</li>
<li>Our OpenStack networking is set up to use Neutron&rsquo;s OpenVSwitch driver and VLANs. In the default configuration, it happened to us that the multicast traffic sent by a single virtual machine flooded the entire network and caused OpenVSwitch to begin dropping packets. We didn&rsquo;t do any further research on the multicast on OpenStack topic so far, just avoided sending multicast altogether.</li>
<li>Kudos goes to the <a href="https://ceph.com/">Ceph</a> storage. We are running the old Ceph v0.94 Hammer which was able to survive emergency situations like lost storage node and running out of space condition without any problems.</li>
</ul>


<h2>Conclusion</h2>

<p>In this blog post, we shared some of our experiences with operating OpenStack. We described the monitoring using Icinga, collecting Ceilometer metrics and events, collecting system logs using the ELK stack, verifying the OpenStack functionality with Rally and generating cloud resource usage reports.</p>

<p>OpenStack is not the easiest software to run, however, if you do your homework you will succeed. At the present time, OpenStack just works for us and brings a lot of value to the teams in our company.</p>

<p>If you&rsquo;d like to share your experience with operating OpenStack, I would love to hear from you. Please, feel free to use the comment section below.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[18 Months with OpenStack, Our Experience, Part I]]></title>
    <link href="http://alesnosek.com/blog/2018/02/19/18-months-with-openstack-our-experience-part-i/"/>
    <updated>2018-02-19T21:06:17-08:00</updated>
    <id>http://alesnosek.com/blog/2018/02/19/18-months-with-openstack-our-experience-part-i</id>
    <content type="html"><![CDATA[<p>It has been 18 months since we deployed OpenStack cloud in our company. In this article, I would like to review our time with OpenStack and describe some of the experience we gained. Are you thinking about building an OpenStack-based cloud? This article might provide you with additional insights and tips that will help you succeed.</p>

<!-- more -->


<h2>Introduction</h2>

<p>Right at the beginning, I&rsquo;d like to say that our company is not a cloud provider. We didn&rsquo;t build a cloud to provide a service to customers. Instead, we built a private cloud to support our engineering team in their software development efforts. Our OpenStack is running development machines, build machines and test machines. The requirements on the availability and reliability of our OpenStack cluster are therefore lower than the requirements that a public cloud would have to meet.</p>

<p>We started evaluating OpenStack around the Kilo release and ended up going with Mitaka into production. Around that time, Internet was flooded with articles criticizing the complexity of OpenStack including scary stories of companies failing their OpenStack projects. I can confirm that deploying OpenStack was a real challenge and that as we were working on it, the OpenStack version of the Kennedy&rsquo;s famous words passed through my mind several times:</p>

<blockquote><p>We choose to deploy OpenStack not because it is easy, but because it is hard.</p></blockquote>

<p>However, nothing can scare away a proficent software practitioner. Eventually, we got the job done and the invested effort did pay off.</p>

<h2>OpenStack essentials</h2>

<p><a href="https://www.openstack.org/">OpenStack</a> is an open-source infrastructure-as-a-service (IaaS) cloud platform. It&rsquo;s important to understand that OpenStack itself is only a controlling layer that relies on other software projects to provide the implementation of the underlying functionality. For instance, OpenStack can spin up virtual machines, however, you would not find any code in the OpenStack project that would actually implement a hypervisor. Instead, OpenStack integrates with an existing hypervisor software to do the job. A very popular choice of the hypervisor used along with OpenStack is <a href="https://www.linux-kvm.org">KVM</a> and so when the user creates a virtual machine on OpenStack, OpenStack merely calls the KVM hypervisor to spin up the virtual machine. The same holds true for other areas of OpenStack functionality like networking and storage where OpenStack drives the underlying networking and storage software to do the actual job.</p>

<p>When planning an OpenStack cluster, you will have to choose from a variety of underlying technologies. For instance, in addition to the KVM hypervisor, OpenStack also supports Xen, VMware vSphere and Hyper-V. Most of the time you will just pick the technology you already run at your place and for which you have the staff to manage it. The freedom of choice you have with OpenStack is amazing, however, I would recommend to always look at the most popular choices first because their integration with OpenStack tends to be more solid. In our case, we chose KVM as a hypervisor, <a href="http://www.openvswitch.org/">Open vSwitch</a> as a networking implementation and <a href="https://ceph.com/">Ceph</a> to provide object and block storage.</p>

<p>OpenStack is an umbrella project under which you can find a host of projects each dealing with a different portion of the cloud functionality. The core projects that one can find installed in the majority of OpenStack deployments are:</p>

<ul>
<li><a href="https://wiki.openstack.org/wiki/Nova">Nova</a>. Manages virtual machines.</li>
<li><a href="https://wiki.openstack.org/wiki/Neutron">Neutron</a>. Provides networking to virtual machines.</li>
<li><a href="https://wiki.openstack.org/wiki/Cinder">Cinder</a>. Provides block storage that can be attached to virtual machines.</li>
<li><a href="https://wiki.openstack.org/wiki/Glance">Glance</a>. Stores virtual machine images.</li>
<li><a href="https://wiki.openstack.org/wiki/Horizon">Horizon</a>. Web-based user interface to OpenStack services.</li>
<li><a href="https://wiki.openstack.org/wiki/Keystone">Keystone</a>. Identity service.</li>
</ul>


<p>Additionally, project <a href="https://wiki.openstack.org/wiki/Heat">Heat</a>, <a href="https://wiki.openstack.org/wiki/Swift">Swift</a>, and <a href="https://wiki.openstack.org/wiki/Telemetry">Ceilometer</a> are also rather popular. You can find plenty of other OpenStack projects listed on the <a href="https://www.openstack.org/software/project-navigator">Project navigator</a> page. When choosing OpenStack projects for your deployment, you should always consider the adoption and the maturity of the projects. Many projects on the list are still in the early stages of development and not ready for production use.</p>

<p>OpenStack was designed for massive scale deployments as you can tell if you look at the <a href="https://docs.openstack.org/arch-design/design.html">OpenStack architecture diagram</a>. Each OpenStack project consists of multiple services (daemons) that can be deployed on separate physical machines allowing OpenStack to scale out. OpenStack services communicate with each other over the network using RESTful APIs. In addition, some of the projects like Nova, Neutron and Cinder chose to leverage a message broker for internal communication. The high number of services that form an OpenStack deployment contributes to its operational complexity.</p>

<h2>Getting started with OpenStack</h2>

<p>If you are new to OpenStack, a great place to start learning OpenStack is the <a href="https://docs.openstack.org/devstack/latest/">DevStack project</a>. DevStack allows you to create an all-in-one deployment of OpenStack. With DevStack you can access debug logs of individual OpenStack services as well as easily restart OpenStack services after you changed their configuration. It took me a while to figure out which configuration option affects which OpenStack service and how OpenStack services communicate with each other. I learned a lot by re-deploying DevStack many times, trying to make the individual OpenStack features work properly.</p>

<p>OpenStack is a fast moving project with two major releases per year. Especially in the past, the project documentation could not keep up with the many changes packed in each release. The documentation was outdated on many places or was missing altogether. When working with OpenStack I quickly realized that reading the OpenStack&rsquo;s Python code was necessary in order to understand how some of the configuration options worked or when troubleshooting various issues.</p>

<blockquote><p> Ability to read the OpenStack source code was required to succeed.</p></blockquote>

<p>OpenStack is written using a beautiful idiomatic Python code which was most of the time a pleasure to read. At first, I started walking through the code of simpler projects like Glance and learned the patterns that were commonly used in other OpenStack projects, too. Only later I dived deeper into the internals of Nova, the OpenStack&rsquo;s brain that schedules and creates virtual machines. When between OpenStack releases configuration options were renamed or moved to different INI file sections, I just grepped through the source code and learned about the changes avoiding any further frustration.</p>

<p>If you are getting started with OpenStack, prepare for a steep learning curve. Apart from studying the OpenStack project documentation, you will have to refer to the documentation of the technologies that you integrate with OpenStack, too. For instance, I spend quite a bit of time studying the documentation of <a href="https://www.rabbitmq.com/documentation.html">RabbitMQ</a>, <a href="https://libvirt.org/docs.html">libvirt</a>, <a href="http://docs.openvswitch.org">Open vSwitch</a>, and <a href="http://docs.ceph.com">Ceph</a>.</p>

<h2>Choosing an OpenStack distribution</h2>

<p>There are several OpenStack distributions available out there. For us the choice was pretty straight forward. As we are a Red Hat shop, we went with <a href="https://www.rdoproject.org/">RDO</a> installed on top of RHEL7. I spent large amounts of time working with RDO and yeah, it was challenging, at least in its Mitaka release. For further details on our experience with OpenStack RDO, you can refer to articles: <a href="/blog/2016/03/27/tripleo-installer-the-good/">1</a>, <a href="/blog/2017/01/15/tripleo-installer-production-ready">2</a>. Due to the complexity of OpenStack, it is rather difficult to create a tool to manage its life-cycle and I&rsquo;m certain that further development effort will have to be spent before reaching perfection.</p>

<p>By the way, some OpenStack distributions come with a GUI-based installer. As there are dozens of configuration parameters to set during the installation, I don&rsquo;t see the point of using a graphical interface to do this. Instead, a well commented configuration file seems more desirable to me. Does the GUI-based installer enable product managers to make a check mark on their data sheet? I would say yes, but you can safely ignore it when choosing your OpenStack distribution.</p>

<h2>Choosing server hardware</h2>

<p>We started with a small OpenStack deployment comprised of 3 controller nodes, 2 compute nodes and 3 Ceph nodes. Over time, we added further nodes to meet the growing demand and ended up with the current size of the cluster being 3 controller nodes, 13 compute nodes and 7 Ceph nodes. Majority of the nodes are HP ProLiant DL360 Gen9 machines with the following hardware parameters:</p>

<ul>
<li><strong>Controller nodes.</strong> 96GB RAM, 2 x 300GB SAS 10K HDD in RAID1, 1Gbit Ethernet NICs</li>
<li><strong>Compute nodes.</strong> 288GB RAM, 8 x 300GB SAS 10K HDD in RAID10 (for the OS + instance ephemeral storage), 1Gbit and 10Gbit Ethernet NICs</li>
<li><strong>Ceph nodes.</strong> 32GB RAM, 2 x 300GB SAS 10K HDD in RAID1 (for the OS), 6 x 1.2TB SAS 10K HDD (Ceph OSD storage drives), 1Gbit and 10Gbit Ethernet NICs</li>
</ul>


<p>1Gbit Ethernet NICs are used to access OpenStack APIs on the controller nodes. Compute nodes and Ceph storage nodes are interconnected using 10Gbit Ethernet. All network interfaces are bonded and connected to two different switches to avoid a single-point-of-failure. There is a dedicated 1Gbit link attached to each of the OpenStack nodes used for node management via SSH.</p>

<p>From our experience, each of the compute nodes can run up to 40-50 virtual machines using the default OpenStack RDO settings: cpu_allocation_ratio=16.0, ram_allocation_ratio=1.0 and disk_allocation_ratio=1.0. Our current limit preventing us to achieve even higher density is the amount of provisioned RAM on the nodes. In the future, we are considering adding more RAM to the compute nodes or increasing the ram_allocation_ratio.</p>

<h2>Deployment overview</h2>

<p>Finally, we are going to take a look at the high-level overview of our OpenStack deployment. In the diagram below you can see the OpenStack projects that we chose for the deployment:</p>

<p><img src="/images/posts/18_months_with_openstack_components.png" width="800" height="1000" title="OpenStack Components" ></p>

<p>Let me comment on some of the projects we deployed:</p>

<ul>
<li><strong><a href="https://docs.openstack.org/ironic">Ironic</a>.</strong> We deployed Ironic in order to manage baremetal machines that we use for performance testing. Performance tests are more accurate when carried out in an isolated baremetal environment than on the virtual machines that share the resources of the hypervisor. To this date we didn&rsquo;t realize this our plan but we will get back to it in the future.</li>
<li><strong><a href="https://docs.openstack.org/magnum">Magnum</a>.</strong> Magnum project simplifies the deployment of container orchestrators like Kubernetes, Swarm and Mesos on top of OpenStack. To accomplish this, Magnum leverages Heat templates behind the scenes and the actual provisioning is done by Heat. To be honest, we never really started using Magnum. When deploying Kubernetes, we preferred to use Heat templates provided by the Kubernetes project. This approach turned to be more straight forward than involving yet another service like Magnum. You can read about it <a href="/blog/2016/06/26/deploying-kubernetes-on-openstack-using-heat">here</a>.</li>
<li><strong><a href="https://docs.openstack.org/sahara">Sahara</a>.</strong> Sahara project allows you to deploy big data frameworks like Apache Hadoop and Apache Spark on top of OpenStack. We made similar experience with Sahara as we made with Magnum. We just didn&rsquo;t start using it at all. It turned out that there were already pre-existing deployment scripts provided by Hortonworks and others that it made no sense for us to use Sahara. While Hortonworks <a href="https://github.com/hortonworks/ansible-hortonworks">scripts</a> can deploy Hadoop on any of the major clouds, Sahara would be an OpenStack-only solution.</li>
<li><strong><a href="https://docs.openstack.org/manila">Manila</a>.</strong> While not depicted in the diagram, we also deployed OpenStack Manila. Manila is a shared file system service and we use it to provision NFS shares. Manila project started as a code copy of the Cinder project and perhaps that&rsquo;s why it was pretty stable and usable soon after its inception. I wrote an <a href="http://alesnosek.com/blog/2016/05/22/test-driving-openstack-manila/">article</a> about Manila at the time we were evaluating it.</li>
<li><strong><a href="https://docs.openstack.org/designate">Designate</a>.</strong>  Designate is a DNS as a service for OpenStack. After evaluating this project, we realized that for our simple purpose Designate was too involved. We ended up writing a Python script that dynamically registers OpenStack virtual machines with our internal DNS server. This script works reliably ever since and you can read about it in this <a href="/blog/2015/05/31/openstack-dynamic-dns-updates">blog post</a>.</li>
</ul>


<h2>Conclusion</h2>

<p>In this post, we described some of our experience with planning the OpenStack cloud and deploying it. In the <a href="/blog/2018/03/08/18-months-with-openstack-our-experience-part-ii/">second</a> blog post, we are going to share the lessons learned when operating OpenStack.</p>

<p>If you have battle scars from working with OpenStack, I would love to hear from you. Please, feel free to share your comments and stories in the comment section below.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Edge Security for Your Cloud Application, Part II]]></title>
    <link href="http://alesnosek.com/blog/2018/01/12/edge-security-for-your-cloud-application-part-ii/"/>
    <updated>2018-01-12T21:21:19-08:00</updated>
    <id>http://alesnosek.com/blog/2018/01/12/edge-security-for-your-cloud-application-part-ii</id>
    <content type="html"><![CDATA[<p>In this article, we&rsquo;re going to create a proof-of-concept deployment featuring a non-TLS client connecting to our cloud application. We are going to leverage the architecture approach discussed in the <a href="/blog/2018/01/10/edge-security-for-your-cloud-application-part-i">previous blog post</a>. A secure communication channel is going to be established between the client and the cloud application including mutual authentication.</p>

<!-- more -->


<h2>Deployment overview</h2>

<p>Before we get our hands dirty, let&rsquo;s gain a better understanding of what we are trying to achieve. The diagram depicting our test deployment looks as follows:</p>

<p><img src="/images/posts/edge_security_for_your_cloud_application_poc_arch.svg" width="1000" title="Architecture Overview" ></p>

<p>We&rsquo;re going to spin up two virtual instances. The edge instance will host our edge service. The client instance will host the client that will be accessing our edge service. For the sake of POC, the edge service is going to be an Apache web server and we&rsquo;re going to use the curl command-line utility in place of the client. The battle-proven HAProxy is going to play the role of the client-side as well as the server-side proxy, securing the client-server communication.</p>

<h2>Getting started</h2>

<p>You can start off with creating two CentOS 7 instances in AWS. Choose a minimalist t2.micro instance type which is sufficient for our proof of concept. In the security groups settings, make sure that in addition to the SSH port you have also enabled access to port 443 (HTTPS) from anywhere.</p>

<p>After the instances booted up, install HAProxy on both instances:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>yum install -y haproxy
</span></code></pre></td></tr></table></div></figure></p>

<p>And create a directory that will hold the keys and certificates required by HAProxy:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>mkdir /etc/haproxy/ssl
</span></code></pre></td></tr></table></div></figure></p>

<p>Make sure that you run the above command on both instances, too.</p>

<h2>PKI keys and certificates</h2>

<p>We are going to leverage the TLS protocol to establish a secure, mutually authenticated connection between the two proxies. TLS relies on PKI keys and certificates that we&rsquo;ll need to generate. The PKI setup for our company consists of a root CA, a layer of subordinate CAs and three end-entity certificates.</p>

<p><img src="/images/posts/edge_security_for_your_cloud_application_pki.svg" width="500" height="600" title="PKI" ></p>

<p>It is a common practice to sign the end-entity certificates by one or more subordinate CAs as it prevents the necessity of revoking a root certificate in the case that an end-entity certificate is incorrectly issued or compromised.</p>

<p>In total, we are going to generate three end-entity certificates. <code>Edge Service Certificate</code> is going to be used by the reverse proxy running on the edge instance in order to authenticate itself to the clients. <code>Customer1 Client Certificate</code> and <code>Customer2 Client Certificate</code> are certificates that our company securely distributes to the tenants (customers). Each tenant uses her certificate and the associated private key to authenticate herself when accessing the cloud application.</p>

<p>A PKI certificate can be created in three steps:</p>

<ol>
<li>Generate a private key.</li>
<li>Using the private key, generate a Certificate Signing Request (CSR).</li>
<li>Using a CA certificate along with the respective private key and the CSR, generate the certificate.</li>
</ol>


<p>An exeption from this three-step procedure is the root certificate which is self-signed.</p>

<p>In the following, we are going to generate seven certificates. All the commands are to be issued on the edge instance. Note that you can populate the certificate fields with pretty arbitrary values with one exception: the <code>Common Name</code> field of the end-entity certificates. <code>Common Name</code> of the <code>Edge Service Certificate</code> must match the DNS name of the edge instance. <code>Common Name</code> of the <code>Customer1 Client Certificate</code> and the <code>Customer2 Client Certificate</code> must match the HAProxy configuration. By inspecting the <code>Common Name</code> field, HAProxy is able to recognize which client is trying to access the cloud application and it is able to route the client request to the appropriate backend service.</p>

<h3>Company RootCA certificate</h3>

<p>Let&rsquo;s generate the company&rsquo;s greatest secret - the private key of the Company&rsquo;s RootCA:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl genrsa -out rootca.company.example.key.pem 4096
</span></code></pre></td></tr></table></div></figure></p>

<p>And create a self-signed RootCA certificate. Below you can see the sample input data:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;<span class="nv">$ </span>openssl req -key rootca.company.example.key.pem -new -x509 -extensions v3_ca -out rootca.company.example.crt.pem&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Country Name <span class="o">(</span><span class="m">2</span> letter code<span class="o">)</span> <span class="o">[</span>XX<span class="o">]</span>:US
</span><span class='line'>State or Province Name <span class="o">(</span>full name<span class="o">)</span> <span class="o">[]</span>:CA
</span><span class='line'>Locality Name <span class="o">(</span>eg, city<span class="o">)</span> <span class="o">[</span>Default City<span class="o">]</span>:San Diego
</span><span class='line'>Organization Name <span class="o">(</span>eg, company<span class="o">)</span> <span class="o">[</span>Default Company Ltd<span class="o">]</span>:Company RootCA
</span><span class='line'>Organizational Unit Name <span class="o">(</span>eg, section<span class="o">)</span> <span class="o">[]</span>:
</span><span class='line'>Common Name <span class="o">(</span>eg, your name or your server<span class="p">&amp;</span>rsquo<span class="p">;</span>s hostname<span class="o">)</span> <span class="o">[]</span>:rootca.company.example
</span><span class='line'>Email Address <span class="o">[]</span>:
</span></code></pre></td></tr></table></div></figure></p>

<p>For the sake of conciseness, I shortened the console output a bit. Note that we are adding the command-line option <code>-extensions v3_ca</code> to denote this certificate as a CA certificate. Otherwise, an end-entity certificate would have been generated by default.</p>

<h3>Company SubCA certificate</h3>

<p>Next, issue the command to generate the private key of the Company&rsquo;s SubCA:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl genrsa -out subca.company.example.key.pem 4096
</span></code></pre></td></tr></table></div></figure></p>

<p>Using the private key, let&rsquo;s create a Certificate Signing Request:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;<span class="nv">$ </span>openssl req -new -key subca.company.example.key.pem -out subca.company.example.csr.pem&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Country Name <span class="o">(</span><span class="m">2</span> letter code<span class="o">)</span> <span class="o">[</span>XX<span class="o">]</span>:US
</span><span class='line'>State or Province Name <span class="o">(</span>full name<span class="o">)</span> <span class="o">[]</span>:CA
</span><span class='line'>Locality Name <span class="o">(</span>eg, city<span class="o">)</span> <span class="o">[</span>Default City<span class="o">]</span>:San Diego
</span><span class='line'>Organization Name <span class="o">(</span>eg, company<span class="o">)</span> <span class="o">[</span>Default Company Ltd<span class="o">]</span>:Company SubCA
</span><span class='line'>Organizational Unit Name <span class="o">(</span>eg, section<span class="o">)</span> <span class="o">[]</span>:
</span><span class='line'>Common Name <span class="o">(</span>eg, your name or your server<span class="p">&amp;</span>rsquo<span class="p">;</span>s hostname<span class="o">)</span> <span class="o">[]</span>:subca.company.example
</span><span class='line'>Email Address <span class="o">[]</span>:&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Please enter the following <span class="p">&amp;</span>lsquo<span class="p">;</span>extra<span class="p">&amp;</span>rsquo<span class="p">;</span> attributes
</span><span class='line'>to be sent with your certificate request
</span><span class='line'>A challenge password <span class="o">[]</span>:
</span><span class='line'>An optional company name <span class="o">[]</span>:
</span></code></pre></td></tr></table></div></figure></p>

<p>And finally, generate the certificate of the Company&rsquo;s SubCA:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl x509 -req -in subca.company.example.csr.pem -CA rootca.company.example.crt.pem -CAkey rootca.company.example.key.pem -CAcreateserial -extfile /etc/pki/tls/openssl.cnf -extensions v3_ca -out subca.company.example.crt.pem
</span></code></pre></td></tr></table></div></figure></p>

<h3>Customer1 SubCA certificate</h3>

<p>Steps to generate the Customer1 SubCA certificate should be quite clear now:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl genrsa -out subca.customer1.example.key.pem 4096
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;<span class="nv">$ </span>openssl req -new -key subca.customer1.example.key.pem -out subca.customer1.example.csr.pem&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Country Name <span class="o">(</span><span class="m">2</span> letter code<span class="o">)</span> <span class="o">[</span>XX<span class="o">]</span>:US
</span><span class='line'>State or Province Name <span class="o">(</span>full name<span class="o">)</span> <span class="o">[]</span>:CA
</span><span class='line'>Locality Name <span class="o">(</span>eg, city<span class="o">)</span> <span class="o">[</span>Default City<span class="o">]</span>:San Diego
</span><span class='line'>Organization Name <span class="o">(</span>eg, company<span class="o">)</span> <span class="o">[</span>Default Company Ltd<span class="o">]</span>:Customer1 SubCA
</span><span class='line'>Organizational Unit Name <span class="o">(</span>eg, section<span class="o">)</span> <span class="o">[]</span>:
</span><span class='line'>Common Name <span class="o">(</span>eg, your name or your server<span class="p">&amp;</span>rsquo<span class="p">;</span>s hostname<span class="o">)</span> <span class="o">[]</span>:subca.customer1.example
</span><span class='line'>Email Address <span class="o">[]</span>:&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Please enter the following <span class="p">&amp;</span>lsquo<span class="p">;</span>extra<span class="p">&amp;</span>rsquo<span class="p">;</span> attributes
</span><span class='line'>to be sent with your certificate request
</span><span class='line'>A challenge password <span class="o">[]</span>:
</span><span class='line'>An optional company name <span class="o">[]</span>:
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl x509 -req -in subca.customer1.example.csr.pem -CA rootca.company.example.crt.pem -CAkey rootca.company.example.key.pem -CAserial rootca.srl -extfile /etc/pki/tls/openssl.cnf -extensions v3_ca -out subca.customer1.example.crt.pem
</span></code></pre></td></tr></table></div></figure></p>

<h3>Customer2 SubCA certificate</h3>

<p>Analogicaly,  we are going to generate the Customer2 SubCA certificate:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl genrsa -out subca.customer2.example.key.pem 4096
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;<span class="nv">$ </span>openssl req -new -key subca.customer2.example.key.pem -out subca.customer2.example.csr.pem&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Country Name <span class="o">(</span><span class="m">2</span> letter code<span class="o">)</span> <span class="o">[</span>XX<span class="o">]</span>:US
</span><span class='line'>State or Province Name <span class="o">(</span>full name<span class="o">)</span> <span class="o">[]</span>:CA
</span><span class='line'>Locality Name <span class="o">(</span>eg, city<span class="o">)</span> <span class="o">[</span>Default City<span class="o">]</span>:San Diego
</span><span class='line'>Organization Name <span class="o">(</span>eg, company<span class="o">)</span> <span class="o">[</span>Default Company Ltd<span class="o">]</span>:Customer2 SubCA
</span><span class='line'>Organizational Unit Name <span class="o">(</span>eg, section<span class="o">)</span> <span class="o">[]</span>:
</span><span class='line'>Common Name <span class="o">(</span>eg, your name or your server<span class="p">&amp;</span>rsquo<span class="p">;</span>s hostname<span class="o">)</span> <span class="o">[]</span>:subca.customer2.example
</span><span class='line'>Email Address <span class="o">[]</span>:&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Please enter the following <span class="p">&amp;</span>lsquo<span class="p">;</span>extra<span class="p">&amp;</span>rsquo<span class="p">;</span> attributes
</span><span class='line'>to be sent with your certificate request
</span><span class='line'>A challenge password <span class="o">[]</span>:
</span><span class='line'>An optional company name <span class="o">[]</span>:
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl x509 -req -in subca.customer2.example.csr.pem -CA rootca.company.example.crt.pem -CAkey rootca.company.example.key.pem -CAserial rootca.srl -extfile /etc/pki/tls/openssl.cnf -extensions v3_ca -out subca.customer2.example.crt.pem
</span></code></pre></td></tr></table></div></figure></p>

<h3>Edge service certificate</h3>

<p>This is the first out of the three end-entity certificates. First, we will generate the private key:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl genrsa -out app.company.example.key.pem 2048
</span></code></pre></td></tr></table></div></figure></p>

<p>Next, we are going to create the CSR. Make sure you populate the <code>Common Name</code> field exactly as you can see below:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;<span class="nv">$ </span>openssl req -new -key app.company.example.key.pem -out app.company.example.csr.pem&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Country Name <span class="o">(</span><span class="m">2</span> letter code<span class="o">)</span> <span class="o">[</span>XX<span class="o">]</span>:US
</span><span class='line'>State or Province Name <span class="o">(</span>full name<span class="o">)</span> <span class="o">[]</span>:CA
</span><span class='line'>Locality Name <span class="o">(</span>eg, city<span class="o">)</span> <span class="o">[</span>Default City<span class="o">]</span>:San Diego
</span><span class='line'>Organization Name <span class="o">(</span>eg, company<span class="o">)</span> <span class="o">[</span>Default Company Ltd<span class="o">]</span>:Company
</span><span class='line'>Organizational Unit Name <span class="o">(</span>eg, section<span class="o">)</span> <span class="o">[]</span>:
</span><span class='line'>Common Name <span class="o">(</span>eg, your name or your server<span class="p">&amp;</span>rsquo<span class="p">;</span>s hostname<span class="o">)</span> <span class="o">[]</span>:app.company.example
</span><span class='line'>Email Address <span class="o">[]</span>:&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Please enter the following <span class="p">&amp;</span>lsquo<span class="p">;</span>extra<span class="p">&amp;</span>rsquo<span class="p">;</span> attributes
</span><span class='line'>to be sent with your certificate request
</span><span class='line'>A challenge password <span class="o">[]</span>:
</span><span class='line'>An optional company name <span class="o">[]</span>:
</span></code></pre></td></tr></table></div></figure></p>

<p>And finally, type this command to generate the certificate:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl x509 -req -in app.company.example.csr.pem -CA subca.company.example.crt.pem -CAkey subca.company.example.key.pem -CAcreateserial -out app.company.example.crt.pem
</span></code></pre></td></tr></table></div></figure></p>

<p>Note that we didn&rsquo;t include the <code>-extensions v3_ca</code> option as we wanted to create an end-entity certificate.</p>

<h3>Customer1 client certificate</h3>

<p>Now we are going to create a certificate for our first customer.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl genrsa -out customer1.example.key.pem 2048
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;<span class="nv">$ </span>openssl req -new -key customer1.example.key.pem -out customer1.example.csr.pem&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Country Name <span class="o">(</span><span class="m">2</span> letter code<span class="o">)</span> <span class="o">[</span>XX<span class="o">]</span>:US
</span><span class='line'>State or Province Name <span class="o">(</span>full name<span class="o">)</span> <span class="o">[]</span>:MA
</span><span class='line'>Locality Name <span class="o">(</span>eg, city<span class="o">)</span> <span class="o">[</span>Default City<span class="o">]</span>:Boston
</span><span class='line'>Organization Name <span class="o">(</span>eg, company<span class="o">)</span> <span class="o">[</span>Default Company Ltd<span class="o">]</span>:Customer1
</span><span class='line'>Organizational Unit Name <span class="o">(</span>eg, section<span class="o">)</span> <span class="o">[]</span>:
</span><span class='line'>Common Name <span class="o">(</span>eg, your name or your server<span class="p">&amp;</span>rsquo<span class="p">;</span>s hostname<span class="o">)</span> <span class="o">[]</span>:customer1.example
</span><span class='line'>Email Address <span class="o">[]</span>:&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Please enter the following <span class="p">&amp;</span>lsquo<span class="p">;</span>extra<span class="p">&amp;</span>rsquo<span class="p">;</span> attributes
</span><span class='line'>to be sent with your certificate request
</span><span class='line'>A challenge password <span class="o">[]</span>:
</span><span class='line'>An optional company name <span class="o">[]</span>:
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl x509 -req -in customer1.example.csr.pem -CA subca.customer1.example.crt.pem -CAkey subca.customer1.example.key.pem -CAcreateserial -out customer1.example.crt.pem
</span></code></pre></td></tr></table></div></figure></p>

<h3>Customer2 client certificate</h3>

<p>And finally, we are going to create a certificate for our second customer.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl genrsa -out customer2.example.key.pem 2048
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;<span class="nv">$ </span>openssl req -new -key customer2.example.key.pem -out customer2.example.csr.pem&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Country Name <span class="o">(</span><span class="m">2</span> letter code<span class="o">)</span> <span class="o">[</span>XX<span class="o">]</span>:US
</span><span class='line'>State or Province Name <span class="o">(</span>full name<span class="o">)</span> <span class="o">[]</span>:TX
</span><span class='line'>Locality Name <span class="o">(</span>eg, city<span class="o">)</span> <span class="o">[</span>Default City<span class="o">]</span>:Austin
</span><span class='line'>Organization Name <span class="o">(</span>eg, company<span class="o">)</span> <span class="o">[</span>Default Company Ltd<span class="o">]</span>:Customer2
</span><span class='line'>Organizational Unit Name <span class="o">(</span>eg, section<span class="o">)</span> <span class="o">[]</span>:
</span><span class='line'>Common Name <span class="o">(</span>eg, your name or your server<span class="p">&amp;</span>rsquo<span class="p">;</span>s hostname<span class="o">)</span> <span class="o">[]</span>:customer2.example
</span><span class='line'>Email Address <span class="o">[]</span>:&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Please enter the following <span class="p">&amp;</span>lsquo<span class="p">;</span>extra<span class="p">&amp;</span>rsquo<span class="p">;</span> attributes
</span><span class='line'>to be sent with your certificate request
</span><span class='line'>A challenge password <span class="o">[]</span>:
</span><span class='line'>An optional company name <span class="o">[]</span>:
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>openssl x509 -req -in customer2.example.csr.pem -CA subca.customer2.example.crt.pem -CAkey subca.customer2.example.key.pem -CAcreateserial -out customer2.example.crt.pem
</span></code></pre></td></tr></table></div></figure></p>

<p>If everything went well, your working directory should contain a collection of PKI files similar to this list:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ls -1
</span><span class='line'>app.company.example.crt.pem
</span><span class='line'>app.company.example.csr.pem
</span><span class='line'>app.company.example.key.pem
</span><span class='line'>customer1.example.crt.pem
</span><span class='line'>customer1.example.csr.pem
</span><span class='line'>customer1.example.key.pem
</span><span class='line'>customer2.example.crt.pem
</span><span class='line'>customer2.example.csr.pem
</span><span class='line'>customer2.example.key.pem
</span><span class='line'>rootca.company.example.crt.pem
</span><span class='line'>rootca.company.example.key.pem
</span><span class='line'>rootca.srl
</span><span class='line'>subca.company.example.crt.pem
</span><span class='line'>subca.company.example.csr.pem
</span><span class='line'>subca.company.example.key.pem
</span><span class='line'>subca.customer1.example.crt.pem
</span><span class='line'>subca.customer1.example.csr.pem
</span><span class='line'>subca.customer1.example.key.pem
</span><span class='line'>subca.customer2.example.crt.pem
</span><span class='line'>subca.customer2.example.csr.pem
</span><span class='line'>subca.customer2.example.key.pem
</span><span class='line'>subca.srl
</span></code></pre></td></tr></table></div></figure></p>

<h2>Installing the edge service</h2>

<p>In our POC project, the role of the edge service will be played by the Apache server. To install the Apache server, issue the following command on the edge instance:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>yum install -y httpd
</span></code></pre></td></tr></table></div></figure></p>

<p>You can start the Apache server by typing:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>systemctl start httpd
</span></code></pre></td></tr></table></div></figure></p>

<p>The default static web page served by Apache is for our purposes a bit too long. Let&rsquo;s replace it with a simple, one line message:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span><span class="nb">echo</span> <span class="p">&amp;</span>lsquo<span class="p">;</span>It works!<span class="p">&amp;</span>rsquo<span class="p">;</span> &gt; /var/www/html/index.html
</span></code></pre></td></tr></table></div></figure></p>

<p>To verify that Apache was installed properly and is running, issue the command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>curl localhost
</span><span class='line'>It works!
</span></code></pre></td></tr></table></div></figure></p>

<h2>Configuring the reverse proxy on the edge instance</h2>

<p>In this section, we are going to set up the reverse proxy on the edge instance. First, let&rsquo;s prepare two files which will be referred to from the HAProxy configuration. The file <code>app.crt</code> will include the edge service certificate along with the CA chain and the respective private key. It is used by HAProxy to authenticate itself to the clients. In the following sections, we will configure the client-side HAProxy to trust these certificates and hence verify that it is connecting to the correct service and not for example to a service of an attacker. To create the <code>app.crt</code> file, you can type:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>cat <span class="se">\</span>
</span><span class='line'>app.company.example.crt.pem <span class="se">\</span>
</span><span class='line'>subca.company.example.crt.pem <span class="se">\</span>
</span><span class='line'>rootca.company.example.crt.pem <span class="se">\</span>
</span><span class='line'>app.company.example.key.pem <span class="se">\&lt;</span>/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;blockquote&gt;&lt;p&gt;/etc/haproxy/ssl/app.crt
</span></code></pre></td></tr></table></div></figure></p></blockquote>

<p>The important task of the server-side HAProxy is to authenticate the incoming client connections. In our project, we are looking at two customers that should be allowed to access our application. For that, we&rsquo;re going to include the CA certificate chains of the two customers into the <code>customer-ca.crt</code> file:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>cat <span class="se">\</span>
</span><span class='line'>subca.customer1.example.crt.pem <span class="se">\</span>
</span><span class='line'>subca.customer2.example.crt.pem <span class="se">\</span>
</span><span class='line'>rootca.company.example.crt.pem <span class="se">\&lt;</span>/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;blockquote&gt;&lt;p&gt;/etc/haproxy/ssl/customer-ca.crt
</span></code></pre></td></tr></table></div></figure></p></blockquote>

<p>As the last step in this section, we are going to configure HAProxy. You can open the HAProxy configuration file <code>/etc/haproxy/haproxy.cfg</code> in your favorite editor and replace its content with:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>global
</span><span class='line'>  tune.ssl.default-dh-param 1024&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;defaults
</span><span class='line'>  timeout client 30s
</span><span class='line'>  timeout server 30s
</span><span class='line'>  timeout connect 5s&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;frontend proxy
</span><span class='line'>  <span class="nb">bind </span>0.0.0.0:443 ssl crt /etc/haproxy/ssl/app.crt ca-file /etc/haproxy/ssl/customer-ca.crt verify required
</span><span class='line'>  mode http&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  use_backend edge_customer1 <span class="k">if</span> <span class="o">{</span> ssl_c_s_dn<span class="o">(</span>cn<span class="o">)</span> -i customer1.example <span class="o">}</span>
</span><span class='line'>  use_backend edge_customer2 <span class="k">if</span> <span class="o">{</span> ssl_c_s_dn<span class="o">(</span>cn<span class="o">)</span> -i customer2.example <span class="o">}</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;backend edge_customer1
</span><span class='line'>  mode http
</span><span class='line'>  server customer1 127.0.0.1:80 check&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;backend edge_customer2
</span><span class='line'>  mode http
</span><span class='line'>  server customer2 127.0.0.1:80 check
</span></code></pre></td></tr></table></div></figure></p>

<p>This is a minimalist configuration file, good enough for our proof of concept. HAProxy is going to listen on port 443 for incoming TLS connections. It will present the edge service certificate to the clients. At the same time, it will only accept connections from the clients sending the Customer1 or Customer2 certificate. Based on the <code>Common Name</code> field of the client&rsquo;s certificate, HAProxy will forward the request to the respective backend. In our case, both customers will be served by the same service listening on 127.0.0.1:80, however, you can imagine that in the real scenario there would be two separate edge services perhaps running on two different machines.</p>

<p>You can start the HAProxy service using the following command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>systemctl restart haproxy
</span></code></pre></td></tr></table></div></figure></p>

<p>Before moving on, check the HAProxy logs. If everything worked well, there should be no errors or warnings:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>journalctl -u haproxy -e
</span></code></pre></td></tr></table></div></figure></p>

<h2>Configuring the proxy on the client instance</h2>

<p>In this section, we&rsquo;re going to turn our attention to the client instance. First, we&rsquo;ll need to copy some of the PKI keys and certificates from the edge instance to the client instance. I configured SSH between the two instances, so that I can issue the following command on the edge instance to copy the files to the client instance:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>scp <span class="se">\</span>
</span><span class='line'>customer1.example.crt.pem <span class="se">\</span>
</span><span class='line'>customer1.example.key.pem <span class="se">\</span>
</span><span class='line'>customer2.example.crt.pem <span class="se">\</span>
</span><span class='line'>customer2.example.key.pem <span class="se">\</span>
</span><span class='line'>subca.company.example.crt.pem <span class="se">\</span>
</span><span class='line'>rootca.company.example.crt.pem <span class="se">\</span>
</span><span class='line'>ip-172-31-33-109.us-west-2.compute.internal:
</span></code></pre></td></tr></table></div></figure></p>

<p>In the above command, make sure that you replace the target host name <code>ip-172-31-33-109.us-west-2.compute.internal</code> with the DNS name of your client instance.</p>

<p>On the client instance, we are going to add a line to the <code>/etc/hosts</code> file which will make the DNS name <code>app.company.example</code> resolve to the IP address of the edge instance. In the following command, replace the IP address with the IP address of your edge instance:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span><span class="nb">echo </span>172.31.44.105 app.company.example &gt;&gt; /etc/hosts
</span></code></pre></td></tr></table></div></figure></p>

<p>Let&rsquo;s check that the TLS client is able to connect to the edge service. On the client instance, type:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>curl <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>cacert rootca.company.example.crt.pem <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>cert ./customer1.example.crt.pem <span class="se">\</span>
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>key ./customer1.example.key.pem <span class="se">\</span>
</span><span class='line'>&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://app.company.example&quot;</span>&gt;https://app.company.example&lt;/a&gt;
</span><span class='line'>It works!
</span></code></pre></td></tr></table></div></figure></p>

<p>Excellent! We&rsquo;ve just verified that the client with the built-in TLS support is able to successfully connect to our edge service and authenticate itself as Customer1.</p>

<p>The ultimate goal of this tutorial was to allow a client without TLS support to access the edge service, too. In order to achieve this goal, we&rsquo;re going to set up a client-side HAProxy. First, let&rsquo;s prepare two files that will be needed by HAProxy. The <code>customer1.crt</code> file enables HAProxy to authenticate itself to the edge service as Customer1. You can create this file by issuing the command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>cat <span class="se">\</span>
</span><span class='line'>customer1.example.crt.pem <span class="se">\</span>
</span><span class='line'>customer1.example.key.pem <span class="se">\&lt;</span>/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;blockquote&gt;&lt;p&gt;/etc/haproxy/ssl/customer1.crt
</span></code></pre></td></tr></table></div></figure></p></blockquote>

<p>Second file allows HAProxy to verify the authenticity of the edge service. It includes a chain of CA certificates, against which the certificate presented by the edge service will be verified. You can create the <code>company-ca.crt</code> file using the following command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>cat <span class="se">\</span>
</span><span class='line'>subca.company.example.crt.pem <span class="se">\</span>
</span><span class='line'>rootca.company.example.crt.pem <span class="se">\&lt;</span>/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;blockquote&gt;&lt;p&gt;/etc/haproxy/ssl/company-ca.crt
</span></code></pre></td></tr></table></div></figure></p></blockquote>

<p>And finally, we are going to configure the client-side HAProxy. On the client instance, open the file <code>/etc/haproxy/haproxy.cfg</code>  in your favorite editor and replace its content with the following configuration:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>global
</span><span class='line'>  tune.ssl.default-dh-param 1024&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;defaults
</span><span class='line'>  timeout client 30s
</span><span class='line'>  timeout server 30s
</span><span class='line'>  timeout connect 5s&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;frontend proxy
</span><span class='line'>  <span class="nb">bind </span>0.0.0.0:80
</span><span class='line'>  mode http&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  use_backend app&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;backend app
</span><span class='line'>  mode http
</span><span class='line'>  server app.company.example app.company.example:443 check ssl verify required ca-file /etc/haproxy/ssl/company-ca.crt crt /etc/haproxy/ssl/customer1.crt
</span></code></pre></td></tr></table></div></figure></p>

<p>HAProxy will listen on port 80 for the incoming HTTP connections. For each HTTP connection it will open a secure HTTPS connection to the edge service and it will pass the data back and forth between the two connections. You can start the HAProxy on the client instance by typing:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>systemctl restart haproxy
</span></code></pre></td></tr></table></div></figure></p>

<p>Double-check that there are no warnings or errors in the HAProxy logs:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>journalctl -u haproxy -e
</span></code></pre></td></tr></table></div></figure></p>

<p>If everything went well, you should be able to connect to the edge service using a non-TLS client. Here we go:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>curl localhost
</span><span class='line'>It works!
</span></code></pre></td></tr></table></div></figure></p>

<p>To verify that our client is recognized by the cloud application as Customer1, you can comment out the line <code>use_backend edge_customer1 if ...</code> in the <code>/etc/haproxy/haproxy.cfg</code> file on the edge instance. Remember to restart HAProxy after you modified the configuration. The repeated test from the client instance proves that indeed there&rsquo;s no backend for the Customer1 available anymore:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>curl localhost
</span><span class='line'>&lt;html&gt;&lt;body&gt;&lt;h1&gt;503 Service Unavailable&lt;/h1&gt;
</span><span class='line'>No server is available to handle this request.
</span><span class='line'>&lt;/body&gt;&lt;/html&gt;
</span></code></pre></td></tr></table></div></figure></p>

<h2>Conclusion and final remarks</h2>

<p>In this blog post, we established a secure communication channel between the client and our application running in the cloud. As demonstrated, our approach is also suitable for client applications that don&rsquo;t support TLS.</p>

<p>In our example, the client certificate authentication was carried out by HAProxy and the edge service sitting behind the proxy didn&rsquo;t get any information about the client. To improve the design, HAProxy could be configured to forward the attributes of the certificate presented by the client to the backend, by setting them as HTTP request headers. HAProxy even allows to insert the entire client certificate into a request header for the backend.</p>

<p>Our server presented a certificate that was signed by our own CA. In practice, we would deploy a certificate signed by a trusted third-party CA. AWS provides <a href="https://aws.amazon.com/certificate-manager">AWS Certificate Manager</a> (ACM) service to generate certificates for ELBs, API Gateway and other AWS services. Unfortunately, we cannot utilize this service for our use case as it doesn&rsquo;t provide access to the private key. Instead, we can purchase a certificate from one of the trusted certificate authorities or leverage the free of charge <a href="https://letsencrypt.org/">Let&rsquo;s Encrypt</a> certificate authority.</p>

<p>This concludes our miniseries about edge security for cloud applications. We are still evaluating the proposed approach. What do you think about it? If you have any feedback, please, feel free to add your comments in the comment section below.</p>
]]></content>
  </entry>
  
</feed>
