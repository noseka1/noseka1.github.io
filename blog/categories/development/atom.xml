<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: development | Ales Nosek - The Software Practitioner]]></title>
  <link href="http://alesnosek.com/blog/categories/development/atom.xml" rel="self"/>
  <link href="http://alesnosek.com/"/>
  <updated>2019-04-21T19:24:24-07:00</updated>
  <id>http://alesnosek.com/</id>
  <author>
    <name><![CDATA[Ales Nosek]]></name>

  </author>
  <generator uri="http://octopress.org/">Octopress</generator>


  <entry>
    <title type="html"><![CDATA[Remote Debugging of Java Applications on OpenShift]]></title>
    <link href="http://alesnosek.com/blog/2019/02/26/remote-debugging-of-java-applications-on-openshift/"/>
    <updated>2019-02-26T13:08:30-08:00</updated>
    <id>http://alesnosek.com/blog/2019/02/26/remote-debugging-of-java-applications-on-openshift</id>
    <content type="html"><![CDATA[<p>In this article I am going to show you how to attach a debugger and a VisualVM profiler to the Java application running on OpenShift. The approach described here doesn&rsquo;t make use of the <a href="https://jolokia.org/">Jolokia</a> bridge. Instead, we are going to leverage the port-forwarding feature of OpenShift.</p>

<!-- more -->


<p>The whole setup can be divided into three steps:</p>

<ol>
<li>Enable debug and JMX ports on the JVM</li>
<li>Set up port forwarding</li>
<li>Attach debugger and VisualVM to the forwarded ports</li>
</ol>


<p>I am going to use OpenShift v3.11 that I installed using Minishift and a test application built with Java OpenJDK 1.8. This is how the complete setup is going to look like:</p>

<p><img src="/images/posts/remote_debugging_of_java_applications_on_openshift.svg"></p>

<h2>Hello world application</h2>

<p>For those of you who want to follow along, let&rsquo;s set up a test application which we will use for debugging. If you already have your Java application running on OpenShift, you can jump ahead to the next section.</p>

<p>Let&rsquo;s deploy a Hello world application that I found on <a href="https://github.com/vert-x3/vertx-openshift-s2i">GitHub</a>. This application was originally created to demonstrate how to build <a href="https://vertx.io/">Vert.x</a>-based microservices on OpenShift. You can get this application up and running in just two steps.</p>

<p>First, issue this command to build an S2I builder image for Vert.x applications:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc create -f &lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&quot;https://raw.githubusercontent.com/vert-x3/vertx-openshift-s2i/master/vertx-s2i-all.json&quot;</span>&gt;https://raw.githubusercontent.com/vert-x3/vertx-openshift-s2i/master/vertx-s2i-all.json&lt;/a&gt;
</span><span class='line'>buildconfig.build.openshift.io/vertx-s2i created
</span><span class='line'>imagestream.image.openshift.io/vertx-centos created
</span><span class='line'>imagestream.image.openshift.io/vertx-s2i created
</span><span class='line'>template.template.openshift.io/vertx-helloworld-maven created
</span></code></pre></td></tr></table></div></figure></p>

<p>OpenShift started the build of the builder image and you can follow the progress with:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc log -f bc/vertx-s2i&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="p">&amp;</span>hellip<span class="p">;</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Removing intermediate container fc4bff8f426c
</span><span class='line'>Successfully built bd4a858867e9
</span><span class='line'>Pushing image 172.30.1.1:5000/myproject/vertx-s2i:latest <span class="p">&amp;</span>hellip<span class="p">;</span>
</span><span class='line'>Pushed 1/8 layers, 50% <span class="nb">complete</span>
</span><span class='line'>Pushed 2/8 layers, 25% <span class="nb">complete</span>
</span><span class='line'>Pushed 3/8 layers, 38% <span class="nb">complete</span>
</span><span class='line'>Pushed 4/8 layers, 50% <span class="nb">complete</span>
</span><span class='line'>Pushed 5/8 layers, 63% <span class="nb">complete</span>
</span><span class='line'>Pushed 6/8 layers, 97% <span class="nb">complete</span>
</span><span class='line'>Pushed 7/8 layers, 99% <span class="nb">complete</span>
</span><span class='line'>Pushed 8/8 layers, 100% <span class="nb">complete</span>
</span><span class='line'>Push successful
</span></code></pre></td></tr></table></div></figure></p>

<p>At the end of the build process OpenShift pushed the new image into the integrated Docker registry. Next, we are going to use the builder image to build and run a sample Vert.x application:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc new-app vertx-helloworld-maven
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>&gt; Deploying template <span class="p">&amp;</span>ldquo<span class="p">;</span>myproject/vertx-helloworld-maven<span class="p">&amp;</span>rdquo<span class="p">;</span> to project myproject&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt; vertx-helloworld-maven
</span><span class='line'> ---------
</span><span class='line'> Sample Vert.x application build with Maven
</span><span class='line'>
</span><span class='line'> * With parameters:
</span><span class='line'>    * <span class="nv">APPLICATION_NAME</span><span class="o">=</span>hello-world
</span><span class='line'>    * <span class="nv">APPLICATION_HOSTNAME</span><span class="o">=</span>
</span><span class='line'>    * <span class="nv">GIT_URI</span><span class="o">=</span>https://github.com/vert-x3/vertx-openshift-s2i.git
</span><span class='line'>    * <span class="nv">GIT_REF</span><span class="o">=</span>master
</span><span class='line'>    * <span class="nv">CONTEXT_DIR</span><span class="o">=</span><span class="nb">test</span>/test-app-maven
</span><span class='line'>    * <span class="nv">APP_OPTIONS</span><span class="o">=</span>
</span><span class='line'>    * <span class="nv">GITHUB_TRIGGER_SECRET</span><span class="o">=</span>EM325a5K <span class="c"># generated</span>
</span><span class='line'>    * <span class="nv">GENERIC_TRIGGER_SECRET</span><span class="o">=</span>CBCcCIWr <span class="c"># generated</span>
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="p">&amp;</span>ndash<span class="p">;</span>&gt; Creating resources <span class="p">&amp;</span>hellip<span class="p">;</span>
</span><span class='line'>    buildconfig.build.openshift.io <span class="p">&amp;</span>ldquo<span class="p">;</span>hello-world<span class="p">&amp;</span>rdquo<span class="p">;</span> created
</span><span class='line'>    imagestream.image.openshift.io <span class="p">&amp;</span>ldquo<span class="p">;</span>hello-world<span class="p">&amp;</span>rdquo<span class="p">;</span> created
</span><span class='line'>    deploymentconfig.apps.openshift.io <span class="p">&amp;</span>ldquo<span class="p">;</span>hello-world<span class="p">&amp;</span>rdquo<span class="p">;</span> created
</span><span class='line'>    route.route.openshift.io <span class="p">&amp;</span>ldquo<span class="p">;</span>hello-world<span class="p">&amp;</span>rdquo<span class="p">;</span> created
</span><span class='line'>    service <span class="p">&amp;</span>ldquo<span class="p">;</span>hello-world<span class="p">&amp;</span>rdquo<span class="p">;</span> created
</span><span class='line'><span class="p">&amp;</span>ndash<span class="p">;</span>&gt; Success
</span><span class='line'>    Build scheduled, use <span class="p">&amp;</span>lsquo<span class="p">;</span>oc logs -f bc/hello-world<span class="p">&amp;</span>rsquo<span class="p">;</span> to track its progress.
</span><span class='line'>    Access your application via route <span class="p">&amp;</span>lsquo<span class="p">;</span>hello-world-myproject.192.168.42.115.nip.io<span class="p">&amp;</span>rsquo<span class="p">;</span>
</span><span class='line'>    Run <span class="p">&amp;</span>lsquo<span class="p">;</span>oc status<span class="p">&amp;</span>rsquo<span class="p">;</span> to view your app.
</span></code></pre></td></tr></table></div></figure></p>

<p>You can follow the build logs by issuing the command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc log -f bc/hello-world&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="p">&amp;</span>hellip<span class="p">;</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="o">[</span>INFO<span class="o">]</span>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> <span class="p">&amp;</span>mdash<span class="p">;</span> maven-clean-plugin:2.5:clean <span class="o">(</span>default-clean<span class="o">)</span> @ vertx-hello-world <span class="p">&amp;</span>mdash<span class="p">;</span>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Deleting /opt/app-root/src/source/target
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> <span class="p">&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;</span>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> BUILD SUCCESS
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> <span class="p">&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;</span>
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Total <span class="nb">time</span>:  1.102 s
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> Finished at: 2019-02-26T20:21:57Z
</span><span class='line'><span class="o">[</span>INFO<span class="o">]</span> <span class="p">&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;&amp;</span>mdash<span class="p">;</span>
</span><span class='line'>Application jar file is located in /opt/openshift/vertx-app.jar
</span><span class='line'>Files located in the application directory:
</span><span class='line'>total 13216
</span><span class='line'>-rw-r<span class="p">&amp;</span>ndash<span class="p">;</span>r<span class="p">&amp;</span>ndash<span class="p">;</span>. <span class="m">1</span> default root      <span class="m">286</span> Feb <span class="m">26</span> 20:21 additional_files.md
</span><span class='line'>-rw-r<span class="p">&amp;</span>ndash<span class="p">;</span>r<span class="p">&amp;</span>ndash<span class="p">;</span>. <span class="m">1</span> default root <span class="m">13525420</span> Feb <span class="m">26</span> 20:21 vertx-app.jar
</span><span class='line'>Pushing image 172.30.1.1:5000/myproject2/hello-world:latest <span class="p">&amp;</span>hellip<span class="p">;</span>
</span><span class='line'>Pushed 0/9 layers, 2% <span class="nb">complete</span>
</span><span class='line'>Pushed 1/9 layers, 11% <span class="nb">complete</span>
</span><span class='line'>Push successful
</span></code></pre></td></tr></table></div></figure></p>

<p>If everything went fine, you should be able to see the Hello world application running:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc get pod <span class="p">|</span> grep hello-world
</span><span class='line'>hello-world-1-build   0/1       Completed    <span class="m">0</span>          6m
</span><span class='line'>hello-world-1-dw5lf   1/1       Running      <span class="m">0</span>          42s
</span></code></pre></td></tr></table></div></figure></p>

<h2>Enabling Debug and JMX ports on JVM</h2>

<p>In the following, I am going to use OpenJDK 1.8. Note that the available JVM options may vary depending on the version of Java  platform you are using.</p>

<p>To enable a remote debug port on JVM, one has to pass the following option to the JVM:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-agentlib:jdwp=transport=dt_socket,server=y,address=8000,suspend=n</span></code></pre></td></tr></table></div></figure></p>

<p>In order to enable JMX, the following JVM options are needed:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-Dcom.sun.management.jmxremote=true
</span><span class='line'>-Dcom.sun.management.jmxremote.port=3000
</span><span class='line'>-Dcom.sun.management.jmxremote.rmi.port=3001
</span><span class='line'>-Djava.rmi.server.hostname=127.0.0.1
</span><span class='line'>-Dcom.sun.management.jmxremote.authenticate=false
</span><span class='line'>-Dcom.sun.management.jmxremote.ssl=false</span></code></pre></td></tr></table></div></figure></p>

<p>This set of options deserves a bit more explanation. By default, JMX utilizes RMI as the underlying technology for the communication between the JMX client and the remote JVM. And as a matter of fact, there are two RMI ports needed for this communication:
* RMI registry port
* RMI server port</p>

<p>At the beginning, the client connects to the RMI registry on port 3000 and looks up the connection to the RMI server. After the successful lookup, the client initiates a second connection to the RMI server. Based on our configuration, the client is going to connect to 127.0.0.1:3001. However, there&rsquo;s no RMI server running on the local machine, so what&rsquo;s the deal? As you will see in the next section, we are going to forward the local port 3001 back to the remote server.</p>

<p>Next, we need to convey our configuration options to the JVM running inside the OpenShift pod. It turns out that there exists an environment variable <code>JAVA_TOOL_OPTIONS</code> that is interpreted directly by the JVM and where you can put your JVM configuration options. I recommend using this variable as there is a great chance that this variable will work no matter how deep in your wrapper scripts you are launching the JVM. Go ahead and modify the DeploymentConfig or Pod descriptor of your application in OpenShift to add the <code>JAVA_TOOL_OPTIONS</code> variable. For example, you can open the DeloymentConfig for editing like this:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc edit dc hello-world
</span></code></pre></td></tr></table></div></figure></p>

<p>&hellip; and add the <code>JAVA_TOOL_OPTIONS</code> environment variable to the container section of the specification:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&hellip;&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;pre>&lt;code>spec:
</span><span class='line'>  containers:
</span><span class='line'>  - env:
</span><span class='line'>    - name: JAVA_TOOL_OPTIONS
</span><span class='line'>      value: -agentlib:jdwp=transport=dt_socket,server=y,address=8000,suspend=n
</span><span class='line'>        -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=3000
</span><span class='line'>        -Dcom.sun.management.jmxremote.rmi.port=3001 -Djava.rmi.server.hostname=127.0.0.1
</span><span class='line'>        -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
</span><span class='line'>&lt;/code>&lt;/pre>
</span><span class='line'>
</span><span class='line'>&lt;p>&hellip;</span></code></pre></td></tr></table></div></figure></p>

<p>After applying the above changes, OpenShift will redeploy the application pod. At startup, JVM will print out the following line to the stderr which will show up in the container logs:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc logs dc/hello-world <span class="p">|</span> grep JAVA_TOOL_OPTIONS
</span><span class='line'>Picked up JAVA_TOOL_OPTIONS: -agentlib:jdwp<span class="o">=</span><span class="nv">transport</span><span class="o">=</span>dt_socket,server<span class="o">=</span>y,address<span class="o">=</span>8000,suspend<span class="o">=</span>n -Dcom.sun.management.jmxremote<span class="o">=</span><span class="nb">true</span> -Dcom.sun.management.jmxremote.port<span class="o">=</span><span class="m">3000</span> -Dcom.sun.management.jmxremote.rmi.port<span class="o">=</span><span class="m">3001</span> -Djava.rmi.server.hostname<span class="o">=</span>127.0.0.1 -Dcom.sun.management.jmxremote.authenticate<span class="o">=</span><span class="nb">false</span> -Dcom.sun.management.jmxremote.ssl<span class="o">=</span><span class="nb">false</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>This verifies that our JVM options are in effect and the debug port and JMX ports are open. How are we going to connect to these ports? Let&rsquo;s set up port forwarding on the local machine next.</p>

<h2>Setting up port forwarding</h2>

<p>OpenShift features <a href="https://docs.okd.io/latest/dev_guide/port_forwarding.html">port forwarding</a> that allows you to connect to an arbitrary port of a pod running on OpenShift. Port forwarding doesn&rsquo;t require you to define any additional objects like Service or Route to enable it. What you need though is to start a port forwarding proxy on your local machine. Issue the following command on your local machine to start the proxy and forward the three ports 8000, 3000, and 3001 to the remote pod running on OpenShift:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc port-forward &lt;POD&gt; <span class="m">8000</span> <span class="m">3000</span> 3001
</span></code></pre></td></tr></table></div></figure></p>

<p>In the above command, remember to replace <code>&lt;POD&gt;</code> with the name of your application pod. If everything worked well, you should see the following output :</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>oc port-forward hello-world-2-55zlq <span class="m">8000</span> <span class="m">3000</span> 3001
</span><span class='line'>Forwarding from 127.0.0.1:8000 -&gt; 8000
</span><span class='line'>Forwarding from 127.0.0.1:3000 -&gt; 3000
</span><span class='line'>Forwarding from 127.0.0.1:3001 -&gt; 3001
</span></code></pre></td></tr></table></div></figure></p>

<p>Note that the proxy keeps running on the foreground.</p>

<h2>Attaching to the JVM running on OpenShift</h2>

<p>Having our port-forwarding proxy all set, let&rsquo;s fire up a debugger and attach it to our application. Note that we instruct the debugger to connect to the localhost on port 8000. This port is in turn forwarded to the port 8000 on the JVM:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>jdb -connect com.sun.jdi.SocketAttach:hostname<span class="o">=</span>localhost,port<span class="o">=</span>8000
</span></code></pre></td></tr></table></div></figure></p>

<p>After the debugger attaches, you can list existing JVM threads using the <code>threads</code> command:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;blockquote>&lt;p>threads
</span><span class='line'>Group system:
</span><span class='line'>  (java.lang.ref.Reference$ReferenceHandler)0x133a                                             Reference Handler                                   cond. waiting
</span><span class='line'>  (java.lang.ref.Finalizer$FinalizerThread)0x133b                                              Finalizer                                           cond. waiting
</span><span class='line'>  (java.lang.Thread)0x133c                                                                     Signal Dispatcher                                   running
</span><span class='line'>  (java.lang.Thread)0x133d                                                                     RMI TCP Accept-3001                                 running
</span><span class='line'>  (java.lang.Thread)0x133e                                                                     RMI TCP Accept-3000                                 running
</span><span class='line'>  (java.lang.Thread)0x133f                                                                     RMI TCP Accept-0                                    running
</span><span class='line'>Group main:
</span><span class='line'>  (java.util.TimerThread)0x1342                                                                vertx-blocked-thread-checker                        cond. waiting
</span><span class='line'>  (io.vertx.core.impl.VertxThread)0x1343                                                       vert.x-worker-thread-0                              cond. waiting&lt;/p>&lt;/blockquote>
</span><span class='line'>
</span><span class='line'>&lt;p>&hellip;</span></code></pre></td></tr></table></div></figure></p>

<p>Next, let&rsquo;s check out if we can attach <a href="https://visualvm.github.io/">VisualVM</a> to our application as well:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>visualvm <span class="p">&amp;</span>ndash<span class="p">;</span>openjmx localhost:3000
</span></code></pre></td></tr></table></div></figure></p>

<p>Works like a charm, doesn&rsquo;t it?</p>

<p><img src="/images/posts/visualvm_attached.png"></p>

<h2>Conclusion</h2>

<p>In this blog post, we were able to attach a debugger and VisualVM to the Java application running on OpenShift. We didn&rsquo;t need to deploy Jolokia proxy or create additional Service or Route objects to make our setup work. Instead, we leveraged the port-forwarding feature already available in OpenShift. The demonstrated method has additional security benefits as we are not exposing any additional ports of the application container.</p>

<p>Hope you enjoyed this article and was able to reproduce this setup for yourself. If you have any thoughts or questions feel free to add them to the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Comparing OpenAPI with gRPC]]></title>
    <link href="http://alesnosek.com/blog/2019/01/25/comparing-openapi-with-grpc/"/>
    <updated>2019-01-25T15:22:46-08:00</updated>
    <id>http://alesnosek.com/blog/2019/01/25/comparing-openapi-with-grpc</id>
    <content type="html"><![CDATA[<p>Are you still coding your API client libraries by hand? Is your manually maintained API documentation drifting away from what was actually implemented? You may be interested in reviewing the two popular technologies that solve this problem. In this article, we are going to look at OpenAPI and gRPC side-by-side.</p>

<!-- more -->


<p>Both OpenAPI and gRPC are communication technologies very much needed in the today&rsquo;s world of microservices applications. They allow you to describe your APIs using  a formal language. This description then serves as a source of truth from which you can generate the client and server code and API documentation. As there are two viable alternatives, the question is which one is going to work better for you? As I was trying to answer the same question I did some research on the Internet and came up with a comparison table. I didn&rsquo;t include every single detail, however, this table could perhaps be a good starting point for you:</p>

<table>
<thead>
<tr>
<th> Criteria </th>
<th> OpenAPI </th>
<th> gRPC </th>
</tr>
</thead>
<tbody>
<tr>
<td> Origins </td>
<td> <a href="https://www.openapis.org/">OpenAPI</a> evolved from the <a href="https://swagger.io/">Swagger</a> project. Swagger started out as a specification for documenting RESTful APIs. Later on, tools to generate client and server code and generating of test-cases were added. While the original Swagger Specification was donated to the <a href="https://linuxfoundation.org">Linux Foundation</a> and renamed the OpenAPI,  Swagger remains one of the most widely used open source tool sets for developing OpenAPIs. </td>
<td> <a href="https://grpc.io/">gRPC</a> was originally developed at Google. Later on, it was donated to <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a>. </td>
</tr>
<tr>
<td> Communication Protocol </td>
<td> OpenAPI uses HTTP/1.1 protocol for transport. For the data representation, JSON is generally assumed. </td>
<td> gRPC uses HTTP/2 protocol for transport and <a href="https://developers.google.com/protocol-buffers/">Protocol Buffers</a> as a serialization format. </td>
</tr>
<tr>
<td> API Description Format </td>
<td> Developers describe their APIs using JSON or YAML documents that follow the <a href="https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md">OpenAPI Specification</a> schema. You can find a large archive of sample OpenAPI descriptions at <a href="https://apis.guru/openapi-directory/">apis.guru/openapi-directory</a>. </td>
<td> APIs are described using <code>.proto</code> files written in a <a href="https://developers.google.com/protocol-buffers/docs/proto3">Protocol Buffer Language</a>. </td>
</tr>
<tr>
<td> Description Style </td>
<td> REST APIs are described using HTTP verbs and URIs. Each URI represents a resource in your system, and the HTTP verbs represent actions you take on your resources. <br/><br/> REST APIs use <a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP status codes</a> to signalize the results of the operation invocations. As the HTTP status codes were primarily meant to convey the results of the transport operations, the mapping of status codes to the results of your API functions may be a bit loose. </td>
<td> With gRPC, you can describe your API in terms of methods or procedures. However, if a lot of methods are added over time, the end result can be a complex and confusing API due to the fact that developers must understand what each method does individually. Instead, Google suggests to use a <a href="https://cloud.google.com/apis/design/resources">resource-oriented design</a> which applies the REST design principles to gRPC. This results in more comprehensible APIs. Also, if you intend to transcode HTTP/JSON API into gRPC, you will greatly benefit from a gRPC API designed using the resource-oriented approach. <br/><br/> gRPC offers a set of <a href="https://godoc.org/google.golang.org/grpc/codes">error codes</a> that are well suited to describe the outcome of API operations. </td>
</tr>
<tr>
<td> Client and Server Code Generation </td>
<td>  There are several tools for generating code based on the OpenAPI description. The most widely used code generation project is <a href="https://swagger.io/tools/swagger-codegen/">Swagger Codegen</a>. Other projects include <a href="https://github.com/Azure/autorest">AutoRest</a> and <a href="https://github.com/capitalone/oas-nodegen">oas-nodegen</a>. </td>
<td> gRPC comes with a modular code generator called <em>protoc</em>. Each supported language is implemented as a separate plugin. The code generator was part of the gRPC project from its inception. </td>
</tr>
<tr>
<td> Interactive Documentation </td>
<td> <a href="https://swagger.io/tools/swagger-ui/">Swagger UI</a> is a great tool to visualize your API and execute test requests against your API. </td>
<td> <a href="https://github.com/sourcegraph/prototools">prototools</a> and <a href="https://github.com/pseudomuto/protoc-gen-doc">protoc-gen-doc</a> can generate documentation based on your <code>.proto</code> files. </td>
</tr>
<tr>
<td> Tooling </td>
<td> <a href="https://swagger.io/">Swagger Tools</a>, <a href="https://curl.haxx.se/">curl</a>, <a href="https://www.getpostman.com/">Postman</a>, web browsers, <a href="https://www.tcpdump.org/">tcpdump</a>, <a href="https://www.wireshark.org/">Wireshark</a> </td>
<td> <a href="https://github.com/grpc-ecosystem/awesome-grpc">Awesome gRPC</a>, <a href="https://github.com/fullstorydev/grpcurl">gRPCurl</a>. At the time of this writing, Wireshark supports gRPC only partially. </td>
</tr>
<tr>
<td> Performance </td>
<td> HTTP/1.1 protocol is a request/response protocol. When sending multiple requests over a single TCP connection, the next request can only be sent after the response to the previous request was received. This would normally result in a poor performance especially on the connections with higher latency. To increase the performance, HTTP client opens multiple TCP connections to a single server and sends multiple HTTP requests in parallel. New connections are opened as they are needed. As establishing a new TCP connection is associated with a cost, clients implement <em>connection pooling</em> to reuse the existing TCP connections. Remember to tune the clients connection pool to achieve good performance. <br/><br/> Some HTTP clients/servers may support HTTP/1.1 <em>pipelining</em>. Each HTTP request over the TCP connection may be made immediately without waiting for the previous request&rsquo;s response to return. As request responses must be returned in the order requested, this is prone to head of line blocking. <br/><br/> HTTP/1.1 is a text-based protocol and JSON is a text-based serialization format which hurts the performance. </td>
<td> By default HTTP/2 client opens a single TCP connection to the server and multiplexes multiple requests on this connection. Requests and responses are split into chunks and can be returned in an intermingled fashion. This prevents the head of line blocking that HTTP/1.1 pipelining may suffer from. In addition to that, the client can open multiple HTTP/2 connections to a single server and implement connection pooling. However, it is common to use a single TCP connection only. <br/><br/> HTTP/2 is a binary protocol. Also, according to <a href="https://medium.com/apis-and-digital-transformation/openapi-and-grpc-side-by-side-b6afb08f75ed">this</a> article by Tim Burks of Google, the Protocol Buffers binary format can be orders of magnitude faster to read than corresponding JSON serializations. <br/><br/> Overall, gRPC offers a better performance than OpenAPI. </td>
</tr>
<tr>
<td> Overall Summary </td>
<td> OpenAPI offers a great interoperability due to leveraging widely used HTTP/1.1 protocol and the JSON format. There is a great amount of tools available that will work with OpenAPI-based interfaces. </td>
<td> If you are looking for maximum performance, gRPC is a great choice for you. Also, HTTP/2 protocol is gradually gaining market share. Why not start using it today? </td>
</tr>
</tbody>
</table>


<h2>Where to go from here?</h2>

<p>The comparison table in the previous section highlights only the basic characteristics of OpenAPI and gRPC. I constructed the table based on many great articles that I found on the web. If you are interested in further details on how OpenAPI and gRPC compares I recommend to you to visit the following references:</p>

<ul>
<li><a href="https://medium.com/apis-and-digital-transformation/openapi-and-grpc-side-by-side-b6afb08f75ed">OpenAPI and gRPC Side-by-Side</a></li>
<li><a href="https://sookocheff.com/post/api/swagger-thrift-or-grpc/">Comparing Swagger with Thrift or gRPC</a></li>
<li><a href="https://code.tutsplus.com/tutorials/rest-vs-grpc-battle-of-the-apis--cms-30711">REST vs. gRPC: Battle of the APIs</a></li>
<li><a href="http://www.andrewconnell.com/blog/grpc-and-protocol-buffers-an-alternative-to-rest-apis-and-json">gRPC and Protocol Buffers: an Alternative to REST APIs and JSON</a></li>
<li><a href="https://www.sajari.com/blog/grpc-and-displacement-of-rest-apis">gRPC and the displacement of REST-based APIs</a></li>
<li><a href="https://improbable.io/games/blog/grpc-web-moving-past-restjson-towards-type-safe-web-apis">gRPC-Web: Moving past REST+JSON towards type-safe Web APIs</a></li>
<li><a href="https://husobee.github.io/golang/rest/grpc/2016/05/28/golang-rest-v-grpc.html">REST v. gRPC</a></li>
<li><a href="https://blogs.dropbox.com/tech/2019/01/courier-dropbox-migration-to-grpc/">Courier: Dropbox migration to gRPC</a></li>
</ul>


<h2>Combining OpenAPI and gRPC</h2>

<p>Do you have to use either OpenAPI or gRPC? If you like the awesome performance offered by gRPC but still need to provide REST interfaces to the external third-party clients there is a solution for you. You can leverage one of the proxies (<a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/http_filters/grpc_json_transcoder_filter">Envoy</a>,  <a href="https://github.com/grpc-ecosystem/grpc-gateway">grpc-gateway</a>) that can transcode the REST interface into gRPC. If you design your gRPC interfaces in a <a href="https://cloud.google.com/apis/design/resources">resource-oriented</a> fashion the transcoding process is straight forward. The resulting system architecture may look like this:</p>

<p><img src="/images/posts/comparing_openapi_with_grpc.svg"></p>

<p>The third-party REST client talks to the proxy using HTTP/JSON. Client requests are transcoded on-the-fly into gRPC requests. After the requests are processed, the resulting responses are transcoded from gRPC back to HTTP/JSON and delivered to the client.</p>

<h2>Conclusion</h2>

<p>In this blog post, we compared the basic characteristics of OpenAPI and gRPC. OpenAPI is a great choice due to its interoperability. On the other hand, gRPC offers a better performance. However, you don&rsquo;t have to choose one or the other. You can happily combine both technologies in a single system.</p>

<p>I hope you enjoyed this article. If you are looking into OpenAPI or gRPC I would be happy to hear about your thoughts. Please, feel free to leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Designing a Common Build System]]></title>
    <link href="http://alesnosek.com/blog/2018/05/03/designing-a-common-build-system/"/>
    <updated>2018-05-03T21:57:40-07:00</updated>
    <id>http://alesnosek.com/blog/2018/05/03/designing-a-common-build-system</id>
    <content type="html"><![CDATA[<p>Code reuse belongs to the basic tenets of software development. Moreover, one should have the same principle in mind when maintaining build scripts. If you are copy-pasting Makefiles and pom.xml files from project to project, stop now and read this article! We are going to discuss how to design a common build system.</p>

<!-- more -->


<p>A good software practitioner avoids having huge chunks of Makefiles, pom.xml files, build.xml files or shell scripts copy-pasted all over the code base. Based on experience, copy-pasted build scripts lead to inconsistencies, build issues and are overall driving the maintenance cost high.</p>

<p>In 2010, we invested heavily in the improvements of our build infrastructure. We introduced a continuous integration server Hudson (remember the project that was later renamed to Jenkins?), added source code analysis tool Sonar (nowadays called SonarQube), embraced RPM packaging and created a set of highly reusable build scripts which we called a common build system. In the next section, I&rsquo;m going to discuss a high-level design and ideas behind the common build system.</p>

<h2>High-level overview</h2>

<p>Our build system supports Java, C++ and C development. The core of the build system comprises of:</p>

<ul>
<li><a href="https://ant.apache.org/">Apache Ant</a> An old-timer between build tools. In current times, writing build scripts in XML is not sexy anymore, however, we like Ant for its simplicity and power. If you cannot express the required functionality using Ant tasks, you can always defer to using an embedded JavaScript. In our Ant scripts, you could find the <code>&lt;script language="javascript"&gt; ... &lt;/script&gt;</code> element that embeds JavaScript in several places.</li>
<li><a href="http://ant.apache.org/ivy/">Apache Ivy</a> Is a very flexible dependency manager that integrates with Apache Ant. While Ivy is predominantly used to manage Java jar files, we use it to manage C/C++ dependencies, too. For that, we zip up the C++ header files and push it along with the C++ shared libraries into the artifact repository.</li>
<li><a href="https://github.com/tumbarumba/AntScriptLibrary">Ant Script Library</a> Writing Ant build scripts from scratch is time consuming. To avoid spending this effort, we embraced Ant Script Library (ASL) which is a collection of re-usable Ant scripts providing a number of pre-defined targets.</li>
<li><a href="https://github.com/dmoulding/boilermake">Boilermake</a> Boilermake is a reusable GNU Make compatible Makefile. It uses a non-recursive strategy which avoids the many well-known pitfalls of recursive make, see also <a href="http://aegis.sourceforge.net/auug97.pdf">Recursive Make Considered Harmful</a>. We leverage Boilermake to compile C/C++ source code. An Ant <code>build.xml</code> wrapper script calls Boilermake when building a C/C++ module.</li>
</ul>


<p>The following diagram illustrates the organization of our code base:</p>

<p><img src="/images/posts/common_build_system.svg" width="600" height="600"></p>

<p>Our code base is divided up into modules. A module contains either Java or C/C++ source code required to build a library or executable. The <code>build-common</code> module is special in that it doesn&rsquo;t contain any source code to compile. Instead, it acts as a container in which we store all our reusable build scripts. The build scripts of other modules import the definitions from the <code>build-common</code> module. Due to high code reuse, the build scripts of individual modules are rather concise. The Ant statement to import the common definitions from the <code>build-common</code> module looks as follows:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;import <span class="nv">file</span><span class="o">=</span><span class="s2">&quot;../../Build/build-common/module.xml&quot;</span> /&gt;
</span></code></pre></td></tr></table></div></figure></p>

<p>Modules are organized into Git repositories according to the functionality they implement. For instance, modules of a specific product reside in its own Git repository. Furthermore, the <code>Platform</code> repository groups together modules that implement common libraries shared across several products.</p>

<p>All artifacts exported by the individual modules (jars, shared libraries, header files) are shared between the modules via the artifact repository. If additional information needs to be shared between modules, modules can publish Java properties files into the artifact repository which other modules can fetch and import. It was important to us to avoid any direct references between modules on the file system with the exception of the reference to the <code>build-common</code> module. These direct references between modules would be less obvious than passing artifacts and extra information via the artifact repository. We like to keep a good track of the dependencies between our software modules.</p>

<h2>Module directory structure</h2>

<p>Apache Ant does not propose any particular directory structure. However, it is easier to work with modules which have a common structure. Ant Script Library embraces the <a href="https://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html">Standard Directory Layout</a> from Maven project and so we derive our directory structure from this standard. Here is our module directory structure in greater detail:</p>

<table>
<thead>
<tr>
<th style="text-align:left;"> Directory          </th>
<th style="text-align:left;"> Purpose                          </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> src/main/java      </td>
<td style="text-align:left;"> Java application/library sources </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/c++       </td>
<td style="text-align:left;"> C++ application/library sources  </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/c         </td>
<td style="text-align:left;"> C application/library sources    </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/resources </td>
<td style="text-align:left;"> Application/library resources    </td>
</tr>
<tr>
<td style="text-align:left;"> src/main/scripts   </td>
<td style="text-align:left;"> Application/library scripts      </td>
</tr>
<tr>
<td style="text-align:left;"> src/test/java      </td>
<td style="text-align:left;"> Java test sources                </td>
</tr>
<tr>
<td style="text-align:left;"> src/test/c++       </td>
<td style="text-align:left;"> C++ test sources                 </td>
</tr>
<tr>
<td style="text-align:left;"> src/test/c         </td>
<td style="text-align:left;"> C test sources                   </td>
</tr>
<tr>
<td style="text-align:left;"> build.xml          </td>
<td style="text-align:left;"> Ant build file                   </td>
</tr>
<tr>
<td style="text-align:left;"> ivy.xml            </td>
<td style="text-align:left;"> Ivy module descriptor            </td>
</tr>
<tr>
<td style="text-align:left;"> README.md          </td>
<td style="text-align:left;"> Module&rsquo;s README file             </td>
</tr>
<tr>
<td style="text-align:left;"> target             </td>
<td style="text-align:left;"> Build output directory           </td>
</tr>
</tbody>
</table>


<h2>Common build targets</h2>

<p>We maintain a set of common Ant build targets which every module must implement:</p>

<table>
<thead>
<tr>
<th style="text-align:left;"> Target name               </th>
<th style="text-align:left;"> Description                                                                </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> default                   </td>
<td style="text-align:left;"> Build artifacts, publish artifacts                                         </td>
</tr>
<tr>
<td style="text-align:left;"> distribute                </td>
<td style="text-align:left;"> Build artifacts, publish artifacts and create a distribution package       </td>
</tr>
<tr>
<td style="text-align:left;"> all                       </td>
<td style="text-align:left;"> Build and test artifacts, publish artifacts, create a distribution package </td>
</tr>
<tr>
<td style="text-align:left;"> clean                     </td>
<td style="text-align:left;"> Delete files generated during the build                                    </td>
</tr>
<tr>
<td style="text-align:left;"> clean-dist                </td>
<td style="text-align:left;"> Delete files generated during the RPM package build                        </td>
</tr>
<tr>
<td style="text-align:left;"> clean-all                 </td>
<td style="text-align:left;"> Delete all generated files                                                 </td>
</tr>
<tr>
<td style="text-align:left;"> ci-default                </td>
<td style="text-align:left;"> Called by CI server during the build job execution                         </td>
</tr>
<tr>
<td style="text-align:left;"> report-sonar              </td>
<td style="text-align:left;"> Do statical analysis and send reports to Sonar server                      </td>
</tr>
</tbody>
</table>


<p>These build targets constitute a well-known interface which allows developers to clean and build any module using the same Ant command. Furthermore, each module defines the <code>ci-default</code> target which is called by the Jenkins CI server when building the module. This allows us to have Jenkins build any of our modules by issuing these two commands:</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ant clean-all
</span><span class='line'>ant ci-default
</span></code></pre></td></tr></table></div></figure></p>

<p>This two-command interface establishes a contract between modules and Jenkins and allows us to keep the Jenkins job definition fairly static. On the other hand, developers have full power to define what should happen during the build by implementing the module&rsquo;s  <code>ci-default</code> target.</p>

<p>Target <code>report-sonar</code> runs the SonarQube source code analysis tool, and sends the collected data to the SonarQube server. As the source code analysis takes some time to complete, we don&rsquo;t run it on every push to the Git repository. Instead, we scheduled a nightly Jenkins job that analyzes all the modules and uploads the collected data at once.</p>

<h2>Final remarks</h2>

<p>It has been several years since we created the common build system and we have been improving it ever since. We added many features to support our development process. We have already discussed some of them. Here is a summary of the most important capabilities we implemented so far:</p>

<ul>
<li>Support for building Java and C/C++ code</li>
<li>Support for multiple target platforms (RHEL5, RHEL6, RHEL7, Solaris 10)</li>
<li>Packaging software as RPM, Solaris pkg, IzPack and Docker image</li>
<li>Import of test data into Oracle database before running the unit tests</li>
<li>Management of build jobs in Jenkins</li>
<li>Source code analysis using SonarQube</li>
</ul>


<p>In our company, the relentless improvement process never stops. The Ant + Ivy tools we leverage at the core of our build system are past their prime. So, what&rsquo;s next? I&rsquo;m very excited about our current progress in gradually replacing Ant + Ivy with the more modern Gradle build tool.</p>

<p>I hope you enjoyed the tour through the design of the common build system. I would be interested to know how you promote code reuse of the build scripts in your company. It would be great to hear about your approach. Please, feel free to leave your comments in the comment section below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[AWS Lambda Adapter for Vert.x Web Applications]]></title>
    <link href="http://alesnosek.com/blog/2017/10/18/aws-lambda-adapter-for-vert-dot-x-web-applications/"/>
    <updated>2017-10-18T23:09:33-07:00</updated>
    <id>http://alesnosek.com/blog/2017/10/18/aws-lambda-adapter-for-vert-dot-x-web-applications</id>
    <content type="html"><![CDATA[<p><a href="http://vertx.io/">Vert.x</a> is an awesome tool-kit for developing reactive microservices. In this article, I&rsquo;m going to present an adapter that allows you to run your Vert.x web service as a Lambda function on AWS.</p>

<!-- more -->


<p><img class="right" src="/images/posts/vertx_logo.png" width="130" height="130"></p>

<p>If you are creating web services using Vert.x, you are leveraging the HTTP server built into the core of the Vert.x tool-kit. This HTTP server is based on the <a href="https://netty.io/">Netty</a> framework. When your web service comes up, the HTTP server opens a network port and starts listening for the incoming client connections. After a client connects, the HTTP server reads the HTTP request and processes this request by invoking callbacks that you registered. HTTP response generated by your implementation is returned back to the client. The web service remains running and processing requests until you shut it down.</p>

<p><img class="right" src="/images/posts/aws_lambda_logo.png" width="100" height="100"></p>

<p>In contrast to the constantly running web service, an AWS Lambda function is instantiated to serve a single HTTP request. After the HTTP request has been processed, the Lambda function is torn down.</p>

<p>In our company, we&rsquo;re looking at deploying our web services on-premise and in the cloud. We realized that when deploying into AWS it would be more cost effective if we could run some of our web services as Lambda functions. The question was, how to allow a Vert.x web service to alternatively run as a Lambda function? And how to accomplish this with a minimum development and maintenance effort?</p>

<p>After browsing through the Vert.x source code, it occurred to me that it would be possible to write a simple adapter that would convert HTTP requests and responses between the Lambda API and the Vert.x API. I then get on with the job and implemented such an adapter. And because software practitioners love open source, you can find this adapter along with the sample application on GitHub: <a href="https://github.com/noseka1/vertx-aws-lambda">vertx-aws-lambda</a>.</p>

<p>As always, I&rsquo;d love to hear your feedback. What do you think about this project? Feel free to leave your comments below.</p>
]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Evaluating Application Metrics Solutions - Prometheus?]]></title>
    <link href="http://alesnosek.com/blog/2017/09/10/evaluating-application-metrics-solutions-prometheus/"/>
    <updated>2017-09-10T16:17:49-07:00</updated>
    <id>http://alesnosek.com/blog/2017/09/10/evaluating-application-metrics-solutions-prometheus</id>
    <content type="html"><![CDATA[<p>In our <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">SOA-based</a> application, the problem of application metrics hasn&rsquo;t been solved yet. We would like to have our application services expose metrics that could be used for monitoring, auto-scaling and analytics. In this blog post, I would like to present to you one of the proposals to solve the application metrics which suggests leveraging <a href="https://prometheus.io/">Prometheus</a>.</p>

<!-- more -->


<p>Our application consists of multiple services that are deployed on multiple machines. Currently, our applicaton is deployed on-premise or as a managed offering on the virtual machines in AWS. We&rsquo;re also working on containerizing the application services to achieve higher density and better manageability when deploying into the AWS cloud. Some of our services are so light-weight that we&rsquo;re going to turn them into Lambda functions in the future to further reduce the operational costs. Thus, a solution for application metrics should be able to work in the serverless environment, too.</p>

<p>As of now, we deploy <a href="https://www.icinga.com/">Icinga</a> along with our application to provide system-level monitoring. Icinga collects the information about the nodes and checks that our services are still running. However, we don&rsquo;t collect any application-level metrics that would allow us to better assess the performance of our system. For example, we would like to know how many requests are processed per second, average request latency, request error rate, what are the depths of the internal queues and so forth. Application metrics would be a welcome input to the auto-scaling decisions and we would like to feed them into our analytics engine as well.</p>

<h2>Getting to know Prometheus</h2>

<p><img class="right" src="/images/posts/prometheus_logo.png" width="130" height="130"></p>

<p>Before jumping in and implementing our own solution for metrics collection and perhaps reinventing the wheel we started shopping around. It seemed to us, that Prometheus monitoring solution was gaining a lot of momentum in recent times. So, we took a closer look at Prometheus and this is what we found:</p>

<ol>
<li>Prometheus is an open-source monitoring solution hosted by <a href="https://www.cncf.io/">CNCF</a> - a foundation that hosts Kubernetes as well. Many companies use and contribute to Prometheus.</li>
<li>The <a href="https://prometheus.io/docs/introduction/overview/">architecture</a> of Prometheus is easy to understand and is modular. While Prometheus provides modules for metrics collection, alerts and Web UI, we would not have to use all of them.</li>
<li>Prometheus is a pull-based monitoring system. Each monitored target has to expose Prometheus formatted metrics. By default, targets make the metrics endpoint available at <a href="http://target/metrics.">http://target/metrics.</a> Prometheus periodically scrapes the metrics exposed by the targets.</li>
<li>Our services would need to expose the application metrics in the <a href="https://prometheus.io/docs/instrumenting/exposition_formats/">Prometheus format</a>. There are actually two formats available: a simple text format and protobufs. There are instrumentation <a href="https://prometheus.io/docs/instrumenting/clientlibs/">libraries</a> for Java, C++ and other languages, to gather the metrics and expose them in the Prometheus format.</li>
<li>The text-based Prometheus metrics format is so simple that it could be collected by other monitoring systems like Nagios or Icinga. Exposing metrics in the Prometheus format doesn&rsquo;t really mandate using Prometheus server for monitoring.</li>
<li>There&rsquo;s a Prometheus <a href="https://github.com/prometheus/jmx_exporter">jmx_exporter</a> library to convert the JMX MBeans data into Prometheus format. This would come in handy for gathering Tomcat metrics, for example.</li>
<li><a href="http://metrics.dropwizard.io/">Dropwizard metrics</a> is a popular Java instrumentation library. For instance, Vert.x toolkit can report its <a href="http://vertx.io/docs/vertx-dropwizard-metrics/java/">internal metrics</a> using the Dropwizard metrics library and there are other frameworks that supports it. Prometheus comes with a <a href="https://github.com/prometheus/client_java/tree/master/simpleclient_dropwizard">simpleclient_dropwizard</a> library that can make Dropwizard metrics available to Prometheus monitoring.</li>
<li>To prevent unauthorized access, the metric targets would need to be protected using TLS in combination with client certs, bearer token or HTTP basic authentication.</li>
<li>Prometheus pulls the metrics from the monitored targets. In addition, Prometheus comes with a <a href="https://prometheus.io/docs/practices/pushing/">Pushgateway</a> where clients can push their metrics to. However, as noted in the Prometheus documentation: <em>Usually, the only valid use case for the Pushgateway is for capturing the outcome of a service-level batch job</em>. Hence, Pushgateway would not work for aggregating metrics pushed by the Lambda functions.</li>
<li>In addition to application-level metrics, system-level metrics can be collected by Prometheus as well thanks to the <a href="https://github.com/prometheus/node_exporter">node_exporter</a>.</li>
<li>Prometheus is a great fit for dynamic environments like clouds and container clusters due to its discovery capabilities. In AWS, operator attaches tags to VMs and based on that Prometheus can discover them and start monitoring them automatically. The same principle works for container clusters like Kubernetes, too. One has to add annotations to pods and Prometheus will discover them automatically.</li>
<li>Prometheus makes the collected metrics available for querying via an <a href="https://prometheus.io/docs/querying/api/">HTTP API</a>. We could retrieve the metrics using this API in order to feed them into our analytics engine.</li>
<li>There is a great <a href="https://prometheus.io/docs/practices/naming/">guide</a> that would help us when designing our custom metrics.</li>
<li>Prometheus is written in Go and comes in a form of statically-linked binaries. This makes the installation of Prometheus a breeze.</li>
</ol>


<h2>Instrumenting Java applications</h2>

<p>In order to gather application metrics and to make them available to the Prometheus monitoring system, we would need to instrument our application services using Prometheus libraries. To get a clear idea, we created a proof-of-concept Java application instrumented using Prometheus. You can find it on <a href="https://github.com/noseka1/prometheus-poc">GitHub</a>.</p>

<p>Alternatively, we are thinking about leveraging Dropwizard metrics library for instrumentation. The Dropwizard metrics library is rather popular and is not connected with any particular monitoring solution. We would still be able to expose the Dropwizard metrics to Prometheus using a wrapper <a href="https://github.com/prometheus/client_java/tree/master/simpleclient_dropwizard">simpleclient_dropwizard</a>.</p>

<h2>Monitoring AWS Lambda functions</h2>

<p>AWS Lambda functions are extremely short-lived processes. Prometheus won&rsquo;t be able to pull the application metrics from them. Instead, Lambdas will have to push their metrics to Prometheus. At the first glance, we thought that the Prometheus Pushgateway could help here, however, reading the Pushgateway&rsquo;s documentation more carefully we found that <em>the Pushgateway is explicitly not an aggregator or distributed counter but rather a metrics cache</em>. And that&rsquo;s a problem, as we would like to count how many Lambda instances are being invoked per second and so on.</p>

<p>At the moment, we can see two approaches how to make the monitoring of Lambda functions work with Prometheus. Either, push the application metrics from the Lambda functions using a StatsD client. Prometheus&#8217; <a href="https://github.com/prometheus/statsd_exporter">statsd_exporter</a> would play a role of a StastD server and make the metrics available to Prometheus. Or, the second approach would be to create our own metrics aggregator that would receive the metrics from Lambda functions in the Prometheus format, aggregate them and expose them to the Prometheus server.</p>

<h2>Alternatives</h2>

<p>Besides using Prometheus, we were also thinking about other solutions for application metrics. As we already deploy Icinga for the system-level monitoring, it would make sense to use it for application metrics, too. We really like Icinga, it&rsquo;s a great monitoring software. Unfortunately, Icinga is based on the node and services model where a statically configured set of nodes are running services on them. This doesn&rsquo;t really fit with the modern containerized deployments where containers are dynamically scheduled on the cluster nodes and are also scaled up and down. Also, Prometheus server supports all sorts of metric queries and aggregations. Icinga is lacking this feature altogether. That&rsquo;s why we&rsquo;re leaning towards replacing Icinga with Prometheus for system-level as well as application-level monitoring.</p>

<p><a href="http://www.hawkular.org/">Hawkular</a> seems to be another modern monitoring project we would like to take a closer look at. In contrast to Prometheus project which is developed by many parties, it seems that Hawkular project is mostly driven by Red Hat.</p>

<h2>Conclusion</h2>

<p>Prometheus is a modern monitoring system. It was the first system we evaluated as we were trying to find a good solution for application metrics. In addition to application-level metrics, we could use Prometheus to collect system-level metrics as well. This would make Prometheus a single monitoring solution for our application. The only bigger issue for us is the absence of the AWS Lambda monitoring story.</p>

<p>If you have an application that you deliver on-premise as well as in the cloud, how did you solve the application metrics collection and monitoring? Is Prometheus a good way to go? Please, leave your comments below.</p>
]]></content>
  </entry>

</feed>
